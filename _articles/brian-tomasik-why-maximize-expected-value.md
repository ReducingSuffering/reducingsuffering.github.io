---
layout: article
title: Зачем максимизировать ожидаемую полезность?
authors:
  - Брайан Томасик
translated_by: К. Кирдан
original: https://reducing-suffering.org/why-maximize-expected-value/
original_date:
  - 2007
  - 2016-04-07
preview: https://reducing-suffering.org/wp-content/uploads/2014/09/FlattenedRoundPills.jpg
---
<h2 id="Аннотация">Аннотация</h2>

<a name="citationa"></a>
Стандартная [байесовская](https://ru.wikipedia.org/wiki/%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B0%D1%8F_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C) теория принятия решений диктует нам максимизировать ожидаемую полезность наших действий<sup><a href="#footnotea">a</a></sup>. К примеру, предположим, что мы видим несколько котят, застрявших на деревьях, и решаем, что спасти n котят в n раз лучше, чем спасти одного котенка. Тогда, если мы окажемся перед выбором: либо точно спасти одного котенка, либо иметь шансы 50 на 50 спасти трех котят (где, если мы потерпим неудачу, мы не спасем ни одного), мы должны попытаться спасти трех котят, потому что при этом ожидаемая полезность равна 1.5 (= 3\*0.5 + 0\*0.5), в то время как ожидаемая полезность спасения одного котенка равна 1 (= 1\*1). Но почему именно ожидаемое значение полезности? Почему бы вместо этого не максимизировать какую-нибудь другую функцию от вероятностей и полезностей исходов? В этой статье я привожу два интуитивных аргумента в пользу ожидаемого значения. Во-первых, в определенных ситуациях максимизация ожидаемого числа организмов, которым будет оказана помощь, эквивалентна максимизации вероятности того, что любому конкретному организму будет оказана помощь. Во-вторых, даже в тех случаях, когда это не так, закон больших чисел часто гарантирует лучший результат в долгосрочной перспективе.

## Содержание

* <a href="#Аннотация">Аннотация</a>
* <a href="#Вымышленный_пример">Вымышленный пример</a>
* <a href="#Соображение_1">Соображение 1: Голосование</a>
* <a href="#Соображение_2">Соображение 2: Закон больших чисел</a>
* <a href="#Что_насчет_смешанных_стратегий">Что насчет смешанных стратегий?</a>
* <a href="#Следствие">Следствие</a>
* <a href="#Бесконечные_исходы">Бесконечные исходы</a>
* <a href="#Что_насчет_изолированных_действий">Что насчет изолированных действий?</a>
* <a href="#Аргумент_1">Аргумент 1: Многомировая интерпретация квантовой механики</a>
* <a href="#Аргумент_2">Аргумент 2: Утилитаризм правил</a>
* <a href="#Логическая_неопределенность">Логическая неопределенность</a>
* <a href="#Сноски">Сноски</a>

---

<h2 id="Вымышленный_пример">Вымышленный пример</h2>

Неизвестная болезнь вспыхнула среди 20 000 жителей небольшого острова. Болезнь очень заразна: она распространилась на всех жителей острова еще до того, как ее кто-либо обнаружил. К счастью, поскольку остров изолирован, нет опасности распространения болезни на другие части мира. К несчастью для самих островитян, болезнь еще и 100% смертельна, и жить каждому из них теперь осталось лишь три дня.

<img align="right" src="https://reducing-suffering.org/wp-content/uploads/2014/09/FlattenedRoundPills.jpg" title="'Round, biconvex white tablets.' By David Richfield (Slashme) at the English language Wikipedia [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC-BY-SA-3.0 (http://creativecommons.org/licenses/by-sa/3.0/)], via Wikimedia Commons: https://commons.wikimedia.org/wiki/File:FlattenedRoundPills.jpg" width="35%" height="50%"/>

Мировое медицинское сообщество не располагает лекарствами, способными вылечить это заболевание или хотя бы предотвратить его смертельные побочные эффекты. Тем не менее, на остров направляются медицинские бригады для оказания паллиативной помощи. Медицинские бригады располагают ограниченным бюджетом в 10 000 долларов, на которые можно купить анальгетики, которые, в случае успеха, облегчат болезненность смерти от этой болезни. Вы, руководитель медицинской бригады, решаете, какое из двух возможных лекарств купить.

- Первое лекарство, "ТочноОблегчин", работает на 100%. Лечение им одного человека стоит 2.04 доллара.
- Другое лекарство, "ДешевоОблегчин", имеет лишь 50% вероятность хорошо подействовать; и если оно не действует хорошо, то оно не действует вообще. Стоимость лечения им одного человека составляет 1 доллар. 50%-я вероятность неудачи одинакова от лечения к лечению; то есть тот факт, что одно из лечений было неудачным, не увеличивает и не уменьшает вероятность того, что неудачным окажется какое-то другое лечение.<br><br>

Поскольку вы считаете, что бессмысленные страдания перед смертью одинаково плохи независимо от того, кто из островитян их испытает, вы придерживаетесь мнения, что успешное лечение _n_ человек в _n_ раз лучше, чем успешное лечение одного человека. Вы рассуждаете следующим образом: «Если мы купим ТочноОблегчин, мы гарантированно предотвратим страдания 10000/2.04 = 4900 человек. Если мы выберем ДешевоОблегчин, то сможем оплатить 10 000 лечений, но неясно, скольким людям это поможет. Поскольку каждое лечение имеет 50% шанс на успех, ожидаемое значение числа людей, которым мы поможем, составляет 10000\*0.5 + 0\*0.5 = 5000. Это больше, чем 4900, значит нам следует купить ДешевоОблегчин».

Но что, если окажется, что неудачу потерпят гораздо больше лечений, чем ожидалось? Что если, скажем, из них сработают только 4800? Тогда мы «проиграем» лечения, которые могли бы помочь 100 людям. Не лучше ли придерживаться безопасной ставки?

<h2 id="Соображение_1">Соображение 1: Голосование</h2>

Предположим, что мы не решаем заранее, кто из островитян получит лечение, которое мы купим. Значит, если у нас есть _t_ лекарств, вероятность того, что любой конкретный человек получит лекарство, равна _t_/20000. Тогда мы проведем опрос жителей острова, чтобы узнать, предпочли бы они, чтобы медицинская бригада купила все ТочноОблегчины, все ДешевоОблегчины или какую-то комбинацию тех и других.

Если островитяне голосуют за тот вариант, который максимизирует вероятность их успешного лечения, то все они проголосуют за покупку всего ДешевоОблегчина. Это следует из простой теоремы:

<div class="message">
<i>Теорема</i>: Предположим, есть <i>N</i> организмов, которые испытают жестокую боль, если им не оказать помощь. Пусть <i>T</i> — <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B0">случайная величина</a>, означающая количество тех случайно выбранных из <i>N</i> организмов, которые успешно избегут болезненного опыта, получив помощь. Тогда вероятность того, что любой организм избежит боли, равна E(<i>T</i>)/<i>N</i>, где за E(<i>T</i>) обозначено ожидаемое значение величины <i>T</i>. В частности, вероятность избежать боли всегда увеличивается по мере увеличения E(<i>T</i>), независимо от <a href="https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D1%8F_%D1%81%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B9_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D1%8B">дисперсии</a> <i>T</i>.<br><br>
<i>Доказательство</i>:<br>
Prob(помогли) = Σ<sub><i>T</i></sub> Prob(<i>T</i>=<i>t</i>) * <i>t</i> / <i>N</i> = (Σ<sub><i>T</i></sub> Prob(<i>T</i>=<i>t</i>) * <i>t</i>) / <i>N</i> = E(<i>T</i>) / <i>N</i>.
</div>

Мы можем применить эту идею и к предыдущему примеру с котятами. Предположим, вы — один из котят, и решаете, хотите ли вы, чтобы ваш потенциальный спасатель спас одного из троих, или попытался спасти всех троих с шансом 50 на 50. В первом случае вероятность того, что вы спасетесь, равна 1/3. Во втором случае вероятность того, что вы спасетесь, равна 1, если спасатель добьется успеха, и 0, если нет. Поскольку вероятности его успеха и провала одинаковы, общая вероятность вашего спасения равна (1/2)\*1 + (1/2)\*0 = 1/2, что больше 1/3.

Я должен отметить, что на практике люди в таких ситуациях, как ситуация с островитянами, могут на самом деле не выбирать тот вариант, который максимизировал бы вероятность получения ими помощи, – возможно, из-за [неприятия неопределеннности](https://en.wikipedia.org/wiki/Ambiguity_aversion), как было показано в [парадоксе Эллсберга](https://en.wikipedia.org/wiki/Ellsberg_paradox). Незнание того, сколько всего лечений пройдет успешно, может соответствовать более высокой неопределенности, чем знание количества успешных лечений при неуверенности лишь в том, кто именно их получит.

<h2 id="Соображение_2">Соображение 2: Закон больших чисел</h2>

Вышеупомянутое соображение хорошо работает в тех ситуациях, в которых распределяется одна и та же потенциальная выгода, так что людей волнует только вероятность ее получения. Но что насчет тех ситуаций, в которых потенциальные выгоды различны – например, предотвращение простуды и предотвращение заражения малярией? Очевидно, что людям нежелательно просто выбирать вариант, который максимизирует вероятность получения ими того или иного лечения, – потому что, например, вероятность 1/2 избежать простуды явно не лучше, чем вероятность 1/3 избежать малярии. Нам нужно наложить на разные исходы некоторую функцию полезности, которая определяла бы, насколько лучше предотвращение малярии, чем предотвращение простуды.

Если мы случайным образом распределяем средства для предотвращения простуды и малярии в группе людей, которые максимизируют ожидаемую индивидуальную полезность, то нетрудно показать, что они предпочли бы тот метод лечения, который максимизирует ожидаемую полезность для всей группы. Но возникает вопрос: нам нужно понять, почему люди вообще хотели бы максимизировать ожидаемую индивидуальную полезность.

<a name="citationb"></a>
Причина, которую обычно называют, заключается в том, что когда решения в отношении какого-то случайного события принимаются неоднократно, максимизация ожидаемого значения делает вероятным, что на длительных промежутках времени вы будете максимизировать фактическое среднее значение. Это следует из [закона больших чисел](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D1%87%D0%B8%D1%81%D0%B5%D0%BB), который гласит, что если мы проведем достаточное количество [некоррелированных](https://en.wikipedia.org/wiki/Uncorrelatedness_(probability_theory)) случайных испытаний (например, подбросим монету достаточное количество раз), мы можем быть сколь угодно уверенными в том, что фактическое среднее значение, которое мы наблюдаем в наших испытаниях (например, среднее значение бросков кубиков, которые мы делаем) будет настолько близко к ожидаемому значению (которое в данном случае составляет 3.5 = 1\*(1/6) + 2\*(1/6) + ... + 6\*(1/6)), насколько мы хотели<sup><a href="#footnoteb">b</a></sup>.

<a name="citationc"></a>
В примере с болезнью на острове количество людей, успешно прошедших лечение ДешевоОблегчином, представляет собой сумму из 10 000 случайных исходов. Это «большое число», что значит, что вероятность того, что фактическое число успешно пролечившихся людей значительно отклонится от 5000 – мала. Фактически, вероятность того, что ДешевоОблегчин успешно вылечит меньше людей, чем ТочноОблегчин, составляет лишь 2.3%<sup><a href="#footnotec">c</a></sup>.

<h2 id="Что_насчет_смешанных_стратегий">Что насчет смешанных стратегий?</h2>

<a name="citationd"></a>
Например, почему бы не потратить 5000 долларов на ТочноОблегчин и 5000 долларов на ДешевоОблегчин? По этой стратегии вы сможете купить 2450 лечений ТочноОблегчином и 5000 лечений ДешевоОблегчином. Ожидаемое количество людей, которым будет оказана помощь, составляет 2450 + 0.5\*5000 = 4950. Тут мы купили небольшую «страховку» от ситуаций, в которых помощь получило бы слишком малое число людей, но за счет возможности реально помочь большему числу людей. Даже здесь вероятность того, что наша смешанная стратегия поможет большему числу людей, чем более рискованная стратегия, составляет лишь 21%<sup><a href="#footnoted">d</a></sup>.

Если бы мы потратили на ТочноОблегчин меньше 50% нашего бюджета, этот разрыв в ожидаемых значениях сократился бы, но вместе с ним уменьшилась бы и наша страховка. Я не вижу причин предпочитать смешанную стратегию: если покупка некоторого количества ДешевоОблегчина поможет больше, чем отказ от покупки ДешевоОблегчина, то покупка _всех_ ДешевоОблегчинов будет еще лучше. Если на 10 000 людях вам сложно увидеть улучшение от покупки всего ДешевоОблегчина по сравнению с покупкой _в основном_ ДешевоОблегчина, то рассмотрите 10 триллионов или 10 [гуголов](https://ru.wikipedia.org/wiki/%D0%93%D1%83%D0%B3%D0%BE%D0%BB) людей. В этих случаях вы практически гарантированно поможете большему числу людей, если купите все ДешевоОблегчины.

<h2 id="Следствие">Следствие</h2>

Теперь рассмотрим следующую ситуацию. Вы снова директор медицинского проекта и обнаруживаете, что получили дополнительное пожертвование в размере 51 доллара, на которое можно купить больше лекарств. Если вы купите ТочноОблегчин, вы гарантированно поможете 51/2.04 = 25 людям. Если вы купите ДешевоОблегчин, ожидаемое количество людей, которым вы поможете, составит 25.5. Но теперь есть 44% вероятность того, что ДешевоОблегчин поможет меньшему числу людей, – возможно, даже сильно меньшему. Вы решите, что, в отличие от предыдущего случая, это дело слишком рискованное, поэтому лучше перестраховаться?

Надеюсь, что нет. Дополнительные 51 доллар не являются изолированными; это часть общего бюджета. Если бы вы начали с бюджета в 10 051 доллар, приведенный выше аргумент против смешанных стратегий говорил бы о том, что вам следует использовать все эти деньги для покупки ДешевоОблегчина, потому что это почти гарантирует лучший результат, – возможно, намного лучший.

<h2 id="Бесконечные_исходы">Бесконечные исходы</h2>

Как отмечает Уильям Феллер в книге «Введение в теорию вероятностей и ее приложения» (William Feller, _An Introduction to Probability Theory and Its Applications_, p. 251), слабый закон больших чисел не работает для случайных величин с бесконечным математическим ожиданием, поэтому аргумент о долгосрочном среднем не работает. Теорема [фон Неймана и Моргенштерна](https://en.wikipedia.org/wiki/Theory_of_Games_and_Economic_Behavior) об [ожидаемой полезности](https://web.archive.org/web/20070221104329/http://www.econ.hku.hk/~wsuen/uncertainty/eu.pdf), к которой тоже иногда обращаются, опирается на аксиому непрерывности, которая тоже нарушается, если мы допускаем бесконечно большие значения полезности (не допуская в то же время бесконечно малых вероятностей).

<h2 id="Что_насчет_изолированных_действий">Что насчет изолированных действий?</h2>

Идея долгосрочного среднего применима к случаям, когда наши пожертвования или действия являются частью более крупного ансамбля действий. Но что, если это не так? Что, если мы столкнемся с одиночной ситуацией «все или ничего», в которой мы не можем быть уверены, что за счет закона больших чисел все в целом пойдет хорошо?

<div class="message"><i>Сценарий.</i> Вы – единственный сентиентный организм во Вселенной, но вы узнаете, что завтра в 5 часов вечера 2 миллиона человек появятся на час, подвергнутся жестоким пыткам, а потом снова исчезнут. Никаких других сентиентных организмов после этого существовать не будет.<br><br> Вы обнаруживаете некую коробку с двумя кнопками – красной и синей. Красная Кнопка, если ее нажать, имеет шанс один на миллион предотвратить пытки всех двух миллионов человек; вместо этого они появятся на час и прочитают газету, прежде чем исчезнуть. Если нажать Синюю Кнопку, это позволит ровно одному человеку из двух миллионов точно избежать пыток и вместо них прочитать газету. Вы можете нажать только одну кнопку, потому что как только одна из этих двух кнопок будет нажата, коробка навсегда исчезнет.</div>

Здесь аргумент о долгосрочных средних значениях, похоже, не применим, потому что событие не повторяется. Аргумент «голосования» был бы применим, если бы мы могли заранее опросить 2 миллиона человек, которые появятся на свет. Но можно придумать и более сложные мысленные эксперименты, в которых это соображение тоже перестанет работать. На этом этапе я был бы готов просто принять критерий ожидаемой полезности как аксиоматическую интуицию: потенциальное благо, достигаемое Красной Кнопкой, настолько велико, что нельзя упускать шанс на него. Однако ниже я рассматриваю два дополнительных аргумента.

<h2 id="Аргумент_1">Аргумент 1: Многомировая интерпретация квантовой механики</h2>

[Многомировая интерпретация](http://plato.stanford.edu/entries/qm-manyworlds/) (ММИ) квантовой механики пользуется [сравнительно большой поддержкой](http://www.hedweb.com/everett/everett.htm#believes) среди определенных групп физиков и представляет, как я считаю, более последовательную точку зрения, чем [копенгагенская интерпретация](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BF%D0%B5%D0%BD%D0%B3%D0%B0%D0%B3%D0%B5%D0%BD%D1%81%D0%BA%D0%B0%D1%8F_%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B0%D1%86%D0%B8%D1%8F). Согласно ММИ выглядящие случайными квантовые события не определяют конкретный результат измерения; вместо этого _все_ возможные исходы реализуются в разных параллельных мирах. Например, если мы поместим [кота в коробку](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D1%82_%D0%A8%D1%80%D1%91%D0%B4%D0%B8%D0%BD%D0%B3%D0%B5%D1%80%D0%B0), подключенную к машине с ядовитым газом, запускаемой счетчиком Гейгера, это не значит, что кот погибнет с вероятностью 50%; это значит, что есть два разных мира-ветви, в одном из которых кот действительно умирает. Таким образом, ожидаемое значение (расчитанное с использованием распределения вероятностей, соответствующего долям различных реализующихся миров) не просто отражает то, что может произойти: оно фактически _подсчитывает_ то, что происходит на самом деле. Значит если эффективность Красной Кнопки в предыдущем примере определяется квантовым исходом, тот факт, что это действие «однократно», не имеет значения: в небольшой части миров вы действительно предотвращаете все 2 миллиона случаев пыток!

Есть две оговорки. Во-первых, наивная картина подсчета «количества миров» не совсем верна — см., например, «[Understanding Deutsch's Probability in a Deterministic Multiverse](http://arxiv.org/PS_cache/quant-ph/pdf/0312/0312136v2.pdf)» Хилари Гривс (2004), разд. 5.3. Что на самом деле подсчитывается, так это _меры_, заданные [правилом Борна](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D0%BE_%D0%91%D0%BE%D1%80%D0%BD%D0%B0). Но тут возникает вопрос о том, [что же такое мера](http://web.archive.org/web/20200615031755/https://possiblyphilosophy.wordpress.com/2008/09/02/uncertainty-in-the-many-worlds-theory/) и [как обосновать использование борновских вероятностей](http://philsci-archive.pitt.edu/archive/00002654/01/WallaceGreavesComments.pdf) вместо каких-либо других мер (например, [основанной на нечетном количестве носков](http://philsci-archive.pitt.edu/3103/2/pitei.pdf) — см. разд. 3.2). В самом деле, Гривc (2004) делает вывод, что использование вероятностей Борна в теории принятия решений, возможно, нужно воспринимать просто «как нечто вроде примитива» (стр. 34), что возвращает нас к исходному вопросу (почему именно ожидаемое значение?), если только не могут быть представлены какие-то другие интуиции, основанные на ММИ.

Во-вторых, даже если мы согласимся с тем, что нам следует использовать вероятности по правилу Борна, это применимо только к _физическим_ неопределенностям, — например, будет ли электрон измерен со спином вверх или вниз, или сработают ли нейроны в моем мозгу так, чтобы заставить меня съехать на обочину дороги. В идеале мы хотели бы максимизировать «ожидаемые значения», рассчитанные в соответствии с истинными мерами разных миров по правилу Борна. Но наши распределения вероятностей не идеальны: большая часть нашей неопределенности в отношении будущего связана не с квантовым расщеплением, а просто с нашим собственным невежеством, которое может и близко не соответствовать истинному распределению меры на исходах. Более того, мы можем назначать вероятности чему-либо на мета-уровне, и они вообще не относятся к конкретным исходам (Например, какова вероятность того, что ММИ ложна? Или насколько вероятно, что тот или иной закон физики верен?). Обоснование максимизации ожидаемого значения с помощью ММИ справедливо лишь в той степени, в какой наши субъективные распределения вероятностей соответствуют истинным квантовым мерам.

<h2 id="Аргумент_2">Аргумент 2: Утилитаризм правил</h2>

Как правило, если бы _все_ следовали совету выбирать действие с максимальной ожидаемой полезностью, то из закона больших чисел следовало бы, что это будет иметь наилучшие последствия, даже если какое-то отдельное действие не приводит к желаемому результату. Мы должны быть тем изменением, которое хотим видеть в мире, и подавать пример, сами следуя этому правилу.

Применительно к предыдущему примеру с Красной Кнопкой мы можем сказать, что даже если это единственный раз, когда у вас будет возможность нажать кнопку и тем самым потенциально предотвратить пытки, вам хотелось бы, чтобы другие в подобных ситуациях вели себя так же, как и вы, потому что в совокупности по всем таким ситуациям это предотвратит пытки большего количества людей.

Соответственно, мы должны хвалить людей [за то](https://reducing-suffering.org/instrumental-judgment-and-expectational-consequentialism/), что они в тот или иной момент считали действием, имеющим наибольшую ожидаемую полезность, даже если им не повезло с фактическим результатом.

<h2 id="Логическая_неопределенность">Логическая неопределенность</h2>

Приведенные выше аргументы не охватывают _все_ случаи неопределенности. Так, вы можете не быть уверены в логической истине вроде [P = NP](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B2%D0%B5%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%BE%D0%B2_P_%D0%B8_NP), но ответ одинаков при любых обстоятельствах, для каждого человека, в любом возможном мире. Большие числа, квантовая неопределенность и утилитаризм правил здесь не помогут.

Конечно, нужно помнить, что нет такой вещи, как объективная вероятность: «реальная» вероятность равна 1 для того, какой мультивселенная является и 0 для всего, чем она не является. Вероятности — это инструменты, которые мы используем для выражения нашего собственного невежества, и о них удобно думать так, как будто они представляют собой «реальную случайность» различных результатов (хотя нет такой вещи как «реальная случайность»). Таким образом, даже если вы сделаете ставку, основанную на возможности того, что P = NP, и предположение окажется ложным, это может быть скомпенсировано тем, что кто-то другой в другом мире сделает другую ставку, основанную на возможности того, что гипотеза Римана ложна, когда в реальности она окажется правдой. (Это всего лишь примеры. [Ни один из этих вопросов](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B8_%D1%82%D1%8B%D1%81%D1%8F%D1%87%D0%B5%D0%BB%D0%B5%D1%82%D0%B8%D1%8F) до сих пор не решен.) Устроит ли вас такой обмен логическими ошибками, отчасти зависит от того, сколько поставлено на карту на основе логической ставки и насколько эти ставки коррелируют между мирами.

Лично я считаю просто интуитивно понятным, что величина важности чего-либо должна линейно зависеть от его вероятности. С этой точки зрения максимизация ожидаемой полезности не нуждается в дальнейшем обосновании; ожидаемая полезность это просто _то_, насколько для меня важен возможный исход.

Кроме того, аргумент «голосования», приведенный в начале этой статьи, все еще _применим_ к таким случаям, как ставка на P = NP, — по крайней мере, если «вероятность того, что вам помогут» оценивается с использованием субъективной вероятности того, что P = NP с точки зрения того, кто помогает. Например, предположим, что вероятность того, что P = NP, равна 5%. Действие A помогло бы каждому из 100 человек получить некоторую фиксированную сумму, если P = NP, и никому не помогло бы, если P != NP. Действие B помогло бы двум людям на ту же самую фиксированную сумму, если P != NP, и не помогло бы никому, если P = NP. Из большого числа N людей, нуждающихся в помощи, вероятность того, что человеку поможет действие A, равна 5% \* (100/N) = 5/N. Вероятность того, что человеку поможет действие B, составляет всего 95% * (2/N) = 1.9/N.

---

<h2 id="Сноски">Сноски</h2>

<a name="footnotea"></a>a. На математическом языке это означает, что мы рассматриваем [пространство элементарных событий](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D1%8D%D0%BB%D0%B5%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%80%D0%BD%D1%8B%D1%85_%D1%81%D0%BE%D0%B1%D1%8B%D1%82%D0%B8%D0%B9) из возможных миров (например, в одном возможном мире может быть котенок, спасенный с дерева, тогда как в другом возможном мире тот же котенок не будет спасен). Дальше мы строим [целевую функцию](https://ru.wikipedia.org/wiki/%D0%9E%D0%BF%D1%82%D0%B8%D0%BC%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)), которая отображает наше пространство элементарных событий во множество вещественных чисел (или, может быть, [гипервещественных](https://ru.wikipedia.org/wiki/%D0%93%D0%B8%D0%BF%D0%B5%D1%80%D0%B2%D0%B5%D1%89%D0%B5%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B5_%D1%87%D0%B8%D1%81%D0%BB%D0%BE), или в другое [упорядоченное поле](https://ru.wikipedia.org/wiki/%D0%A3%D0%BF%D0%BE%D1%80%D1%8F%D0%B4%D0%BE%D1%87%D0%B5%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BF%D0%BE%D0%BB%D0%B5)). Затем мы рассматриваем некоторый набор (для простоты предполагающийся конечным) возможных действий, которые мы можем предпринять. Для каждого действия мы присваиваем нашему пространству элементарных событий субъективное распределение вероятностей, которое учитывает разные возможные результаты выполнения этого действия (например, если наше действие — вызов пожарных, то распределение вероятностей будет говорить о том, насколько вероятно, что они спасут котенка). Итак, для каждого действия наша целевая функция становится случайной величиной. Стандартная теория принятия решений гласит следующее: если для каждого действия целевая функция имеет конечное математическое ожидание, то выбирайте действие, ожидание которого максимально ("ожидаемое значение" случайной величины — это тоже самое, что ее "[математическое ожидание](https://ru.wikipedia.org/wiki/%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BE%D0%B6%D0%B8%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5)" — прим. пер.).

Если мы гедонистические [утилитаристы](https://reducing-suffering.org/a-short-introduction-to-utilitarianism/), то наша целевая функция отображает множество возможных миров во множество кардинальных значений полезности (конкретно в этом случае полезность будет определяется через [благополучие](https://plato.stanford.edu/entries/well-being/) [сентиентных](https://www.animal-ethics.org/what-is-sentience/) существ; но вообще говоря, термин "полезность" в [теориях принятия решений](https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq) применяется в более широком смысле, просто численно выражая важность последствий с точки зрения агента — прим. пер.).  (<a href="#citationa">назад</a>)

<a name="footnoteb"></a>b. Технически это [слабый закон больших чисел](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D1%87%D0%B8%D1%81%D0%B5%D0%BB#%D0%A1%D0%BB%D0%B0%D0%B1%D1%8B%D0%B9_%D0%B7%D0%B0%D0%BA%D0%BE%D0%BD), который справедлив в большем количестве случаев, чем сильный закон.  (<a href="#citationb">назад</a>)

<a name="footnotec"></a>c. Это число легко вычисляется с помощью [нормального приближения к биномиальному распределению](http://web.archive.org/web/20180311165807/http://faculty.chas.uni.edu/~campbell/stat/prob8.html). При использовании ДешевоОблегчина, mu = 0.5\*10000 = 5000, sigma = \[10000\*0.5\*(1-0.5)\]<sup>(1/2)</sup> = 50, z = (4900 - 5000)/50 = -2. Вероятность того, что стандартная нормальная случайная величина будет меньше -2, составляет 2.3%.  (<a href="#citationc">назад</a>)

<a name="footnoted"></a>d.  Рассмотрим разницу двух случайных величин: одной биномиальной (10 000, 0.5) и другой биномиальной (5 000, 0.5). Вероятность того, что смешанная стратегия окажется лучше, равна вероятности того, что разница между этими двумя величинами будет меньше 2450. Аппроксимируем обе как независимые нормально распределенные величины. Разница между ними имеет дисперсию, равную сумме их дисперсий: 10000\*0.5\*(1-0.5) + 5000\*0.5\*(1-0.5), откуда следует что sigma = 61.2, mu = 2500. Наша вероятность — это вероятность того, что стандартная нормальная случайная величина будет меньше -0.816.  (<a href="#citationd">назад</a>)