---
layout: article
title: "Для предсказания будущего неважно, какова моральная истина"
authors:
  - Джим Бюлер
original_date: 2023.04.09
original: https://forum.effectivealtruism.org/s/wmqLbtMMraAv5Gyqn/p/hat6TafzAoDx97N6j
translated_by: К. Кирдан
math: true
preview: "https://res.cloudinary.com/cea/image/upload/c_fill,ar_1.91,g_auto/SocialPreview/o16nyr34czgsc3lyrjwb"
---
Многие лонгтермисты питают надежду, что наши потомки (или любая продвинутая цивилизация/сверхинтеллект) в конечном итоге будут действовать в соответствии с какой-то моральной истиной[^1]. Хотя я симпатизирую некоторым формам морального реализма, я считаю такой сценарий довольно маловероятным для любой цивилизации, и тем более — для самых продвинутых/экспансионистских. Этот пост кратко объясняет, почему.

Чтобы было понятно: мой аргумент ни в коем случае не значит, что мы не должны действовать в соответствии с тем, что считаем моральной истиной. Я просто утверждаю, что мы не можем полагаться на то, что наши потомки — или любая могущественная цивилизация — будут поступать «объективно правильно». И это важный момент для расстановки приоритетов с точки зрения лонгтермизма.

***Эпистемический статус:*** _Поскольку я считаю идеи этого поста менее важными, чем те, что будут обсуждаться в следующих постах этой серии, я написал его быстро и не просил никого провести тщательный анализ перед публикацией. Поэтому я думаю, что мог упустить какие-то важные соображения с большей вероятностью, чем обычно. Дайте знать, что вы думаете!_

***Обновление от 10 апреля:*** _Когда я впервые опубликовал это, заголовок был «Неважно, какова моральная истина». Я понял, что он вводил в заблуждение. Казалось, что я выдвигаю сильное нормативное утверждение о том, что важно, в то время как моя реальная цель заключалась в предсказании того, что может произойти. Так что я поменял заголовок._

## Мало кто в конечном итоге будет действовать в соответствии с какой-либо моральной истиной

Для того, чтобы агенты (субъекты) делали то, что объективно лучше всего, необходимо соблюдение всех следующих условий:

- Существует моральная истина.
- Возможно «найти» её и признать таковой.
- Они находят что-то, что признают моральной истиной.
- Они (безоговорочно) принимают её, даже если она кажется им крайне контринтуитивной.
- То, что они нашли, действительно является моральной истиной. Никакой нормативной ошибки.
- Им удаётся действовать в соответствии с этой истиной. Никаких практических ошибок.
- Они удерживают это навсегда. Никакого дрейфа ценностей.

Я считаю, что в общем случае вероятность одновременного выполнения всех этих семи условий крайне мала, в основном по следующим причинам:

- (К условию #1) Хотя я нахожу убедительным аргумент о том, что (некоторые из) наших субъективных переживаний являются воплощением объективно отрицательной ценности (см. [Rawlette 2016](https://www.amazon.com/Feeling-Value-Grounded-Phenomenal-Consciousness/dp/1534768017); [Vinding 2014](https://www.amazon.co.uk/Moral-Truths-Foundation-Magnus-Vinding-ebook/dp/B00P4MNBF0)), я очень скептично отношусь к утверждениям о моральных истинах, которые не полностью зависят от сентиентности.
- (К #2) Я не вижу причин, почему мы должны предполагать, что возможно «найти» (с достаточной степенью уверенности) моральную истину, особенно если она более сложна, чем что-то вроде «удовольствие — это хорошо, а страдание — плохо» или и вовсе отлична от этой.
- (К #3 и #4) Если они «найдут» моральную истину и им не понравится то, что она предписывает, они вполне могут не действовать в соответствии с ней?[^2]
- (К #3, #4, #5 и #7) В рамках цивилизации следует ожидать, что отбор будет в конечном итоге благоволить агентам с ценностями, наиболее приспособленными к выживанию, размножению и экспансии (см., напр., [Bostrom 2004](https://nickbostrom.com/fut/evolution); [Hanson 1998](https://mason.gmu.edu/~rhanson/filluniv.pdf)), и у меня нет оснований предполагать, что моральная истина особенно хорошо приспособлена к этому всему.

## Даже если такие агенты не редки, их влияние останется незначительным

Теперь предположим, что много умных агентов приходит к какой-то единой моральной истине и эффективно оптимизирует свои действия в соответствии с ней. Однако по причинам, аналогичным тем, что обсуждались в предыдущем пункте, можно ожидать, что цивилизации или группы/индивиды внутри цивилизаций, которые примут моральную истину, будут менее конкурентоспособными по сравнению с теми, кто придерживается ценностей, наиболее способствующих адаптации и приспособленных к гонке в колонизации космоса.

В моем [следующем посте](jim-buhler-the-grabby-values-selection-thesis.html) этот эффект отбора исследуется более детально, но вот пример для размышлений: предположим, что Дания хочет следовать моральной истине, которая заключается в максимизации суммы $X − Y$, где $X$ — это что-то желательное (положительно ценное), а $Y$ — что-то нежелательное (отрицательно ценное). В это время Франция просто хочет «занять как можно больше космического пространства». Пока датчане сталкиваются с выбором между (A) как можно более быстрым распространением и созданием военного оружия/обороны и (B) инвестированием в «безопасность колонизации»[^3], чтобы убедиться, что они действительно оптимизируют свои действия в соответствии с моральной истиной, французы не сталкиваются с этой дилеммой и могут полностью сосредоточиться на варианте (A), что даёт им эволюционное преимущество. Значительность этого эффекта отбора зависит от того, входит ли моральная истина в число таких возможных целей цивилизаций, которые наиболее «способствуют экспансии» этих цивилизаций, или в число близких к ним. И я сомневаюсь, что моральная истина такова.

## Заключение

Действия в соответствии с некой моральной истиной требуют успешного выполнения последовательности многих неочевидных шагов, что маловероятно.

Кроме того, ценности не появляются из ниоткуда. Они являются продуктом эволюционных процессов. Следует ожидать, что наиболее приспособленные к выживанию ценности будут представлены в наибольшей степени, по крайней мере среди самых экспансионистских обществ. И похоже, что истинность моральной теории слабо связана с её конкурентоспособностью[^4], так что у нас нет предварительных оснований полагать, что (наиболее могущественные) цивилизации или агенты будут поступать объективно правильно.

Если я более-менее прав, **это значит, что аргумент об «открываемой моральной реальности», который выдвигают в пользу того, что будущее будет хорошим** (см. [Anthis 2022](https://forum.effectivealtruism.org/posts/WebLP36BYDbMAKoa5/the-future-might-not-be-so-great#Discoverable_Moral_Reality)), **— довольно слаб**. Также это может нести более непосредственные следствия для расстановки приоритетов в лонгтермизме, которые будут рассмотрены в следующих постах этой серии.

## Благодарности

До сих пор моя работа над этой цепочкой финансировалась [Existential Risk Alliance](https://erafellowship.org/).

Все допущения/утверждения/упущения являются моими.

## Сноски

[^1]: Основываюсь на неформальных взаимодействиях, которые у меня были, а также на воспоминаниях об утверждениях, сделанных в каких-то подкастах, которые я не могу вспомнить. На удивление, я не смог найти ничего, что подробно бы освещало именно эту идею, и не думаю, что стоит тратить больше времени на поиски. Пожалуйста, поделитесь в комментариях, если у вас есть какие-либо мысли по этому поводу!

[^2]: Интересно, что Брайан Томасик ([2014](https://reducing-suffering.org/why-the-modesty-argument-for-moral-realism-fails/)) пишет: «Лично мне не особо важно, какова моральная истина, даже если она существует. Если бы моральная истина была опубликована в книге, я прочитал бы эту книгу из любопытства, но не чувствовал бы себя обязанным следовать её указаниям. Вместо этого я продолжал бы делать то, что меня больше всего эмоционально волнует.»

[^3]: После проведения тщательных оценок они могут даже осознать, что лучший способ максимизировать полезность для них заключается в том, чтобы избегать колонизации космоса (например, потому что ожидаемая отрицательная ценность конфликта с Францией или [с инопланетными цивилизациями](https://www.youtube.com/watch?v=jMouMl7RHk0) слишком высока).

[^4]: В [этой ветке комментариев](https://forum.effectivealtruism.org/posts/hat6TafzAoDx97N6j/it-doesn-t-matter-what-the-moral-truth-might-be?commentId=qKLdydHJ9cBZXTFfZ) обсуждается интересный аргумент Вэй Дая, который ставит под сомнение данное утверждение.
