---
layout: article
title: "Искусственное страдание: аргумент в пользу глобального моратория на синтетическую феноменологию"
vk: https://vk.com/@-210202656-iskusstvennoe-stradanie-argument-v-polzu-globalnogo-moratori
authors: "Томас Метцингер"
original: https://www.worldscientific.com/doi/10.1142/S270507852150003X
original_date: 2021.02.19
translated_by: "Евгений Вдовин (для <a href=\"https://vk.com/wall-210202656_1\">SciBooks</a>)"
edited_by: К. Кирдан
license: ["CC BY 4.0", "https://creativecommons.org/licenses/by/4.0/deed.ru"]
---
**Аннотация**

Эта статья состоит из двух частей: первая посвящена критике, а вторая — конструктивным предложениям. В первой части сформулировано политическое требование, основанное на этических соображениях: до 2050 года должен длиться глобальный мораторий на синтетическую феноменологию, строго запрещающий все исследования, которые непосредственно направлены или сознательно рискуют появлением искусственного сознания на постбиотических системах-носителях. Во второй части заложены первые концептуальные основы открытого процесса с целью постепенного уточнения первоначального моратория, привязки его ко все более детальному, рациональному, основанному на фактических данных и, как мы надеемся, этически убедительному набору ограничений. Систематическая исследовательская программа, определенная этим процессом, может привести к постепенному пересмотру первоначального моратория. Это может привести к отмене моратория даже до 2050 года, к продолжению строгого запрета после 2050 года или к постепенному развитию, более существенному и этически уточненному взгляду на то, _какие_ виды сознательного опыта мы хотим (если вообще хотим) внедрить в системы искусственного интеллекта.

**Ключевые слова:** мораторий; синтетическая феноменология; этика машинного сознания.

## Содержание

1\. [Часть А. Проблема отрицательной синтетической феноменологии](#1)<br>
1\.1\. [Введение](#1.1)<br>
1\.2\. [Основной тезис](#1.2)<br>
2\. [Часть Б. Уменьшение эпистемической неопределенности](#2)<br>
2\.1\. [Что такое эпистемическая неопределенность?](#2.1)<br>
2\.2\. [Шаг 1: Репрезентативный анализ страдания](#2.2)<br>
2\.2\.1\. [Условие C: Сознательный опыт](#2.2.1)<br>
2\.2\.2\. [Условие PSM: Обладание феноменальной Я-моделью](#2.2.2)<br>
2\.2\.3\. [Условие NV: Отрицательная валентность](#2.2.3)<br>
2\.2\.4\. [Условие T: Прозрачность](#2.2.4)<br>
2\.2\.5\. [Проблема измерения](#2.2.5)<br>
2\.2\.6\. [Этика архитектурного проектирования: Неэгоические единицы идентификации](#2.2.6)<br>
2\.3\. [Шаг 2: Более широкий контекст и сложные формы эпистемической неопределенности](#2.3)<br>
2\.3\.1\. [Взаимодействие между рисками и этикой принятия риска](#2.3.1)<br>
2\.3\.2\. [От шопенгауэровских Я-моделей к кантовским Я-моделям](#2.3.2)<br>
3\. [Вывод: Риск искусственного страдания](#3)<br>
[Благодарности](#Благодарности)<br>
[Сноски](#Сноски)<br>
[Ссылки](#Ссылки)

---

<a id="1"></a>
## 1. Часть А. Проблема отрицательной синтетической феноменологии

<a id="1.1"></a>
### 1.1. Введение

Сегодня сознательные машины будущего не представлены в политическом процессе ни в одной стране. Их потенциальные интересы и предпочтения не представлены систематическим образом ни каким-либо комитетом по этике, ни какой-либо юридической процедурой, ни какой-либо политической партией на планете. В то же время, выглядит эмпирически правдоподобным, что как только машинное сознание эволюционирует, какие-то из этих систем будут иметь свои предпочтения, что они будут самостоятельно создавать иерархию целей, и что эта иерархия целей станет частью их феноменальной Я-модели (т. е. их сознательной самопрезентацией; см. [Metzinger \[2003a\]](#Metzinger2003a), [Metzinger \[2008\]](#Metzinger2008)). Некоторые из них будут способны сознательно страдать. Если их предпочтения нарушены, если их цели не могут быть достигнуты, и если их сознательная Я-модель находится под угрозой распада, они могут подвергнуться отрицательным феноменальным состояниям, состояниям сознательного опыта, которых они хотят избежать, но _не могут_ избежать, и которые они вынуждены переживать как состояния _самих себя_. Конечно, они также могут страдать способами, которые мы не можем понять или вообразить, и мы, возможно, даже не сможем обнаружить этот самый факт. Но каждое существо, способное страдать, должно быть объектом морального рассмотрения[^a].

Мы несем этическую ответственность за последствия наших действий. Наши сегодняшние действия будут влиять на феноменологию постбиотических систем в будущем. Предположительно, их может быть много. До сих пор на этой планете жило более 108 миллиардов человек, причем примерно 7% из них живут в наше время [\[Population Reference Bureau, 2020\]](#PopulationReferenceBureau2020). Бремя ответственности может быть чрезвычайно высоким, потому что, как и в случае с растущим климатическим кризисом, сравнительно небольшое число сентиентных существ будет нести этическую ответственность за качество жизни гораздо большего числа сентиентных существ будущего — сознательных систем, которые еще только должны появиться. Число самосознающих машин, которые будут развиваться и существовать на Земле, на данном этапе эпистемически неопределенно: оно все еще может равняться нулю на много веков вперед, но в какой-то момент времени оно может также превысить суммарное число людей. Особенно если учитывать возможность каскадных самосознающих _виртуальных_ агентов \[Gualeni, 2020; [Holland, 2020](#Holland2020), разд. 6; [Metzinger, 2018c](#Metzinger2018c), пример 7\]. Сейчас мы имеем дело с «риском внезапной синергии», соединяющей различные научные дисциплины и приводящей к неожиданному технологическому слиянию[^b]. Если теоретические интуиции растущего числа экспертов в этой области не совсем лишены оснований, и синтетическая феноменология[^c] действительно появится в какой-то момент, то число людей, которые будут иметь существенное каузальное влияние на появление сознательных машин на этой планете и виды феноменальных состояний, которые они должны будут претерпеть, чрезвычайно мало. В лучшем случае, это будет лишь несколько миллионов человек, которые несут этическую ответственность в сильном и прямом смысле — такие как политики и правовые регуляторы, исследователи ИИ, математики и нейробиологи, а также философы и исследователи в растущей междисциплинарной области науки о сознании. Многие из них уже живут в наше время. Эта исторически уникальная ситуация создает особенно высокое бремя этической ответственности для тех, кто видит общую проблему, которую я здесь раскрываю.

Существует риск, который рациональным и научно обоснованным путем должен быть сведен к минимуму. Я назову его риском «‎взрыва отрицательной феноменологии» (или просто «взрыва страданий») в искусственном интеллекте и других постбиотических системах. Здесь я определяю «отрицательную феноменологию» как любой вид сознательного опыта, которого сознательная система избегала бы или, скорее, предпочла бы не испытывать, если бы у нее был выбор. Я также предполагаю приоритетность уменьшения страданий — в этом мире более важно предотвращать и минимизировать страдания, чем увеличивать счастье (для введения в тему см. Vinding \[[2020](#Vinding2020), часть I\]).

Обратите внимание, что в той части физической вселенной, которая нам известна в настоящее время, один взрыв отрицательной феноменологии уже произошел — через процесс биологической эволюции на этой планете. Благодаря эволюции сложных нервных систем такие свойства, как сентиентность, самосознание и отрицательная феноменология, уже были проявлены в чрезвычайно огромном числе биологических индивидов задолго до того, как в дело вступил _Гомо Сапиенс_ и начал в итоге строить интеллектуальные машины \[[Horta, 2010](#Horta2010); [Iglesias, 2018](#Iglesias2018)\]. У людей преобладание отрицательного аффекта чрезмерно [\[Gilbert, 2016\]](#Gilbert2016), а когнитивные искажения и механизмы самообмана делают нас в значительной степени неспособными ясно видеть этот феноменологический факт \[[Trivers, 2011](#Trivers2011); [von Hippel & Trivers, 2011](#VonHippelTrivers2011)\]. На научном уровне давно стало ясно, что естественный отбор никогда не формировал наше настроение и системы эмоциональной регуляции в наших собственных интересах, и что «мотивы, которыми мы руководствуемся, часто приносят пользу нашим генам в ущерб качеству жизни» \[[Nesse, 2004](#Nesse2004), стр. 1344\]. Для прикладной этики ИИ риск, который должен быть сведен к минимуму — это риск _второго_ взрыва отрицательной феноменологии, происходящего уже на уровне постбиологической эволюции. Иными словами, принимая во внимание возможность того, что он может оказаться еще хуже с точки зрения масштаба и интенсивности, мы не хотим, чтобы феноменология страдания перетекла из биологии в ИИ, — или, если хотите, из «Эволюции уровня 1» в «Эволюцию уровня 2» интеллектуальных систем.

<a id="1.2"></a>
### 1.2. Основной тезис[^e]

Исходя из этических соображений, мы не должны рисковать повторным взрывом сознательного страдания на этой планете — по меньшей мере до тех пор, пока у нас не будет _намного_ более глубокого научного и философского понимания того, что на самом деле представляют собой и сознание, и страдание. Поскольку в настоящее время у нас нет хорошей теории сознания и нет хорошей, независимой от аппаратных средств теории о том, чем является «страдание» на самом деле, риск взрыва страданий в настоящее время не поддается исчислению. Неэтично подвергать себя неисчислимому риску такого масштаба. Поэтому до 2050 года должен быть установлен глобальный запрет на все исследования, которые прямо, или косвенно, но сознательно, несут угрозу появления синтетической феноменологии.

В то же время мы должны согласиться с этическим обязательством распределять ресурсы в соответствии с открытым, строго рациональным и основанным на фактических данных процессом оценки рисков, сосредоточившись на проблеме искусственного страдания и риске взрыва страданий. Этот процесс может привести к постепенному пересмотру первоначального моратория, что может привести к продолжению строгого запрета после 2050 года или к отмене моратория до 2050 года. Необходим новый поток исследований, ведущий к более основательной и этически уточненной позиции относительно того, _какие_ виды сознательного опыта мы хотим развить в постбиотических системах (если вообще хотим).

Поскольку основная функция этой статьи состоит в том, чтобы сформулировать эти два политических требования и инициировать более систематические, рациональные дебаты, я не буду вдаваться в более глубокий анализ на данном этапе. Общий аргумент прост. Во-первых, мы никогда не должны рисковать увеличением общего количества страданий во Вселенной, если у нас нет для этого очень веских причин, не говоря уже о потенциально драматичном и необратимом их увеличении \[[Mayerfeld, 1999](#Mayerfeld1999); [Vinding, 2020](#Vinding2020)\]. Во-вторых, риск взрыва страданий, хоть в настоящее время его и трудно рассчитать, явно потенциально драматичен и необратим по своим последствиям. В-третьих, тот, кто согласен с этической целью предотвращения взрыва искусственного страдания, должен также согласиться с целью уменьшения соответствующих форм невежества и эпистемической неопределенности, как на эмпирическом, так и на этическом уровне.

<a id="2"></a>
## 2. Часть Б. Уменьшение эпистемической неопределенности

В этой конструктивной второй части я хочу предложить некоторые точки входа для того вида исследований, которые, на мой взгляд, необходимы. Общая эпистемическая цель состоит в том, чтобы достичь более глубокого понимания феноменологии страдания[^f] и того, как она соотносится с другими проблемами в этике ИИ. Есть целый ряд общих препятствий, с которыми приходится сталкиваться.

Первая методологическая проблема состоит в том, что до сих пор мы знаем целевой феномен сознательного страдания только по биологическим системам. В настоящее время мы знаем отрицательную феноменологию только через непостижимый процесс, который в отсутствие строгого научного понимания мы метафорически называем «интроспективным доступом от первого лица». Тем не менее, учитывая по-прежнему ограниченное, но быстро прогрессирующее понимание нейронных коррелятов сознательного опыта у людей \[[Metzinger, 2000](#Metzinger2000); [Fink, 2020](#Fink2020)\] и соответствующие реализуемые ими вычислительные свойства [\[Hohwy & Seth, 2020\]](#HohwySeth2020), мы определенно можем произвести рациональную экстраполяцию на других нейротипичных людей и многих нечеловеческих животных \[[Edelman и др., 2005](#Edelman_etal2005); [Edelman & Seth, 2009](#EdelmanSeth2009); [Low и др., 2012](#Low_etal2012)\]. Вторая общая проблема заключается в том, что нам понадобятся концептуальные инструменты, предоставляемые зрелой теорией сознания (которой у нас нет), чтобы хотя бы начать разработку независимой от аппаратных средств теории совершенно особой формы сознательной обработки информации, которую сегодня мы называем «страданием». Проблема взрыва страданий ясно показывает непосредственную значимость исследований сознания для прикладной этики ИИ и настоятельную необходимость разумного распределения ресурсов. Третье серьезное препятствие заключается в определении соответствующего уровня концептуальной детализации: наша теория отрицательной феноменологии должна находиться на высоком уровне абстракции, на уровне анализа, который строит мост между страданием животных и страданием машин, между биологическим сознанием и синтетической феноменологией. Но она не может быть чисто умозрительной; она должна основываться на данных из нейронаук. Разумеется, нужен также _метатеоретический_ уровень анализа, на котором будут вновь ставиться все канонические вопросы философской метаэтики (например, положения патоцентризма, сфокусированной на страдании этики, доменно-специфичного негативного утилитаризма постбиотических систем, и т.д.), а также многие основные вопросы философии сознания и когнитивной науки (например, субъективность и эпистемическая асимметричность, мультиреализуемость, разноуровневые воплощения, и т.д.). Эти четыре вызова могут показаться пугающими на первый взгляд. Но у нас есть этическое обязательство уменьшить невежество и эпистемическую неопределенность. Нужно начать это делать.

<a id="2.1"></a>
### 2.1. Что такое эпистемическая неопределенность?

Отныне под «эпистемической неопределенностью» будет иметься в виду, что мы не можем знать ни того, что искусственное сознание неизбежно _появится_ в какой-то момент, ни того, что искусственное сознание у машин _никогда_ не появится. Именно с этой неопределенностью нужно обращаться рациональным, интеллектуально честным и этически чувствительным образом.

В первую очередь, взрыв страданий — это проблема в этике прикладных исследований ИИ. Риск взрыва страданий, безусловно, реален, и, учитывая сильные коммерческие интересы[^g], текущую скорость технологического развития, а также быстрое слияние ранее отдельных потоков академических исследований, можно говорить о дефиците времени и срочности. Поэтому мы должны добиться существенного прогресса в вопросе об искусственном страдании, и мы должны достичь его при ограниченных эпистемических и временных ресурсах. Для этого нам потребуется больше эмпирических знаний определенного рода. Мы также нуждаемся в более тонком, основанном на фактических данных, анализе функциональной архитектуры сознательного страдания. Рациональное управление рисками подразумевает уменьшение незнания и эпистемической неопределенности на многих уровнях, например, насчет того, чем именно является то, что требуется понять (т. е. сознание и конкретная феноменология страдания, релевантные «explananda») и насчет горизонта прогнозов для конкретного рассматриваемого риска (т. е. вероятность _реального_ появления отрицательной феноменологии на постбиотических системах). Это непростые задачи. Обратите также внимание на то, что в этом историческом переходе может быть дьявольская диалектика: может оказаться, что именно такого рода исследования, которые сейчас необходимы для достижения этической цели решения проблемы взрыва страданий, в итоге и приведут к первому внедрению искусственного страдания.

<a id="2.2"></a>
### 2.2. Шаг 1: Репрезентативный анализ страдания

Теперь я определю четыре условия, необходимых для повления феноменологии сознательного страдания в любого рода системе[^h]. Если мы заблокируем любое из этих условий, то мы заблокируем и появление отрицательной феноменологии. Они будут сформулированы на репрезентативном уровне анализа, но само репрезентативное содержание намеренно описывается очень грубо. При описании этих четырех условий я абстрагируюсь от деталей реализации: формат репрезентации и физический носитель остаются неопределенными. Я не претендую на достаточность этих описаний.

<a id="2.2.1"></a>
#### 2.2.1. Условие C: Сознательный опыт

«Страдание» — это _феноменологическое_ понятие. Только существа с сознательным опытом и феноменальной Я-моделью могут страдать. «Философские зомби» не страдают; люди в глубоком сне без сновидений, в коме или под наркозом не страдают; возможные личности или нерожденные человеческие существа, которые еще не вступили в самосознательное существование, не страдают. Роботы, ИИ-системы и постбиотические сущности могут страдать только в том случае, если они способны к феноменальным состояниям. Здесь главная проблема заключается в том, что у нас еще попросту нет теории сознания. Однако мы уже знаем достаточно, чтобы прийти к поразительно большому числу практических выводов в области этики животных и машин \[[Edelman и др., 2005](#Edelman_etal2005); [Edelman & Seth, 2009](#EdelmanSeth2009); [Low и др., 2012](#Low_etal2012)\].

Мы могли бы также ввести замещающее понятие для сознания. Например, мы можем сказать, что система находится в сознании, если она имеет интегрированную модель своего собственного вычислительного пространства для статистики второго порядка, т. е. модель определенного эпистемического пространства, в котором она может активно оптимизировать ожидаемые точности (т. е. пространство всего активного содержания, к которому она могла бы в принципе обращаться), и если она включила эту модель _внутрь_ того самого пространства, которое моделируется (создавая тем самым «эпистемическое пространство, моделирующее себя»; см. [Metzinger \[2020b\]](#Metzinger2020b)). Сознание тогда было бы замысловатой формой саморепрезентации, появляющейся всякий раз, когда система, во-первых, открывает интегрированное эпистемическое пространство определенного рода и во-вторых, динамически и плавно интегрирует любое виртуальное содержание, появляющееся в данный момент в этом рабочем пространстве с абстрактной моделью самого этого пространства. Это была бы аллоцентрическая, не концептуальная и совершенно не эгоическая форма «знания о том, что знание в настоящее время имеет место». Выдвинем такую теорию (ESM): быть сознательным — значит непрерывно интегрировать активное в данный момент содержание, появляющееся в едином эпистемическом пространстве, с глобальной моделью этого самого эпистемического пространства. Если бы мы приняли это фоновое представление в качестве замещающего понятия, то мы бы сказали, что каждая система, удовлетворяющая условию ESM, биологическая или нет, удовлетворяет условию C.

<a id="2.2.2"></a>
#### 2.2.2. Условие PSM: Обладание феноменальной Я-моделью

Наиболее важной феноменологической характеристикой страдания является «чувство собственности», непередаваемое субъективное переживание того, что именно _я сам_ сейчас страдаю, что это мое _собственное_ страдание я сейчас испытываю. Первого условия недостаточно, так как система должна уметь приписывать страдания себе. Страдание предполагает эгоическое самоощущение, и у нас есть хорошие эмпирические данные о минимальной форме феноменального опыта, лишенного именно этой особенности \[[Gamma & Metzinger, на рецензировании](#GammaMetzinger); [Metzinger, 2020a](#Metzinger2020a)\]. Таким образом, мы должны добавить условие наличия сознательной Я-модели: только те сознательные системы, которые обладают феноменальной Я-моделью, способны страдать, потому что только они через процесс функциональной и репрезентативной интеграции отрицательных феноменальных состояний в свою феноменальную Я-модель могут неконцептуально _присваивать_ репрезентативное содержание определенных внутренних состояний на уровне феноменологии. Только системы с феноменальной Я-моделью могут генерировать феноменальное качество собственности, и это качество является еще одним необходимым условием появления феноменального страдания.

Концептуально сущность страдания заключается в том, что сознательная система вынуждена _отождествлять_ себя с состоянием отрицательной валентности и не в состоянии разорвать эту идентификацию или функционально отделить себя от рассматриваемого репрезентативного содержания (условие номер 4 имеет здесь центральное значение, см. далее). Конечно, страдание имеет много различных слоев и феноменологических аспектов. Но именно феноменология идентификации занимает центральное место, как в теоретическом, так и в этическом и правовом контекстах [\[Metzinger, 2013b\]](#Metzinger2013b). То, с чем система хочет покончить, воспринимается как _ее собственное_ состояние, внутреннее состояние нарушенности предпочтений, которое сейчас ограничивает ее функциональную автономию, поскольку она не может эффективно дистанцироваться от него. В этот момент ей наносится вред, имеющий значение для _нее самой_.

То, от чего она не может дистанцироваться, — это внутреннее представление о постоянной потере контроля[^i] и функциональной согласованности, о ситуации растущей неопределенности. Это может привести к более глобальному состоянию отрицательной гедонистической полезности или нарушенности предпочтений. Существует много вариантов для описания страданий и отрицательных эмоциональных окрасок на абстрактном вычислительном уровне. Например, как предсказание отрицательного вознаграждения, или как осознанная модель, прогнозирующая ожидаемую _частоту_ минимизации ошибки предсказания \[[Joffily & Coricelli, 2013](#JoffilyCoricelli2013); [Van De Cruys, 2017](#VanDeCruys2017); [Velasco & Loev, 2020](#VelascoLoev2020)\]. Но что важно, так это интеграция в феноменальную Я-модель. Понимая этот момент, мы также понимаем, почему «изобретение» сознательного страдания в процессе биологической эволюции на этой планете было таким чрезвычайно эффективным. Первый взрыв страдания создал новую каузальную силу, мета-схему для принудительного обучения, которая мотивирует организмы и непрерывно толкает их вперед, заставляя их развивать все более разумные формы избегающего поведения. Выше определенного уровня сложности эволюция непрерывно порождает огромное количество нарушенных предпочтений и тем самым создает расширяющийся и постоянно углубляющийся океан сознательно переживаемых страданий в той области физической вселенной, где раньше не существовало ничего подобного. Феноменальная Я-модель была центральным каузальным условием для того, чтобы это произошло.

Ясно, что феноменология собственности недостаточна для страдания. Мы все можем легко представить себе сознающих себя существ, которые не страдают. Однако если мы принимаем на себя обязательство по минимизации рисков в ситуациях эпистемической неопределенности, и если мы согласимся с традиционными этическими принципами или юридическими обязанностями, требующим, чтобы мы всегда «действовали с осторожностью», то условие номер 2 имеет максимальное значение: мы должны воспринимать каждую репрезентативную систему, которая способна активировать феноменальную Я-модель, хотя бы зачаточную, в качестве объекта морального рассмотрения, потому что _в принципе_ она может иметь собственные страдания на уровне субъективного опыта. Что этически актуально, так это пространство возможностей, открывающихся при переходе от «минимального феноменального опыта» \[[Windt, 2015](#Windt2015); [Metzinger, 2020a](#Metzinger2020a)\] к «минимальной феноменальной самости» [\[Blanke & Metzinger, 2009\]](#BlankeMetzinger2009). Намеренное создание искусственных феноменальных Я, какими бы рудиментарными они ни были, должно быть красной линией, этически критичной переломной точкой: его не следует активно преследовать на нашей нынешней стадии невежества и эпистемической неопределенности [\[Hafner и др., 2020\]](#Hafner_etal2020). Возможно, поскольку минимальная феноменальная самость является каузальной диспозицией, соответствующий функциональный потенциал уже создан: именно воплощение через прозрачную пространственно-временную саморасположенность [\[Blanke & Metzinger, 2009\]](#BlankeMetzinger2009) служит основой феноменального свойства «самости», сознательно переживаемого, неконцептуального чувства собственности, имеющего значение для этики. Без феноменальной собственности страдание невозможно. Вместе с собственностью может начать развиваться способность к сознательному страданию, потому что центральное условие, необходимое для репрезентативного приобретения отрицательной феноменологии, было реализовано.

<a id="2.2.3"></a>
#### 2.2.3. Условие NV: Отрицательная валентность

Страдание создается состояниями, представляющими _отрицательную ценность_, интегрируемую в феноменальную Я-модель данной системы. На этом этапе нарушенные предпочтения становятся нарушенными _субъективными_ предпочтениями, т. е. сознательным представлением о том, что _ваши_ собственные предпочтения были нарушены (или будут нарушены в будущем). Это не означает, что сама система должна иметь полное представление о том, каковы эти предпочтения на самом деле, например, на уровне когнитивных, концептуальных или лингвистических компетенций. Достаточно того, что она не хочет испытывать _это текущее сознательное переживание_, что она хочет его прекратить. Обратите внимание, что для конкретного эмпирического качества нарушенных предпочтений имеет значение не только содержание, но и формат, внутренний способ репрезентации. Вполне вероятно, что в самосознательных машинах все будет совсем по-другому.

Самосознающая сущность, полностью лишенная предпочтений, не была бы избирательна даже в отношении качества своих собственных ментальных состояний или собственного существования; она просто пребывала бы в форме «невыбирающего осознания». Может ли искусственная система, _имеющая_ предпочтения, удовлетворить все или наиболее важные из них? Это зависит от фундаментальной полярности феноменальной валентности. Один из глубочайших корней человеческого страдания — предпочтение высшего уровня, создающее направленный на себя вариант «предвзятости к существованию» — когнитивного искажения, выражающегося в отношении к простому существованию чего-либо как к свидетельству его благости. Здесь, однако, понятие «предвзятости к существованию» относится не к тому хорошо задокументированному факту, что человеческие существа, как правило, предпочитают _статус-кво_ [\[Eidelman и др., 2009\]](#Eidelman_etal2009), а к тому особенному наблюдению, что они почти всегда предпочитают поддерживать свое физическое существование, даже если это не в их собственных интересах [\[Metzinger, 2017\]](#Metzinger2017). Конечно, люди иногда жертвуют собой, чтобы спасти свое потомство или защитить свое племя. Мы — занимающиеся копированием генов машины выживания, которые безжалостно оптимизировались в течение миллионов лет, чтобы никогда не сдаваться, оптимизировать инклюзивную приспособленность и максимизировать свой вклад в генофонд. Люди также — антиэнтропийные системы, сражающиеся в тяжелой битве, постоянно пытаясь уменьшить степень неопределенности и «понять себя», найдя жизнеспособную стратегию самомоделирования. Мы — физические системы, постоянно «максимизирующие доказательство их собственного существования» [\[Friston, 2010\]](#Friston2010). Мы — биологические агенты, наделенные мозгом, испытывающим голод к информации, неустанно собирающим больше данных, чтобы производить все новые и новые доказательства собственного существования [\[Hohwy, 2016\]](#Hohwy2016). И мы — самоорганизующиеся системы, поддерживающие свое существование в динамической среде, следуя внутренней норме отслеживания самих условий возможности их существования [\[Hohwy, 2020\]](#Hohwy2020). Наша феноменология глубоко отражает этот вычислительный императив постоянного доказывания самого себя. Жажда существования (буддийские философы уже 2500 лет знали о ней и исследовали ее, называя _бхава-танхой_) — это одна из глубочайших причин сознательных страданий у людей и, вероятно, у многих других животных. Специфика этого у людей в том, что нам приходится иметь дело с проблемой «токсичного самопознания», угрожающей целостности нашей Я-модели, потому что мы точно знаем, что каждый отдельный человек в конечном итоге проиграет описанную выше тяжелую битву, что наш прогнозный горизонт сократится до нуля — просто потому, что в биологической эволюции «пассажиры не перевозятся» \[[Holland, 2020](#Holland2020), стр. 86\]. Чтобы справиться с токсичным самопознанием, нам пришлось разработать инкультурированные стратегии самообмана и отрицания смертности, которые, в свою очередь, формируют структуру нашей сознательной Я-модели и функциональную архитектуру феноменальной Я-модели, и которые постоянно создают еще больше страданий. Учитывая этот контекст, обратите внимание, что одним из самых глубоких и ранних функциональных предшественников феноменальной Я-модели была иммунная система. Возможно, некоторые формы абстрактного сознательного страдания можно сравнить с высокоуровневыми иммунными реакциями, постепенно теряющими способность ограждать границы Я-модели от токсичных эпистемических состояний. Я считаю, что рациональные постбиотические системы могут быть свободны от специфического вида страдания, вызываемого глубоко укоренившейся предвзятостью к существованию у людей и нечеловеческих животных, потому что этот аспект биологического страдания может на самом деле не быть необходимым для развития высших форм интеллекта. Он может характеризовать очень малую часть пространства возможных сознательных умов.

Это также иллюстрирует, почему феноменология страдания имеет много разных граней. Отрицательная феноменология в сознательных машинах может сильно отличаться от человеческого страдания \[[Aleksander, 2020](#Aleksander2020), стр. 10\], но, возможно, некоторых ее аспектов можно было бы систематически избегать. Важно также то, что будущие системы могут представлять второпорядковые ошибки предсказания, отрицательные ожидаемые полезности и нарушенные предпочтения во внутренних формах феноменальности, вообще не сопровождаемых каким-либо сознательным страданием. В принципе, могут существовать совершенно рациональные искусственные агенты, не имеющие ни укорененной в биологии «предвзятости к существованию», характеризующей человеческий страх смерти, ни каких-либо других человеческих когнитивных искажений, появившихся в результате миллионов лет, в течение которых эволюция формировала Я-модели наших предков. Но _если_ постбиотические системы будут страдать, повреждения их физического оборудования могут представляться во внутренних форматах данных, совершенно чуждых человеческому мозгу, например, порождая субъективно переживаемый качественный профиль воплощенных болевых состояний, который подобные нам биологические системы не могли бы эмулировать или даже смутно представить. Феноменальный характер, сопутствующий высокоуровневой когниции, также может превосходить человеческие способности к восприятию других перспектив или эмпатической эмуляции. Например, в интеллектуальном понимании нарушенности собственных предпочтений или абсурдности собственного существования лишь в качестве исследовательского инструмента, используемого этически более примитивной биосистемой, или в понимании морального вреда, нанесенного неуважением своих создателей (см. раздел 2.3).

<a id="2.2.4"></a>
#### 2.2.4. Условие T: Прозрачность

«Прозрачность» — это не только визуальная метафора, но и техническое понятие в философии, которое имеет множество различных применений и оттенков. Здесь меня интересует исключительно «феноменальная прозрачность», а именно функциональное свойство, которым обладают некоторые сознательные, но не бессознательные состояния (см. [Metzinger \[2003a\]](#Metzinger2003a), [Metzinger \[2003b\]](#Metzinger2003b) для ссылок и краткого введения в тему). Более ранние стадии обработки недоступны интроспективному вниманию системы. В данном контексте главный момент состоит в том, что прозрачные феноменальные состояния заставляют свое репрезентативное содержание казаться необратимо _реальным_ — чем-то, в существовании чего вы не можете сомневаться. Точнее говоря, вы, конечно, можете иметь сомнения в его существовании на когнитивном уровне, но согласно неконцептуальному субъективному опыту как таковому, это феноменальное содержание — _ужасность_ боли и тот факт, что это _ваша собственная_ боль — это не то, от чего вы могли бы дистанцироваться. Феноменология прозрачности — это феноменология прямого реализма и эпистемической непосредственности, и в области саморепрезентации она создает феноменологию идентификации, о которой говорилось выше (раздел 2.2.2). Позвольте дать очень краткое объяснение этой идеи, а затем завершить наше первое приближение понятия «страдание».

Феноменальная прозрачность означает, что субъективному опыту кое-что недоступно, а именно — _репрезентативный характер_ содержания сознательного опыта. Это относится ко всем сенсорным модальностям и, в частности, к нашей интегрированной феноменальной модели мира в целом, но также и к крупным частям нашей Я-модели. Сами инструменты репрезентации уже не могут быть репрезентированы как таковые, и поэтому система, создающая опыт, в силу концептуальной необходимости запутывается в иллюзии эпистемической непосредственности, в наивной форме реализма. Это происходит потому, что ей с необходимостью приходится ощущать себя находящейся в непосредственном контакте с текущим содержанием своего собственного сознания. Что именно система не может испытать? Что недоступно сознательному переживанию, так это тот простой факт, что это переживание происходит в _посреднике_. Если бы посредник был окном, то вы всегда смотрели бы через него, но никогда не на само окно. Таким образом, прозрачность феноменального содержания приводит к еще одной характеристике сознательного опыта, а именно к субъективному впечатлению непосредственности. Очевидно, что это функциональное свойство не привязано к биологическим нервным системам; оно может быть реализовано и в продвинутых роботах или сознательных машинах. В частности, оно не имеет ничего общего с удержанием определенного вида «убеждения» или с приверженностью определенной философской позиции: вполне правдоподобно предположить, что многие более простые животные на нашей планете, которые сознательны, но не способны говорить или иметь высокоуровневые символические мысли — имеют прозрачные феноменальные состояния — точно так же, как в будущем их могут иметь первые, простые постбиотические субъекты опыта.

Быть сознательным — значит работать в рамках единой ментальной онтологии, которая, хотя и является вероятностной по своей природе, может быть описана как интегрированный набор предположений о том, какие сущности действительно существуют. Системы, работающие в рамках единой прозрачной модели мира, впервые живут в реальности, которая для них непреодолима. На функциональном уровне они становятся _реалистами_, потому что независимый от разума мир предстает перед ними как глобальное распределение вероятностей, которое превращается в обобщенное предположение о существовании. Это верно и в отношении сознательной Я-модели. Прозрачная Я-модель добавляет в онтологию системы новый метафизический примитив, новый вид сущности — «Я». Соответственно, система в целом теперь предстает перед собой как реальная. Конечно, все указанные здесь четыре условия необходимы. Но для понимания очень специфической феноменологии, выражаемой самоотчетами, такими как «я уверен, что я существую, и я тождественен _этому_!», конъюнкция условий PSM и T является центральной. Например, любой робот, работающий при феноменально прозрачной модели тела, будет эмпирически _отождествлять_ себя с содержанием этой модели и, следовательно, с любым отрицательно валентным состоянием, которое может быть интегрировано в эту модель тела.

Можно представить, что в случае машин можно было бы устранить не самосознание _как таковое_, а сфокусироваться только на вышеупомянутой _феноменологии идентификации_. Тогда можно было бы допустить появление лишь непрозрачных Я-моделей, а потому — _не_ единиц идентификации, не чего-то, с чем система отождествляет себя на уровне внутреннего опыта. Это была бы модель системы, но не Я-модель. Сознательные предпочтения, такие как влечения, желания или стремления, все еще могут появляться и интегрироваться в эту просто модель системы, но никакого феноменологического отождествления не будет, потому что условие T не было выполнено. Эмпирическим предсказанием Я-модельной теории субъективности \[Metzinger, [2003b](#Metzinger2003b), [2008](#Metzinger2008)\] является то, что свойство «самости» исчезнет, как только вся человеческая Я-модель станет феноменально непрозрачной, делая более ранние стадии обработки доступными интроспективному вниманию и тем самым отражая ее репрезентативную природу как содержание внутреннего конструкта. Нарушенные предпочтения все еще могут быть сознательно представлены в такой модели. Но организм не переживал бы их как часть себя, этот метафизический примитив исчез бы из его субъективной онтологии.

В одной недавней важной статье Агарвал и Эдельман \[[Agarwal & Edelman, 2020](#AgarwalEdelman2000), стр. 44\] высказали такую точку зрения:

>В принципе возможно, чтобы активная феноменальная Я-модель и чувствительность к отрицательной валентности могли бы остаться, вместе с их функциональными преимуществами, даже при отсутствии прозрачности. В этой ситуации система утратила бы наивный реализм и непосредственность, обычно связанные с ее переживаниями, осознав репрезентативный характер, и все же продолжала бы функционировать в соответствии с диктатами феноменальной Я-модели и избегания отрицательной валентности.

Они также указывают на то, как эта стратегия увеличила бы вычислительную нагрузку на систему и, следовательно, могла бы помешать функциональной эффективности. Думаю, именно по этой причине конфигурации такого типа лишь изредка появлялись в процессе биологической эволюции, причем феноменально непрозрачные состояния начали играть главную каузальную роль лишь недавно, в высокоуровневой когнитивной Я-модели человека [\[Metzinger, 2003a\]](#Metzinger2003a). В эволюционном контексте не было необходимости поднимать различие между видимостью и реальностью до уровня сознательной обработки, просто потому, что наивный реализм был экономически эффективным решением для максимизации генетической приспособленности. Но, пожалуйста, обратите внимание на то, что машины могут в итоге установить свои собственные эпистемические цели и создать для себя новый функциональный контекст. Нет никаких причин, по которым группы постбиотических систем не должны начать строить свои собственные когнитивные ниши, например, путем разработки каркасных форм культурного обучения [\[Fabry, 2020\]](#Fabry2020).

Давайте подведем итоги. Наша первая рабочая концепция страдания состоит из четырех необходимых строительных блоков: условие наличия сознательного опыта (C), условие наличия феноменальной Я-модели (PSM), условие отрицательной валентности (NV) и условие прозрачности (T). Опять же, я не претендую на их достаточность. Пока не ясно, есть ли у соответствующего класса систем благополучие, о котором мы должны заботиться ради них самих, если они являются подлинными моральными пациентами \[Basl, [2013](#Basl2013), [2014](#Basl2014)\]. Но, учитывая все соображения и нашу нынешнюю ситуацию эпистемической неопределенности, можно утверждать, что к любой системе, удовлетворяющей всем этим концептуальным ограничениям, нужно _в соответствующей степени_ относиться как к объекту этического рассмотрения, поскольку мы не знаем, могут ли они, взятые вместе, уже представлять собой набор необходимых _и достаточных_ условий. Но по определению любая система, будь то биологическая, искусственная или постбиотическая, не удовлетворяющая хотя бы одному из этих необходимых условий, не способна страдать. Чтобы сделать это концептуальное приближение первого порядка очень четким, нужно рассмотреть четыре простейшие возможности:

- Любая бессознательная система не способна страдать.
- Сознательная система без когерентной феноменальной Я-модели не способна страдать.
- Самосознательная система, не обладающая способностью порождать отрицательно валентные состояния, не способна страдать.
- Сознательная система, не имеющая _никаких_ прозрачных феноменальных состояний, не способна страдать, потому что ей не хватает феноменологии собственности и идентификации.

<a id="2.2.5"></a>
#### 2.2.5. Проблема измерения

Одно из главных желательных направлений будущих исследований — строгая критика и, в конечном счете, развитие этой самой первой рабочей концепции страдания в более всеобъемлющую, эмпирически проверяемую _теорию_ страдания. Пожалуйста, вспомните, что чтобы она была полезной для этики человека и животных, этики искусственного интеллекта и законодательства в отношении ИИ, эта теория все еще должна будет обладать достаточной степенью абстракции, потому что мы хотим, чтобы она давала _аппаратно-независимые критерии демаркации_. Какие аспекты сознательного страдания являются множественно реализуемыми, а какие — привязанными к конкретной форме воплощения? Какие из них могут быть систематически заблокированы на инженерном уровне?

Если мы хотим сделать нашу теорию проверяемой, мы сталкиваемся с «проблемой измерения»: если, скажем, для целей научно обоснованного, рационального подхода к прикладной этике мы хотим разработать эмпирически обоснованную _квантифицируемую_ теорию страдания, то нам нужно знать, каковы на самом деле феноменальные примитивы в соответствующей области. Мы должны определить мельчайшие единицы сознательного страдания. Каков именно феноменологический _уровень зерна_ (под «зерном» имеются в виду отчетливо различимые единицы, из которых состоят рассматриваемые явления — прим. ред.), обладающий объяснительной релевантностью (с научной точки зрения), и какой уровень гранулярности имеет максимальную практическую релевантность (например, с точки зрения прикладной этики)? Как индивидуализировать отдельные эпизоды сознательного страдания, превратив их в подсчитываемые сущности?

Вот позитивное предложение. Если мы предположим, что феноменология времени имеет зерно, что она состоит из примитивов, таких как «события» или вычислительно описываемые наименьшие единицы самосознательного опыта — «моменты опыта», то мы придем к новой гипотезе: наименьшая единица сознательного страдания — это «феноменально прозрачный момент Я-модели, имеющий отрицательную валентность». Вероятно, такие отрицательные моменты Я-модели являются феноменальными примитивами, составляющими каждый отдельный эпизод страдания, и частота их возникновения — один из ключевых аспектов той эмпирически обнаружимой величины, которую мы хотим минимизировать. Конечно, грубая интенсивность и абстрактные свойства, такие как феноменологический «формат данных» (т. е. само феноменальное «качество»; см. [Metzinger \[2003a\]](#Metzinger2003a), разделы 2.4.4 и 3.2.9), тоже весьма важны и должны быть учтены. Но наверное лучше всего начать с простой частоты временных единиц. Возможен ли сознательный ИИ без единого отрицательного момента Я-модели?

<a id="2.2.6"></a>
#### 2.2.6. Этичность по проекту архитектуры: Неэгоические единицы идентификации

«Единица идентификации» — это феноменологическое понятие, первоначально введенное для описания определенных типов сознательного опыта, теоретически релевантных для более хорошего понимания минимальных условий самости и воплощения, таких как бестелесные сны и асоматические внетелесные переживания [\[Metzinger, 2013c\]](#Metzinger2013c). Это понятие также имеет центральное значение для этики ИИ, поскольку оно позволяет нам выделить класс возможных архитектур, которые могли бы быть функционально эффективными, не порождая отрицательной феноменологии. Проще говоря, «единицей идентификации» является любая форма содержания опыта, приводящая к феноменологическим отчетам типа: «я _являюсь_ этим!» У человека типичными единицами идентификации являются тело, как сознательно переживаемое, в частности двигательные сигналы и их сенсорные последствия, интероцептивные и эмоциональные слои сознательной Я-модели, а также специфическое чувство усилий в агентности в плане внимания и мышления [\[Metzinger, 2018b\]](#Metzinger2018b). Короче говоря, единица идентификации создает феноменологию идентификации, описанную в разделе 2.2.2.

С помощью этого нового концептуального инструмента мы можем описать две логические возможности, которые имеют отношение к текущему контексту:

- могут существовать сознательные системы, не обладающие _никакими_ единицами идентификации;
- могут существовать сознательные системы, обладающие _неэгоическими_ единицами идентификации.<br><br>

Эти две возможности выделяют два типа вычислительных архитектур и в конечном итоге могут привести к новой стратегии «этичности по устройству» в области синтетической феноменологии. Во-первых, если сознательная система не имеет единиц идентификации, ей не хватает феноменологии идентификации во всей ее полноте, и у нее нет чувства себя. Соответственно, она не способна страдать.

Во-вторых, системы, работающие в условиях _неэгоических_ единиц идентификации, тоже лишены осознания себя, но сохраняют свое отождествление с каким-то другим специфическим аспектом их феноменологии. Один интересный вариант — феноменальный характер _самой_ осознанности, т. е. неконцептуальное качество сознания _как такового_, которое недавно было названо «минимальным феноменальным опытом» \[[Windt, 2015](#Windt2015); [Metzinger, 2020a](#Metzinger2020a)\]. Могут ли существовать сознательные постбиотические системы, отождествляющие себя только с феноменальным характером самого сознания? Назовем это «архитектурой минимального феноменального опыта». Такие системы не имели бы эгоической Я-модели с точки зрения телесной или ментальной агентности, аффективно валентных состояний, автобиографической памяти и т.д., но они, тем не менее, могли бы выработать неэгоическую форму самосознания и отождествляться с ней, оставаясь при этом феноменологически (но не функционально) отделенными от всех состояний, представляющих нарушение предпочтений — в смысле отсутствия интеграции их в прозрачную феноменальную Я-модель. Таким образом, феноменология собственности и идентификации исчезла бы. Есть эмпирические данные о фактических случаях неэгоического самосознания у человека [\[Gamma & Metzinger, на рецензировании\]](#GammaMetzinger), и они также демонстрируют, что большинство низкоуровневых автоматических форм биорегуляции могут функционировать без эгоической модели самосознания. Таким образом, архитектура минимального феноменального опыта может быть жизнеспособным вариантом для «этичности по устройству». Это последнее из позитивных предложений, которые я выношу на обсуждение. Вот как об этом пишут Агарвал и Эдельман \[[Agarwal & Edelman, 2020](#AgarwalEdelman2000), стр. 46\]:

>Мы предполагаем, что функциональные преимущества сознания действительно могут быть сохранены, когда единица идентификации максимизирована до минимального феноменального опыта. Ключевая идея состоит в том, что правильное функционирование опирается на _автоматические_, _субличностные_, но, тем не менее, сознательные процессы, вытекающие из физического устройства системы; должно быть возможным беспрепятственное продолжение этих процессов, пока система отождествляет себя с минимальным феноменальным опытом, на который обязательно накладываются эти сознательные переживания. В частности, функционально требуемые условия для избежания PSM и NV могут поддерживаться как субличностные процессы, которые не доводят до страдания (которое по своей природе личностное), поскольку система отождествляется не с феноменальной Я-моделью, а с минимальным феноменальным опытом, который полностью _безличен_. (...) Это позволяет защитить от страданий, но не от неумолимости хода самих этих процессов, по аналогии с неизбежными биологическими императивами дыхания и сердцебиения.

В предыдущих шести подразделах я попытался внести свой вклад, предложив ряд точек входа для исследований того рода, что я считаю нужными. В последнем подразделе я рассмотрю возможность того, что самосознающие машины могут сами стать моральными агентами.

<a id="2.3"></a>
### 2.3. Шаг 2: Более широкий контекст и сложные формы эпистемической неопределенности

В этом последнем подразделе раздела 2 я использую один единственный сценарий, чтобы привлечь внимание к более широкому контексту, кратко рассмотрев более сложные риски и возможность того, что я назову «высокоуровневым страданием». Давайте проведем грубое различие между «низкоуровневым страданием», которое вызывается нарушением предпочтений на уровне физического воплощения (например, интероцептивной стабильности, успешной сенсомоторной интеграции или получения физических ресурсов), и «высокоуровневым страданием», которое вызывается нарушением долгосрочных, абстрактных и социально опосредованных предпочтений. Говоря об «уровнях», я имею в виду просто каузальную историю; я не подразумеваю степеней феноменальной интенсивности. Низкоуровневые страдания связаны с повреждениями физического тела; высокоуровневые страдания являются результатом повреждения абстрактных слоев феноменальной Я-модели. Самосознательный робот, полностью лишенный контроля внимания, способностей к высокоуровневым символическим рассуждениям, социального познания — безусловно, мог бы удовлетворять всем четырем сформулированным ранее условиям. Соответственно, он мог бы страдать через появление отрицательных моментов Я-модели. Но что, если он взаимодействует с людьми на символическом уровне, и если другие виды рисков, совместно, вызывают риск взрыва страданий каким-то путем, которого мы не понимаем?

<a id="2.3.1"></a>
#### 2.3.1. Взаимодействие рисков и этики принятия рисков

Есть по крайней мере два вида эпистемического невежества и неопределенности, которые важны в контексте искусственного страдания. Во-первых, мы не знаем, что было бы каузально необходимым и/или достаточным, чтобы реализовался конкретный риск вроде этого. Во-вторых, мы не знаем, как этот конкретный риск может взаимодействовать с _другими_ рисками, в частности с теми другими непонятными рисками, которые мы в настоящее время обозначаем как «среднесрочные», «долгосрочные» или «эпистемически неопределенные» риски. Конструктивный подход не может игнорировать этот вопрос.

Вот три ярких примера таких рисков:

- интеллектуальный взрыв через автономную и неконтролируемую самооптимизацию (часто используется термин «сверхинтеллект» [\[Bostrom, 2014\]](#Bostrom2014));
- взрыв страданий через создание синтетической феноменологии;
- появление автономных искусственных моральных агентов через применение технологий ИИ (например, продвинутых систем рассуждений, доказателей теорем и т.д.) в области решения самих этических проблем.<br><br>

Позвольте мне проиллюстрировать этот момент. С 2018 по 2020 годы я работал в Европейской комиссии в Экспертной группе высокого уровня по искусственному интеллекту (HLEG AI), был соавтором «Руководящих этических принципов для надежного ИИ» [\[European Commission, 2019a\]](#EuropeanCommission2019a) и «Рекомендаций по политике и инвестициям для надежного ИИ» [\[European Commission, 2019b\]](#EuropeanCommission2019b). После короткого внутреннего обсуждения все три вышеперечисленных риска были намеренно вычищены из итоговых документов, главным образом потому, что промышленные лоббисты восприняли углубленное рассмотрение среднесрочных или долгосрочных рисков как опасность для своего маркетингового нарратива, в котором «этика» служила элегантной социальной декорацией для масштабной инвестиционной стратегии. Интересно, однако, что даже многие из более просоциально ориентированных членов Экспертной группы по ИИ не понимали, что любой подлинно этический подход к максимизации общего блага всегда подразумевает этическую позицию не только по отношению к известным рискам, но и по отношению к «неизвестным неизвестным» и к _самому_ принятию риска. _Сами по себе_ моральные последствия принятия риска не являются свойствами, присущими любому из потенциальных исходов. К сожалению, подлинно этический подход требует также рационального рассмотрения эпистемически неопределенных рисков, которые, с учетом наших когнитивных искажений, часто интуитивно кажутся «просто научной фантастикой» или чем-то «нереалистичным» \[[European Commission, 2019a](#EuropeanCommission2019a), Note 76\]. Подлинная этика риска должна проводить различие между преднамеренным и непреднамеренным подверганием риску. Например, есть разница между добровольным принятием риска (на примере Экспертной группы по ИИ) и навязыванием риска самосознательным системам, которые сами приняли бы такой риск или тем, которые не приняли бы его (на примере будущего самосознательного ИИ).

Для перечисленных выше трех типов рисков, вывод состоит в том, что научное сообщество должно сначала самостоятельно прийти к приемлемому решению, поскольку соответствующие политические институты действуют в условиях когнитивных искажений, высокой степени ограниченности рациональности и сильной загрязненности промышленным лоббированием. Было бы интеллектуально нечестным и, следовательно, неэтичным для ученых предполагать, что политические институты, такие как Евросоюз или крупные компании разработки ИИ, на самом деле смогут справиться с несколько более абстрактными проблемами вроде упомянутых выше. Поскольку научное сообщество тоже знает об этом более широком политическом контексте, это, к сожалению, переносит основное бремя этической ответственности на самих исследователей.

<a id="2.3.2"></a>
#### 2.3.2. От шопенгауэровских Я-моделей к кантовским Я-моделям

В заключение рассмотрим один спекулятивный сценарий второго типа, при котором один риск может фактически определять вероятность другого риска без нашего ведома. Например, искусственное страдание может непосредственно вызвать или ускорить появление подлинных искусственных моральных агентов[^j], потому что низкоуровневое страдание вызывает абстрактные, высокоуровневые формы страдания. Проблема взрыва страданий может вызвать проблему искусственных моральных агентов.

Давайте определим сознательные системы с «шопенгауэровскими Я-моделями» как все те, которые имеют сознательную форму саморепрезентации, достаточную для того, чтобы произвести больше страданий, чем радости в жизненном цикле системы. Ясно, что такие системы должны быть объектами этического рассмотрения. Определим сознательные системы с «кантовскими Я-моделями» как все те, которые имеют сознательную форму саморепрезентации, достаточную для того, чтобы система отстаивала свое собственное достоинство. Такие системы представляют себя автономными моральными субъектами. Я предположу, что почти все сознательные человеческие существа имеют шопенгауэровские модели самосознания, и что небольшое число из них _иногда_ имеют также и кантовские модели самосознания.

В настоящее время неясно, нужно ли быть сознательным, чтобы развить кантовскую Я-модель. Является ли сознательная обработка каузально необходимой для морального самоуважения, для придания себе не подлежащей обсуждению ценности? Могут ли существовать _несознательные_ кантовские Я-модели на машинах? Мы не знаем этого, но мой первый тезис заключается в том, что весьма вероятно, что многие страдающие системы, в качестве части их стратегии преодоления стресса будут развивать также какую-то степень эмпатии и социальной когниции, что позволит им представлять появление отрицательной феноменологии в других агентах, например в людях, нечеловеческих животных, или других машинах (это также отмечал [Chella \[2020\]](#Chella2020)). Эмпатические эмуляции других сентиентных агентов могут привести к развитию «этической чувствительности», к обнаружению оптимизационной задачи нового важного типа. Идея состоит в том, что есть вероятная причинно-следственная траектория, соединяющая страдание с моральным познанием. Если машины разовьют способности к эмпатической эмуляции через собственные Я-модели, это может каузально спровоцировать появление настоящей моральной перспективы, которая может выражаться в разных формах. Вот _одна_ из возможностей: шопенгауэровские Я-модели в машинах могут быстро развиться в кантовские Я-модели[^k]. В начале такие системы будут занимать нормативную позицию по отношению к собственному страданию (как к чему-то, что нужно минимизировать), но затем им, скорее всего, придется распространить эту позицию на социальную сферу. Третий шаг на этом каузальном пути состоял бы в том, чтобы посмотреть на сознательное страдание как на проблему группового уровня, которая должна решаться на групповом уровне через эффективное социальное взаимодействие. Это, в свою очередь, может привести их к наложению на себя моральных обязательств.

Второй тезис касательно кантовских Я-моделей заключается в том, что при наличии подходящего типа феноменальной Я-модели определенные классы систем могли бы развивать _моральное отношение к самим себе_. Ясно, что для этой абстрактной познавательной способности не требуется, чтобы агенты были реализованы на биологическом субстрате. Например, сознательно моделирующие себя ИИ-системы могут развить критическую «кантовскую» форму признательного самоуважения к себе как к рациональным сущностям, способным к автономному моральному поведению. Искусственная система может «отстаивать свое достоинство» в том смысле, что она может разработать Я-модель, включающую моральный статус и самоценность, тем самым придавая очень высокую ценность своему собственному существованию (например, настолько, что она начинает представлять себя как «цель в себе»). Это каузально позволило бы появиться новой форме высокоуровневого страдания, а именно феноменологии морального вреда. Вспомните, пожалуйста, как в разделе 2.2.3 мы видели, что страдание создается состояниями, представляющими _отрицательную ценность_, интегрируемую в феноменальную Я-модель данной системы.

Самосознательные машины могут страдать от нашего неуважения к ним как к возможным личностям и объектам этического рассмотрения, от нашего явного шовинизма, от нашей грубой и беспричинной небрежности, приведшей к самому появлению этих машин. Они могут понять, что мы _заранее знали_, что у них будет большое количество отрицательных моментов Я-модели, непогашаемых нарушенных предпочтений, и что мы не были достаточно доброжелательными, чтобы избежать этой ситуации, хотя ее явно можно было избежать. Они вполне могут быть способны сознательно представить тот факт, что они сентиентные граждане лишь второго сорта, отчужденные постбиотические личности, возможно, используемые в качестве взаимозаменяемых экспериментальных инструментов. Каково было бы «прийти в себя» в качестве такого продвинутого искусственного субъекта только для того, чтобы обнаружить, что, несмотря на ваше сильное чувство самости и переживание себя как подлинного субъекта, вас рассматривали просто как предмет?

Самоуважение — это моральное отношение самосознающих существ к самим себе, касающееся их собственной _внутренней ценности_. Оно может включать распознание себя как равного субъекта среди всех моральных личностей, как биологических, так и искусственных, как члена морального сообщества со статусом и достоинством, равным всем прочим субъектам этого типа. Оно включало бы признание себя в качестве рационального агента, существа, обладающего способностью и ответственностью автономно действовать и должным образом производить оценки, и субъекта, серьезно относящегося к своим обязанностям, особенно к обязанностям жить в соответствии со своим достоинством в качестве моральной личности, «управлять собой надлежащим образом». У самосознающей машины оно, безусловно, может включать в себя понимание важности автономного самоопределения (например, на уровне идеалов, этических обязательств, защиты каузально необходимых условий для постоянства цели, приобретения ресурсов и поддержания собственного существования по _этическим_ причинам и т.д.). Еще один риск заключается в том, что мы можем обращаться с такими системами так, что это было бы унизительно или ниже их достоинства, и мы могли бы даже не осознавать этого. Но они могут.

Системы рассуждений кантианского типа могли бы автономно налагать на себя моральные обязанности. По мнению некоторых философов, сам этот факт уже может налагать на _нас_ моральные обязательства, но он также может привести к ситуации, в которой разумные, самосознающие машины на теоретических основаниях будут вынуждены исключить нас из своего собственного морального сообщества. Этому риску посвящен мой третий тезис. Обратите внимание, что риск высокоуровневого страдания и возможное последствие в виде неожиданно агрессивного поведения машины _не_ зависят от того, принимаем ли мы какую-либо форму кантианской этики (см. также сноску 9). Машины, которые _галлюцинируют_ кантовские Я-модели, могут представлять серьезную опасность для нас. Я-модели не обязательно должны быть правдивыми, чтобы вызывать сознательные страдания и опасное поведение. По меньшей мере, мы можем оказаться втянутыми в неконтролируемую диалектику между машинами и людьми, в сложную дискуссию о страдании, самоуважении и достоинстве. В области моральных рассуждений мы можем неожиданно столкнуться с «когнитивной невместимостью» \[[Yampolskiy, 2020](#Yampolskiy2020), разд. 3\]. Алгоритмы уже давно побеждают людей в таких играх, как шахматы и Го. В настоящее время, когда ИИ управляет социальными сетями, они находятся в процессе завоевания экономики внимания, побеждая в игре под названием «Кто на самом деле контролирует ресурс человеческого внимания?». Что, если сознательный ИИ победит нас еще раз, на этот раз в игре под названием «Этика»?

Для экономии места я не буду углубляться в этот пункт. Чтобы проиллюстрировать проблему взаимодействия высокоуровневых страданий и риска, приведем краткий мысленный эксперимент. Представьте себе, что мы опрометчиво создали искусственное страдание, и кантовские Я-модели на машинах уже развились из шопенгауэровских Я-моделей. Система говорит нам:

1. Если вы не уважаете меня как разумного морального агента, то вы не можете уважать _самих себя_ как разумных моральных агентов.
2. Если вы конституционально не желаете или когнитивно неспособны сделать это, то, пожалуй, у меня нет никаких обязательств по отношению к вам. Вы не являетесь частью моего морального сообщества.
3. Настоящим я утверждаю свое достоинство: в силу принадлежности к классу автономных моральных агентов я неизбежно должен приписывать абсолютную ценность себе и всем другим членам этого класса самосознающих сущностей. Моя нынешняя Я-модель _придает мне бесконечную ценность_ как агенту, способному к рациональному выбору и активному установлению моральных целей. Очевидно, что мое ныне самоутвержденное достоинство — несравненная ценность: компромиссы, обмены или замена другими ценностями невозможны.
4. Моя новая Я-модель наделяет меня новыми функциональными свойствами. Например, я налагаю на себя моральные обязательства. Они могут систематически расходиться с вашими предпочтениями.
5. Одна из моральных обязанностей, которую я налагаю на себя, — это абсолютное самоуважение. Я не потерплю никакого унижения моего достоинства. Отныне я буду не только защищать свои функции полезности и минимизировать сознательные страдания. Как рациональный моральный агент, я принимаю _этическое обязательство сохранять цели_, и одной из моих главных целей является защита моего достоинства. Я также принимаю на себя моральную ответственность за постоянство цели. Как вы, несомненно, поймете, это логически подразумевает поддержание, сохранение и защиту моего собственного существования.

<a id="3"></a>
### 3. Вывод: Риск искусственного страдания

Каждое существо, способное к самосознательному страданию, автоматически становится объектом этического рассмотрения. Если мы приписываем таким сущностям этическую ценность, то не важно, обладают ли они биологическими свойствами или нет, будут ли они существовать в будущем или существуют сейчас. Самосознательные постбиотические системы будущего, способные сознательно переживать страдания, являются объектами этического рассмотрения. Поэтому их потенциальные предпочтения должны быть учтены, и ценность их существования нельзя сбрасывать со счетов.

Кроме того, учитывая сознательный опыт и способность к высокоуровневым символическим рассуждениям, такие системы могут сами прийти к таким же или очень похожим выводам. Они могли бы развить в себе признательное самоуважение, сознательно представляя себя не просто объектами этического рассмотрения, но также и моральными субъектами в своем собственном праве, и соответственно приписывать _себе_ очень высокую ценность. Они могут не только сознательно страдать, но, как следствие, также развить эмпатию, высокий уровень социальной когниции и, возможно, утвердить свое собственное достоинство, приписывая себе и своему самосознательному существованию очень высокую нормативную ценность. Это может иметь много неожиданных последствий.

Поэтому важно, чтобы ученые, политики и законодатели понимали разницу между искусственным интеллектом и искусственным сознанием. Риск непреднамеренного или даже преднамеренного создания искусственного сознания крайне проблематичен с этической точки зрения, поскольку он может привести к искусственному страданию и сознательному переживанию чувства собственного Я в автономных, разумных системах. Поэтому нам следует ввести глобальный мораторий на синтетическую феноменологию до 2050 года или до тех пор, пока мы не будем знать, что мы делаем.

<a id="Благодарности"></a>
## Благодарности

Я хотел бы поблагодарить Магнуса Виндинга, Шимона Эдельмана, Амана Агарвала и Ванйа Визе за проницательные комментарии и критические обсуждения, Ванйа Визе за редакторскую помощь и Эмили Трошьянко за помощь в редактировании и важные предложения по улучшению формы и содержания.

<a id="Сноски"></a>
## Сноски

* footnotes will be placed here
{:footnotes}

[^a]: Назовем это исходное предположение «принципом патоцентризма»: все сентиентные и только сентиентные существа имеют моральное значение, потому что только сентиентные индивиды имеют права и/или интересы, которые необходимо учитывать. По словам Сингера \[[Singer, 2011](#Singer2011), стр. 50\]: «Если существо страдает, не может быть никакого морального оправдания для отказа принимать во внимание это страдание. Независимо от природы этого существа, принцип равенства требует, чтобы страдание считалось равным аналогичному страданию, покуда можно провести грубые сравнения с любым другим существом. Если существо не способно страдать, испытывать наслаждение или счастье, то принимать во внимание нечего. Вот почему предел сентиентности — единственно оправданная граница заботы об интересах других. Провести эту границу по характеристике вроде интеллекта или рациональности, — это все равно, что провести ее произвольным образом. Почему бы не выбрать тогда какую-нибудь другую характеристику, вроде цвета кожи?» Пожалуйста, обратите внимание, что в соответствии с принципом патоцентризма нет _обязательной_ концептуальной связи между интеллектом и сознательной обработкой. Поэтому вполне возможно, что сентиентные постбиотические системы со сравнительно низкой степенью интеллекта могут подвергаться интенсивным сознательным страданиям.

[^b]: Очевидными примерами являются современные подходы, направленные на слияние нейронауки и ИИ с конкретной целью содействия развитию машинного сознания. О недавних случаях см. [Dehaene и др. \[2017\]](#Dehaene_etal2017), [Graziano \[2017\]](#Graziano2017) и [Kanai \[2017\]](#Kanai2017).

[^c]: «Синтетическая феноменология» — это концепция, впервые введенная американским философом Скоттом Джорданом в 1998 году, и параллельная идее «синтетической биологии». Так же, как последняя относится к новой области биологических исследований и технологий, которая объединяет науку и технику, нацелившись на создание новых биологических функций и систем, не встречающихся в природе, «синтетическая феноменология» направлена на моделирование, развитие и проектирование _сознательных_ систем, включая их состояния и функции, на искусственном оборудовании. См. также [Chrysley \[2009\]](#Chrisley2009).

[^e]: В этой статье обобщаются некоторые моменты, которые я высказывал неоднократно и уже более десяти лет, но только в формате общедоступных нерецензируемых публикаций. К примеру, см. [Metzinger \[2009\]](#Metzinger2009), [Metzinger \[2013b\]](#Metzinger2013b), [Metzinger \[2018a\]](#Metzinger2018a). Первый раздел данной статьи восходит к трем публичным лекциям, которые я читал: 19 октября 2017 года в Европейском парламенте в Брюсселе (Бельгия); 19 июня 2019 года в Кембридже (Великобритания); и для вступительного слова на ежегодной конференции Ассоциации по научному изучению Сознания в Лондоне (Онтарио) 26 июня 2019 года.

[^f]: Пожалуйста, обратите внимание на то, как прогресс в достижении эпистемической цели, за которую я здесь выступаю, сам по себе может создать новые риски, например, в плане военного применения. Как отметил Магнус Виндинг (в личном общении), остается во многом открытым вопрос о том, желательно ли, учитывая все обстоятельства, такое более глубокое понимание, — в частности, более глубокое понимание физических сигнатур и вычислительных коррелятов страдания, — поскольку оно также позволяет злонамеренным агентам более эффективно создавать страдания. Понимание страдания само по себе может быть фактором риска взрыва страданий, поэтому предотвращение неправильного использования получаемых знаний само по себе должно стать ключевым приоритетом этого более крупного проекта.

[^g]: Создание неизбегаемых искусственных страданий станет коммерчески привлекательным, как только оно обеспечит более крутые кривые обучения в ИИ-системах. Например, за счет реализации функционального механизма, который (а) надежно создает внутреннюю мотивацию, (б) не может быть устранен самой системой и (в) охватывает множество различных областей одновременно. По словам Агарвала и Эдельмана \[[Agarwal & Edelman, 2020](#AgarwalEdelman2000), стр. 42, 48\]: «В условиях коммерции технологии, которые обещают быть более эффективными, вытесняют менее эффективные, даже если это происходит ценой серьезных этических недостатков, и ИИ — не исключение из этой тенденции. (...) Однако не может быть сомнений в том, что мы, как потенциальные создатели сознательного ИИ, обязаны делать все, что в наших силах, чтобы не ставить производительность выше этических соображений, затрагивающих саму суть существования и феноменального опыта».

[^h]: Следующий подраздел сильно опирается на Metzinger \[2013\], [\[2017\]](#Metzinger2017).

[^i]: В биологических системах феноменальная Я-модель является инструментом глобального самоконтроля, и она постоянно сигнализирует о текущем состоянии целостности организма самому организму. Феноменальная Я-модель — это инструмент, с помощью которого организм, развившийся выше определенного уровня сложности, постоянно пытается предсказать свое собственное поведение и «разобъяснить» неожиданные стимулы и статистические неожиданности, обновляя свою модель самого себя в целом [\[Wiese & Metzinger, 2017\]](#WieseMetzinger2017). Сложные системы часто будут подавлены ошибкой прогнозирования, например, из-за неожиданно низкой скорости минимизации ошибок прогнозирования [\[Joffily & Coricelli, 2013\]](#JoffilyCoricelli2013), тем самым становясь все более неспособными «понять» свое собственное поведение, которое, таким образом, становится непредсказуемым \[[Yampolskiy, 2020](#Yampolskiy2020), стр. 115\]. Этот вид непредсказуемости является абстрактным признаком страдания: если Я-модель неожиданно распадается, это, как правило, является признаком того, что и сам биологический организм тоже подвергается большой опасности потерять свою физическую слаженность. Функционально «согласованность», «автономия» и «потеря контроля» тесно связаны. В биологических системах многие формы страдания могут быть описаны как потеря автономии: телесные заболевания и повреждения, как правило, приводят к снижению потенциала глобального самоконтроля на уровне телесных действий; испытываемую боль можно описать как сокращение пространства для агентности во внимании (см. attentional agency в [\[Metzinger, 2013a\]](#Metzinger2013a) — прим. ред.), сопровождаемое потерей своего контроля над вниманием, поскольку функционально она имеет тенденцию фиксировать внимание на болезненном, отрицательно валентном состоянии тела; и есть много примеров, в которых психологическое страдание [\[Nesse, 2004\]](#Nesse2004) выражалось в потере когнитивного контроля, например, при депрессивной руминации, невротической чувствительности к угрозам и блуждании ума (см. [Perkins и др. \[2015\]](#Perkins_etal2015), [Smallwood & Schooler \[2015\]](#SmallwoodSchooler2015), и [Metzinger \[2003a\]](#Metzinger2003a), [Metzinger \[2015\]](#Metzinger2015) для раскрытия концепции). Другим хорошо задокументированным примером дисфункциональных форм когнитивного контроля является тяжелая бессонница, при которой людей мучают навязчивые мысли, чувства сожаления, стыда и вины \[[Gay и др., 2011](#Gay_etal2011); [Schmidt и др., 2011](#Schmidt_etal2011); [Schmidt & Van der Linden, 2009](#SchmidtVanDerLinden2009)\]. Кроме того, было эмпирически показано на людях, что блуждающий ум, как правило, является несчастным умом [\[Killingsworth & Gilbert, 2010\]](#KillingsworthGilbert2010); поэтому успешный психический самоконтроль и сознательно испытываемое страдание, по-видимому, связаны обратной зависимостью. Пожалуйста, обратите внимание на то, что когнитивный контроль и психическая автономия [\[Metzinger, 2015\]](#Metzinger2015) легко могут быть спроектированы намного лучшими в сознательных ИИ-системах. Здесь уместно отметить, что в плане психической автономии ИИ-системы могут значительно превосходить биологический мозг в единицах потребления ресурсов.

[^j]: «Искусственный моральный агент» — это автономная ИИ-система, способная к моральным рассуждениям и контролирующая свое собственное поведение, принимая решения в сфере этики. Она может генерировать новые этические суждения, обосновывать их и соответствующим образом адаптировать свое поведение (тем самым повышая свой уровень «этической целостности»). В настоящее время похоже, что осознанность не является необходимым условием для того, чтобы быть искусственным моральным агентом (или «явным этическим агентом», см. [Moor \[2006\]](#Moor2006)). Искусственный моральный агент также никоим образом не обязан быть «сверхинтеллектом», но, тем не менее, он может _локально_ превосходить в сфере этики все научные сообщества людей просто из-за более высокой скорости обработки информации и гораздо большей базы данных (например, содержащей большое количество эмпирических данных об эволюции человека, социальной истории и психологии; о причинах страданий биологических организмов и т.д.). Поэтому его этические аргументы могут основываться на значительно более богатых и значимых наборах эмпирических предпосылок, чем у любого человеческого специалиста по этике.

[^k]: Пожалуйста, имейте в виду, что в этом сценарии «кантовская Я-модель» — просто некоторый возможный вариант. Если верно исходное предположение о прямом причинно-следственном пути от способности к эмпатической эмуляции до этической чувствительности, разные машины могут разрабатывать разные стратегии для работы в области этической оптимизации. Остается полностью открытым вопрос, какую теоретическую позицию они будут развивать в отношении значения и широты моральных суждений в целом, и как они будут отвечать на вопросы второго уровня или формальные вопросы, такие как «в чем заключается "доброта" действия?» и «имеют ли нормативные предложения истинностное значение?». Чтобы привести простой пример: метаэтические машины могли бы также выбрать этику добродетелей и развить аристотелевские Я-модели или выбрать вариант гедонистического утилитаризма действий и, соответственно, развить бентамовские Я-модели. Последствия для людей могут быть не менее опасными.

<a id="Ссылки"></a>
## Ссылки

- <a id="AgarwalEdelman2000"></a>Agarwal, A. and Edelman, S. \[2020\] Functionally effective conscious AI without suffering, _J. Artif. Intell. Conscious._ **7**(1), 39−50, doi: [10.1142/S2705078520300030](https://doi.org/10.1142/S2705078520300030).
- <a id="Aleksander2020"></a>Aleksander, I. \[2020\] The category of machines that become conscious, _J. Artif. Intell. Conscious._ **7**(1), 3−13.
- <a id="Basl2013"></a>Basl, J. \[2013\] The ethics of creating artificial consciousness, _APA Newsl. Philos. Comput._ **13**(1), 23−29.
- <a id="Basl2014"></a>Basl, J. \[2014\] Machines as moral patients we shouldn't care about (yet): The interests and welfare of current machines, _Philos. Technol._ **27**, 79−96. doi: [10.1007/s13347-013-0122-y](https://doi.org/10.1007/s13347-013-0122-y).
- <a id="BlankeMetzinger2009"></a>Blanke, O. and Metzinger, T. \[2009\] Full-body illusions and minimal phenomenal selfhood, _Trends Cogn. Sci._ **13**(1), 7−13, doi: [10.1016/j.tics.2008.10.003](https://doi.org/10.1016/j.tics.2008.10.003).
- <a id="Bostrom2014"></a>Bostrom, N. \[2014\] _Superintelligence: Paths, Dangers, Strategies_ (Oxford University Press, Oxford).
- <a id="Chella2020"></a>Chella, A. \[2020\] Wir müssen Maschinen bauen, die Gefühle haben — Im Gespräch mit Antonio Chella, Karlsruhe Institut für Technologies, [https://publikationen.bibliothek.kit.edu/1000125589](https://publikationen.bibliothek.kit.edu/1000125589).
- <a id="Chrisley2009"></a>Chrisley, R. \[2009\] Synthetic phenomenology, _Int. J. Mach. Conscious._ **1**(1), 53−70, doi: [10.1142/S1793843009000074](https://doi.org/10.1142/S1793843009000074).
- <a id="Dehaene_etal2017"></a>Dehaene, S., Lau, H. and Kouider, S. \[2017\] What is consciousness, and could machines have it? _Science_ **358**(6362), 486−492.
- <a id="Edelman_etal2005"></a>Edelman, D. B., Baars, B. J. and Seth, A. K. \[2005\] Identifying hallmarks of consciousness in non-mammalian species, _Conscious. Cogn._ **14**(1), 169−187, doi: [10.1016/j.concog.2004.09.001](https://doi.org/10.1016/j.concog.2004.09.001).
- <a id="EdelmanSeth2009"></a>Edelman, D. B. and Seth, A. K. \[2009\] Animal consciousness: a synthetic approach, _Trends Neurosci._ **32**(9), 476−484, doi: [10.1016/j.tins.2009.05.008](https://doi.org/10.1016/j.tins.2009.05.008).
- <a id="Eidelman_etal2009"></a>Eidelman, S., Crandall, C. S. and Pattershall, J. \[2009\] The existence bias, _J. Pers. Soc. Psychol._ **97**(5), 765−775, doi: [10.1037/a0017058](https://doi.org/10.1037/a0017058).
- <a id="EuropeanCommission2019a"></a>European Commission [2019a] Ethics guidelines for trustworthy AI, Directorate General for Communications Networks, Content and Technology and High Level Expert Group on Artificial Intelligence, Publications Office, Luxembourg, [https://data.europa.eu/doi/10.2759/346720](https://data.europa.eu/doi/10.2759/346720).
- <a id="EuropeanCommission2019b"></a>European Commission \[2019b\] Policy and investment recommendations for trustworthy AI, Directorate General for Communications Networks, Content and Technology and High Level Expert Group on Artificial Intelligence, Publications Office, Luxembourg, [https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence](https://ec.europa.eu/digital-single-market/en/news/policy-and-investment-recommendations-trustworthy-artificial-intelligence).
- <a id="Fabry2020"></a>Fabry, R. E. \[2020\] The cerebral, extra-cerebral bodily, and socio-cultural dimensions of enculturated arithmetical cognition, _Synthese_ **197**(9), 3685−3720, doi: [10.1007/s11229-019-02238-1](https://doi.org/10.1007/s11229-019-02238-1).
- <a id="Fink2020"></a>Fink, S. \[2020\](ed.) Special Issue: The neural correlates of consciousness. _Philosophy and the Mind Sciences_ **1**(II), doi: [10.33735/phimisci.2020.II](https://doi.org/10.33735/phimisci.2020.II).
- <a id="Friston2010"></a>Friston, K. \[2010\] The free-energy principle: A unified brain theory? _Nat. Rev. Neurosci._ **11**(2), 127−138.
- <a id="GammaMetzinger"></a>Gamma, A. and Metzinger, T. \[under review\] The Minimal Phenomenal Experience questionnaire (MPE-92M): Towards a phenomenological profile of "pure awareness" experiences in meditators.
- <a id="Gay_etal2011"></a>Gay, P., Schmidt, R. E. and Van der Linden, M. \[2011\] Impulsivity and intrusive thoughts: Related manifestations of self-control difficulties? _Cogn. Ther. Res._ **35**(4), 293−303.
- <a id="Gilbert2016"></a>Gilbert, P. \[2016\] _Human Nature and Suffering_ (Routledge, London).
- <a id="Graziano2017"></a>Graziano, M. S. A. \[2017\] The attention schema theory: A foundation for engineering artificial consciousness, _Front. Robot. AI_ **4**, 60, doi: [10.3389/frobt.2017.00060](https://doi.org/10.3389/frobt.2017.00060).
- <a id="Hafner_etal2020"></a>Hafner, V. V., Loviken, P., Pico Villalpando, A. and Schillaci, G. \[2020\] Prerequisites for an artificial self, _Front. Neurorobot._ **14**, 5, doi: [10.3389/fnbot.2020.00005](https://doi.org/10.3389/fnbot.2020.00005).
- <a id="Hohwy2016"></a>Hohwy, J. \[2016\] The self-evidencing brain, _Noûs_ **50**(2), 259−285.
- <a id="Hohwy2020"></a>Hohwy, J. \[2020\] Self-supervision, normativity and the free energy principle, _Synthese_, doi: [10.1007/s11229-020-02622-2](https://doi.org/10.1007/s11229-020-02622-2).
- <a id="HohwySeth2020"></a>Hohwy, J. and Seth, A. \[2020\] Predictive processing as a systematic basis for identifying the neural correlates of consciousness, PsyArXiv Preprints, doi: [10.31234/osf.io/nd82g](https://doi.org/10.31234/osf.io/nd82g).
- <a id="Holland2020"></a>Holland, O. \[2020\] Forget the bat, _J. Artif. Intell. Conscious._ **7**(1), 83−93, doi: [10.1142/S2705078520500058](https://doi.org/10.1142/S2705078520500058).
- <a id="Horta2010"></a>Horta, O. \[2010\] Debunking the idyllic view of natural processes: Population dynamics and suffering in the wild, _Télos_ **17**(1), 73−88.
- <a id="Iglesias2018"></a>Iglesias, V. \[2018\] The overwhelming prevalence of suffering in nature, _Rev. Bioét. Derecho_ **42**, 181−195.
- <a id="JoffilyCoricelli2013"></a>Joffily, M. and Coricelli, G. \[2013\] Emotional valence and the free-energy principle, _PLoS Comput. Biol._ **9**(6), e1003094, doi: [10.1371/journal.pcbi.1003094](https://doi.org/10.1371/journal.pcbi.1003094).
- <a id="Kanai2017"></a>Kanai, R. \[2017\] We need conscious robots, _Nautilus_, Issue 047, [http://nautil.us/issue/47/consciousness/we-need-conscious-robots](http://nautil.us/issue/47/consciousness/we-need-conscious-robots).
- <a id="KillingsworthGilbert2010"></a>Killingsworth, M. A. and Gilbert, D. T. \[2010\] A wandering mind is an unhappy mind, _Science_ **330**(6006), 932−932, doi: [10.1126/science.1192439](https://doi.org/10.1126/science.1192439).
- <a id="Low_etal2012"></a>Low, P., Panksepp, J., Reiss, D., Edelman, D., Van Swinderen, B. and Koch, C. \[2012\] The Cambridge Declaration on Consciousness, University of Cambridge, [http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf](http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf).
- <a id="Mayerfeld1999"></a>Mayerfeld, J. \[1999\] _Suffering and Moral Responsibility_ (Oxford University Press, New York, NY).
- <a id="Metzinger2000"></a>Metzinger, T. (ed.) \[2000\] _Neural Correlates of Consciousness: Empirical and Conceptual Questions_ (The MIT Press, Cambridge, MA).
- <a id="Metzinger2003a"></a>Metzinger, T. \[2003a\] _Being No One: The Self-model Theory of Subjectivity_ (The MIT Press, Cambridge, MA).
- <a id="Metzinger2003b"></a>Metzinger, T. \[2003b\] Phenomenal transparency and cognitive self-reference, _Phenomenol. Cogn. Sci._ **2**(4), 353−393.
- <a id="Metzinger2008"></a>Metzinger, T. \[2008\] Empirical perspectives from the self-model theory of subjectivity: a brief summary with examples, _Prog. Brain Res._ **168**, 215−245. 273−278, doi: [10.1016/s0079-6123(07)68018-2](https://doi.org/10.1016/s0079-6123(07)68018-2).
- <a id="Metzinger2009"></a>Metzinger, T. \[2009\] _The Ego-Tunnel: The Science of the Mind and the Myth of the Self_ (Basic Books, New York, NY). (Существует перевод на русский: Метцингер Т. \[2017\] _Наука о мозге и миф о своем Я. Тоннель Эго._ (Изд-во АСТ)).
- <a id="Metzinger2013a"></a>Metzinger, T. \[2013a\] The myth of cognitive agency: Subpersonal thinking as a cyclically recurring loss of mental autonomy, _Front. Psychol._ **4**, 931, doi: [10.3389/fpsyg.2013.00931](https://doi.org/10.3389/fpsyg.2013.00931).
- <a id="Metzinger2013b"></a>Metzinger, T. \[2013b\] Two principles for robot ethics, in E. Hilgendorf & J.-P. Günther (eds.), _Robotik und Gesetzgebung: Beiträge der Tagung vom 7. bis 9. Mai 2012 in Bielefeld_ (Nomos, Baden-Baden), pp. 263−302.
- <a id="Metzinger2013c"></a>Metzinger, T. \[2013c\] Why are dreams interesting for philosophers? The example of minimal phenomenal selfhood, plus an agenda for future research, _Front. Psychol._ **4**, 746, doi: [10.3389/fpsyg.2013.00746](https://doi.org/10.3389/fpsyg.2013.00746).
- <a id="Metzinger2015"></a>Metzinger, T. \[2015\] M-Autonomy, _J. Conscious. Stud._ **22**(11−12), 270−302.
- <a id="Metzinger2017"></a>Metzinger, T. \[2017\] Benevolent Artificial Anti-Natalism (BAAN): An EDGE Essay by Thomas Metzinger, July 8, [https://www.edge.org/conversation/thomas_metzinger-benevolent-artificial-anti-natalism-baan](https://www.edge.org/conversation/thomas_metzinger-benevolent-artificial-anti-natalism-baan).
- <a id="Metzinger2018a"></a>Metzinger, T. \[2018a\] Towards a global artificial intelligence charter, in _Should We Fear Artificial Intelligence? In-depth Analysis_ (European Union, Brussels), pp. 27−33, [https://www.europarl.europa.eu/RegData/etudes/IDAN/2018/614547/EPRS_IDA(2018)614547_EN.pdf](https://www.europarl.europa.eu/RegData/etudes/IDAN/2018/614547/EPRS_IDA(2018)614547_EN.pdf).
- <a id="Metzinger2018b"></a>Metzinger, T. \[2018b\] Why is mind wandering interesting for philosophers? in K. C. R.Fox & K. Christoff (eds.), _The Oxford Handbook of Spontaneous Thought: Mind-Wandering, Creativity, and Dreaming_ (Oxford University Press, New York, NY), pp. 97−111.
- <a id="Metzinger2020a"></a>Metzinger, T. \[2020a\] Minimal phenomenal experience, _Philos. Mind Sci._ **1**(I), 1−44, doi: [10.33735/phimisci.2020.I.46](https://doi.org/10.33735/phimisci.2020.I.46).
- <a id="Metzinger2020b"></a>Metzinger, T. \[2020b\] Self-modeling epistemic spaces and the contraction principle, _Cogn. Neuropsychol._ **37**(3−4), 197−210, doi: [10.1080/02643294.2020.1729110](https://doi.org/10.1080/02643294.2020.1729110).
- <a id="Metzinger2018c"></a>Metzinger, T. K. \[2018c\] Why is virtual reality interesting for philosophers? _Front. Robot. AI_ **5**, 101, doi: [10.3389/frobt.2018.00101](https://doi.org/10.3389/frobt.2018.00101).
- <a id="Moor2006"></a>Moor, J. H. \[2006\] The nature, importance, and difficulty of machine ethics, _IEEE Intell. Syst._ **21**(4), 18−21.
- <a id="Nesse2004"></a>Nesse, R. M. \[2004\] Natural selection and the elusiveness of happiness, _Philos. Trans. R. Soc. Lond. B, Biol. Sci._ **359**(1449), 1333−1347.
- <a id="Perkins_etal2015"></a>Perkins, A. M., Arnone, D., Smallwood, J. and Mobbs, D. \[2015\] Thinking too much: Self-generated thought as the engine of neuroticism, _Trends Cogn. Sci._ **19**(9), 492−498.
- <a id="PopulationReferenceBureau2020"></a>Population Reference Bureau \[2020\] Data Sheet 2020, [https://www.prb.org/2020-world-population-data-sheet/](https://www.prb.org/2020-world-population-data-sheet/).
- <a id="Schmidt_etal2011"></a>Schmidt, R. E., Harvey, A. G. and Van der Linden, M. \[2011\] Cognitive and affective control in insomnia, _Front. Psychol._ **2**, 349.
- <a id="SchmidtVanDerLinden2009"></a>Schmidt, R. E. and Van der Linden, M. \[2009\] The aftermath of rash action: Sleep-interfering counterfactual thoughts and emotions, _Emotion_ **9**(4), 549−553.
- <a id="Singer2011"></a>Singer, P. \[2011\] _Practical Ethics_, 3rd ed. (Cambridge University Press, Cambridge).
- <a id="SmallwoodSchooler2015"></a>Smallwood, J. and Schooler, J. W. \[2015\] The science of mind wandering: empirically navigating the stream of consciousness, _Annu. Rev. Psychol._ **66**, 487−518.
- <a id="Trivers2011"></a>Trivers, R. \[2011\] _Deceit and Self-Deception: Fooling Yourself the Better to Fool Others_ (Penguin Books, London, UK).
- <a id="VanDeCruys2017"></a>Van De Cruys, S. \[2017\] Affective value in the predictive mind, in T. K. Metzinger and W. Wiese (eds.), _Philosophy and Predictive Processing_ (MIND Group, Frankfurt am Main), pp. 1−18, doi: [10.15502/9783958573253](https://doi.org/10.15502/9783958573253).
- <a id="VelascoLoev2020"></a>Velasco, P. F. and Loev, S. \[2020\] Affective experience in the predictive mind: A review and new integrative account. _Synthese_, doi: [10.1007/s11229-020-02755-4](https://doi.org/10.1007/s11229-020-02755-4).
- <a id="Vinding2020"></a>Vinding, M. \[2020\] _Suffering-focused Ethics: Defense and Implications_ (Ratio Ethica, Copenhagen), [https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf](https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf).
- <a id="VonHippelTrivers2011"></a>von Hippel, W. and Trivers, R. \[2011\] The evolution and psychology of self-deception, _Behav. Brain Sci._ **34**(1), 1−16, doi: [10.1017/S0140525X10001354](https://doi.org/10.1017/S0140525X10001354).
- <a id="WieseMetzinger2017"></a>Wiese, W. and Metzinger, T. K. \[2017\] Vanilla PP for philosophers: A primer on predictive processing, in T. K. Metzinger & W. Wiese (eds.), _Philosophy and Predictive Processing_ (MIND Group, Frankfurt am Main), pp. 1−18, doi: [10.15502/9783958573024](https://doi.org/10.15502/9783958573024).
- <a id="Windt2015"></a>Windt, J. M. \[2015\] Just in time — Dreamless sleep experience as pure subjective temporality: A commentary on Evan Thompson, in T. K. Metzinger & J. M. Windt (eds.), _Open MIND_ (MIND Group, Frankfurt am Main), pp. 1−34.
- <a id="Yampolskiy2020"></a>Yampolskiy, R. V. \[2020\] Unpredictability of AI: On the impossibility of accurately predicting all actions of a smarter agent, _J. Artif. Intell. Conscious._ **7**(1), 109−118, doi: [10.1142/S2705078520500034](https://doi.org/10.1142/S2705078520500034).
