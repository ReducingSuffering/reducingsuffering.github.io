---
layout: article
title: Что такое уменьшение страданий
unixtime: 
vk: 
authors:
  - К. Кирдан
original_date:
  - 2024.01.02
---
В данной статье мы постараемся доступно и довольно подробно объяснить, что понимается под _уменьшением страданий_ (или, что обычно тоже самое, _минимизацией страданий_) в современном [(негативно) утилитарном](https://reducingsuffering.github.io/71.html) дискурсе.

Поскольку страдания — лишь одна из многих вещей, которые могут волновать людей, тогда как стоящие за их минимизацией соображения по большей части универсальны, данный текст может помочь разобраться в некоторых вопросах [консеквенциализма](https://reducingsuffering.github.io/44.html) в целом и утилитаризма в частности.

Мы рассмотрим такие темы как: отличия между оптимизацией в локальном и глобальном масштабах, отличия между субъективным и объективным качеством принимаемых решений, проблема выбора горизонта планирования, проблема невозможности достоверно предсказывать будущее, инструментальные ценности, приоритизация усилий, комбинации цели уменьшения страданий с другими целями, типичные ошибки и не только.

## Содержание
[1\. Страдания и их количество](#1)<br>
[2\. Что значит "уменьшение"](#2)<br>
[3\. Локальный случай](#3)<br>
[3.1. Субъективно оптимальный выбор](#3.1)<br>
[3.2. Объективное качество выбора](#3.2)<br>
[3.3\. Вероятности наступления событий](#3.3)<br>
[3.4. Время на принятие решений](#3.4)<br>
[4\. Горизонт планирования](#4)<br>
[5. Глобальный случай](#5)<br>
[5.1. Постановка задачи](#5.1)<br>
[5.2. Решение задачи](#5.2)<br>
[5.2.1. Процедуры принятия решений](#5.2.1)<br>
[5.2.2. Инструментальные ценности](#5.2.2)<br>
[5.2.3. Приоритизация](#5.2.3)<br>
[6. Модификации](#6)<br>
[6.1. Дополнительные цели оптимизации](#6.1)<br>
[6.2. Ограничения на способы оптимизации](#6.2)<br>
[6.3. Ограничения морального круга](#6.3)<br>
[7. Некоторые ошибки](#7)<br>
[7.1. Отсутствие сравнений](#7.1)<br>
[7.2. Предубеждения о приоритетах](#7.2)<br>
[Источники](#sources)<br>
[Что еще почитать](#further)

---
<a name="1"></a>
## 1. Страдания и их количество

В данном тексте мы не будем углубляться в вопрос о природе страданий и опустим подробные объяснения вопросов о сравнениях и численном оценивании страданий для индивидов и сообществ. Это темы для отдельных статей. Здесь мы лишь кратко приведем самое главное.

Страдания — это некоторая разновидность переживаний. Чаще всего имеются в виду все те переживания, которые обычно зовут "отрицательными": их примерами являются [боль](https://plato.stanford.edu/entries/pain/), печаль, страх, раздражение, тревога и злость. Но иногда в качестве страданий рассматриваются не все отрицательные переживания, а лишь какая-то наиболее проблематичная их часть.

Одни страдания могут быть хуже, чем другие. Самый простой (хотя и не единственный) способ выразить, что одни из них хуже других — это ввести числовые оценки _интенсивности_ страданий. Чем выше интенсивность страдания — тем оно хуже. Если целью является _лишь уменьшение страданий_, то переживания, не являющиеся страданиями, оцениваются нулевым значением.

Для принятия решений нам нужно не только оценивать отдельные переживания, но также и понимать, _сколько_ страданий переживалось тем или иным лицом с течением времени, а также целым сообществом лиц. Составление такой общей оценки на основе оценок отдельных моментов называется _[агрегацией](https://en.wikipedia.org/wiki/Aggregate_function)_, и наиболее известны три ее разновидности:
1. Cумма оценок всех мгновений;
2. Cредняя величина от оценок всех мгновений (т. е. сумма, поделенная на общее число мгновений);
3. Оценка наихудшего из всех мгновений.

Как правило, с понятием "[утилитаризма](https://reducingsuffering.github.io/337.html)" связывают лишь первые два вида агрегации, но наши дальнейшие рассуждения применимы и для прочих видов.

Важно отметить, что в жизни мы не имеем прямого доступа к переживаниям других персон, не уверены насчет того, кто вообще может страдать, не имеем общего стандарта для оценки переживаний и, как правило, редко пользуемся числами.

Однако это не мешает нам выносить интуитивные предположения о том, где и когда страданий больше, а где меньше — на основании ограниченных данных и предположений вроде такого: похожие существа испытывают похожие переживания, если попадают в похожие обстоятельства и похожим образом реагируют на них.

<a name="2"></a>
## 2. Что значит "уменьшение"

Начнем с небольших простых примеров, когда люди могут считать, что чье-то страдание было уменьшено:
1. Человек принял обезболивающее, чтобы уменьшить свою головную боль;
2. Страдающий от какого-то психического заболевания сходил на сеанс психотерапии и на некоторое время почувствовал себя лучше, чем в предыдущие дни;
3. Один человек помог перейти дорогу другому человеку, который стоял и переживал.

Что объединяет все эти ситуации?

Кто-то совершает поступок, в результате которого то или иное страдание той или иной персоны прекращается. Возможно, ему на смену приходит другое страдание, но оно меньше по сравнению с тем, что было. Поэтому можно сказать, что страдания в результате поступка _уменьшились_ по сравнению с тем, что _испытывалось_ до этого.

Однако такое простое значение фразы "уменьшение страданий" само по себе крайне далеко от того, к чему призывает консеквенциалистская [этика противодействия страданию](https://magnusvinding.com/2020/05/31/suffering-focused-ethics-defense-and-implications/) (такая как [негативный утилитаризм](https://reducingsuffering.github.io/what-is-negative-utilitarianism.html)), хотя и может быть согласовано с ее требованиями. В ней "уменьшение" сводится к тем или иным стратегиям "минимизации", и целью ставится **минимизация страданий** в глобальном масштабе: добиваться того, чтобы во всем совокупном будущем — во все времена и во всех местах, доступных для влияния — _агрегированные страдания_ всех существ были _настолько малы, насколько этого возможно достигнуть_.

Перечислим основные отличия этой идеи от приведенных нами ранее примеров:

1\. Сравниваются не разные последовательные участки одной временной шкалы (типа вчерашнего дня и сегодняшнего), а _разные варианты_ того, что _могло бы произойти_ в будущем;<br>
2\. Последствия учитываются:<br>
2.1. Не только для какого-то одного человека или животного, а для всех _сентиентных_ (способных страдать) существ;<br>
2.2. Не в каком-то отдельном месте (вроде одной страны или одной планеты), а во _всех достижимых_ для нашего влияния местах;<br>
2.3. Не в какой-то ограниченной и краткой временной перспективе (типа дня или столетия), а для _всех будущих_ достижимых для нашего влияния времен;<br>
2.4. Не в рамках какого-то одного выбранного сценария будущего (где якобы "все пойдет по плану"), а _с учетом вариативности_;

3\. Это не то, что можно сделать один раз и забыть, а скорее _повторяющийся в течение жизни_ вид поведения.

Для полного объяснения этой идеи нам придется сначала изложить ряд вспомогательных соображений.

<a name="3"></a>
## 3. Локальный случай

Перед тем, как мы сможем доступно описать идею уменьшения страданий в _глобальном_ смысле, нам нужно рассмотреть задачи _локального_ (узкомасштабного) уменьшения страданий, поскольку они более просты в постановке и изучении. В дальнейшем мы объясним, что с ними не так и почему последовательный утилитаризм подразумевает нечто большее, чем просто локальную минимизацию страданий.

<a name="3.1"></a>
### 3.1. Субъективно оптимальный выбор

Представим себе, что есть некоторый вид схожих друг с другом и _ограниченных в пространстве и времени_ ситуаций (обстоятельств, положений дел), в которые могут попасть люди или иные _агенты_ (действующие лица).

Например, у вас заболела голова, или вы врач и принимаете пациента, или вы ведете машину и проезжаете перекресток, или вы размышляете о том, кому из своих знакомых пожертвовать тысячу рублей, или вы — водитель вагонетки в знаменитой [проблеме вагонетки](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0_%D0%B2%D0%B0%D0%B3%D0%BE%D0%BD%D0%B5%D1%82%D0%BA%D0%B8).

Итак, пусть мы выбрали какой-то конкретный вид схожих ситуаций. Можно представить, что в ситуациях такого вида разные агенты в принципе могли бы повести себя по разному. Например, разные врачи могут немного по разному вести прием пациентов — проявляя разный уровень вежливости, применяя разные медикаменты и приборы, и т. п. Более того, законы физики не запрещают врачу, например, начать плясать и петь во время приема. С другой стороны, агенты могут быть ограничены чем-то еще, если уменьшение страданий — не их единственная цель. Например, врач, как правило, имеет имеет цели не покалечить и не убить пациента (если только он не эвтаназиолог) в процессе приема.

Во всяком случае, нам нужно представить, что в рассматриваемой ситуации попавший в нее агент — главный герой нашей истории — теоретически мог бы вести себя более чем каким-то одним фиксированным способом. В частности, он может сознательно задумываться о выборе того, как ему поступить, рассматривая какие-то варианты A, B, C и т. д., и _предсказывая последствия_ для всех этих вариантов, _как если бы_ они произошли в реальности (см. понятия _[контрфактуалов](https://bigenc.ru/c/kontrfaktual-noe-myshlenie-41076d)_ и _[возможных миров](https://knife.media/possible-worlds/)_ для более полного и разностороннего погружения в идею "могло бы быть иначе".).

Возможно, что разные варианты поведения агента привели бы к разному количеству страданий у тех или иных участников ситуации. Например, от действий врача, очевидно, частично зависит то, какую боль будет испытывать на приеме пациент. От вашей реакции на головную боль зависит то, как долго она продлится. А от выбора, кому из ваших знакомых пожертвовать деньги, зависит то, что будут испытывать эти знакомые.

Итак, представляя разные варианты возможного развития событий и разные итоги этого развития — в виде количества страданий в течение какого-то времени у лиц, благополучие которых нас интересует — мы можем задаться вопросом о том, в каких случаях страданий _меньше_, а в каких — больше. Если агент, попавший в ситуацию, задается этим вопросом и пытается действовать так, чтобы страдание было _как можно меньшим_, можно сказать, что он пытается _минимизировать_ страдание в рамках ситуации или, что тоже самое, _уменьшить_ страдание (в рамках ситуации) _по сравнению_ с альтернативными путями развития событий.

Это означает, что агент решает определенную [задачу оптимизации](https://en.wikipedia.org/wiki/Mathematical_optimization), где целевая функция оценивает количество страданий, а целью является минимально возможное значение этой функции; возможно, с дополнительными ограничениями на множество допустимых решений. Важно отметить, что минимум не всегда нулевой — опции с нулевым значением может просто не быть среди возможных.

Но что, если я, рассматривая ситуацию, вижу одни варианты поведения агента и исходы, а другой человек — совсем другие? Что, если мы по разному предсказываем, что именно произойдет в результате того или иного выбора агента, имеем разное мнение о том, какие варианты выбора вообще нужно рассматривать, и, что хуже всего, по разному решили бы эту задачу, если бы находились на месте агента? Кто из нас прав? И что мы имеем в виду, говоря "_прав_"?

<a name="3.2"></a>
### 3.2. Объективное качество выбора

Агент может сознательно решать задачу минимизации страданий в той или иной ситуации, но серьезно ошибаться, несмотря на субъективную оптимальность его решения. Как понять, насколько он ошибается? Для этого нам понадобятся _объективные_ меры качества решений.

Поскольку ситуации того или иного рассматриваемого нами вида могут происходить с совершенно разными агентами (возможно, даже неоднократно), и поведение этих агентов может отличаться, в принципе возможно сравнить их и заметить, что, в общем случае могут отличаться:
1. Набор рассматриваемых вариантов возможного поведения;
2. Принятое решение вести себя тем или иным образом;
3. Результаты (т. е. количество страданий);
4. Качество предсказаний (т. е. разница между тем, что они предсказывали, и что реально случилось в результате выбранного поведения).

Важно, что мы не должны ограничиваться рассмотрением лишь тех агентов, цели которых совпадают с минимизацией страданий. В подобные ситуации могут попадать агенты и с другими целями, но мы все равно можем использовать их опыт для понимания того, как в реальности работают те или иные поступки.

Итак, порой для оценки того, насколько _объективно_ хорошо тот или иной агент решает задачу, мы можем сравнивать его с другими агентами в похожих ситуациях и оценивать, насколько малого числа страданий по сравнению с другими ему удалось добиться. Например, врач, занимающийся обезболиванием, может обратиться к опыту своих коллег или к соответствующей литературе со статистикой.

Но что делать, если никаких данных о других агентах в схожих ситуациях нет? Например, если никто никогда еще не оказывался в подобной ситуации? Приведем пару соображений на этот счет.

Во-первых, если задачу можно разбить на подзадачи, качество решений которых (данным агентом) поддается оценке, то и качество решения большой задачи можно оценить через качество решения ее подзадач, т. к. оно от них прямо зависит.

Во-вторых, поскольку качество решения задачи зависит от качества предсказаний, а качество предсказаний зависит от того, насколько хорошей моделью реальности обладает агент, мы можем сфокусироваться на оценке качества модели реальности этого агента в целом или тех ее частей, которые кажутся наиболее релевантными для рассматриваемой задачи.

Например, если задача, по-видимому, требует владения биоинформатикой, мы можем предположить, что агенты, которые (насколько нам известно) хорошо разбираются в биоинформатике, решают ее лучше тех, кто плохо в ней разбирается.

P. S. Для углубления в тему см. дискуссии об [объективном консеквенциализме против субъективного](https://philpapers.org/browse/objective-and-subjective-consequentialism) и [максимизирующем против удовлетворяющего](https://philpapers.org/browse/maximizing-and-satisficing-consequentialism).

<a name="3.3"></a>
### 3.3. Вероятности наступления событий

Мы не всегда можем с хорошей вероятностью предсказывать последствия нашего выбора. И даже когда у нас это получается, у нас нет детальных карт переживаний существ, благополучие которых нас интересует. В частности, мы можем вообще сомневаться в том, что они сентиентны, в то же время не имея полной уверенности и в обратном.

Однако, для принятия решений нам необязательно детально предсказывать будущее. Мы можем рассматривать два или больше варианта того, что произойдет в результате того или иного нашего выбора. Как же в таких случаях сравнивать разные варианты выбора, чтобы хорошо решать поставленную задачу?

Условия, при которых мы предполагаем более одного возможного исхода у одного и того же выбора, называются _условиями риска_, если мы, по крайней мере, имеем те или иные  _субъективные вероятности_ (степени уверенности) наступления каждого из исходов. И называются _условиями неопределенности_, если таких вероятностей у нас нет, или, что еще хуже — нет идей, что вообще может произойти.

Разработано множество _[теорий принятия решений](https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq)_, чтобы объяснить, как нам лучше поступать в различных ситуациях, чтобы добиваться той или иной цели. 

Что делать, если мы находимся в условиях неопределенности? Для некоторых видов таких задач могут существовать специфические для них приемы, которые обычно хорошо работают. Но в общем случае лучше перейти к условиям риска, попытавшись определить наиболее правдоподобные варианты последствий для каждого из вариантов выбора и оценить вероятности наступления этих последствий.

В контексте условий риска рассмотрим один, наиболее известный принцип — _[максимизацию ожидаемой полезности/ценности](https://www.cold-takes.com/expected-value/)_, обоснованный в [работе](https://reducingsuffering.github.io/347.html) фон Неймана и Моргенштерна.

Пусть мы должны сделать выбор между вариантами A и B, где у варианта A возможны исходы, имеющие ценность (полезность) a<sub>1</sub>, a<sub>2</sub>, ..., a<sub>n</sub> с вероятностями p<sub>1</sub>, p<sub>2</sub>, ..., p<sub>n</sub> соответственно, а у варианта B — исходы, имеющие ценность b<sub>1</sub>, b<sub>2</sub>, ..., b<sub>m</sub> с вероятностями q<sub>1</sub>, q<sub>2</sub>, ..., q<sub>m</sub> соответственно. Тогда мы составляем оценки _ожидаемой ценности (полезности)_ f для вариантов A и B по формулам f(A) = p<sub>1</sub>a<sub>1</sub> + p<sub>2</sub>a<sub>2</sub> + ... + p<sub>n</sub>a<sub>n</sub> и f(B) = q<sub>1</sub>b<sub>1</sub> + q<sub>2</sub>b<sub>2</sub> + ... + q<sub>m</sub>b<sub>m</sub> соответственно. Согласно принципу, лучшим из этих решений будет то, у которого максимальная ожидаемая ценность f. В случае большего числа вариантов выбора все аналогично — нужно будет оценить ожидаемую ценность f(X) для каждого варианта X и выбрать вариант с наибольшей из них.

Поскольку в качестве цели мы рассматриваем уменьшение страданий, ценность того или иного исхода будет равна количеству страданий, взятому с отрицательным знаком. Таким образом, максимизация ожидаемой ценности будет превращаться в _минимизацию ожидаемых страданий_.

По какой причине рекомендованы именно такие формулы?

Есть две основные группы причин. Во-первых, [можно показать](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem), что такой ход мышления будет наименее противоречив с точки зрения некоторых довольно убедительных предпосылок. Во-вторых, [можно убедиться](https://reducing-suffering.org/why-maximize-expected-value/) путем сбора статистики на практике или путем статистического моделирования, что при многократном принятии решений в ситуациях с соответствующими распределениями вероятностей и исходами, именно формула ожидаемой ценности будет оптимальна среди [функций](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0)) от вероятностей и ценностей исходов.

В жизни мы не всегда имеем возможность производить подобные расчеты в явном виде, но можем позаботиться о том, чтобы наши более грубые, интуитивные методы принятия решений приближались к этому идеалу. Например, при оценке некоторого плана действий, мы должны учитывать не только то, с какой вероятностью что-то может пойти не так, но и то, каковы будут последствия нашей неудачи (поскольку в формуле вероятность _умножается_ на ценность исхода). Даже крайне маловероятные последствия возможной неудачи, если они достаточно масштабны, могут сделать план неоправданным.

Важно отметить, что принцип максимизации ожидаемой ценности не идеален. Порой вместо него или в дополнение к нему есть смысл обращаться к другим приемам из [теории игр](https://reducingsuffering.github.io/245.html) и иных [теорий принятия решений](https://casparoesterheld.com/a-comprehensive-list-of-decision-theories/). В частности, у описанного принципа возникают проблемы в случаях, когда [другие агенты могут предсказывать ваш выбор еще до того, как вы его сделаете](https://lesswrong.ru/w/%D0%9F%D0%B0%D1%80%D0%B0%D0%B4%D0%BE%D0%BA%D1%81_%D0%9D%D1%8C%D1%8E%D0%BA%D0%BE%D0%BC%D0%B0_%D1%81%D0%BE%D0%B6%D0%B0%D0%BB%D0%B5%D1%8F_%D0%BE_%D1%81%D0%B2%D0%BE%D0%B5%D0%B9_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8), и в ситуациях [коллективного принятия решений](https://www.jstor.org/stable/20010532), подобных голосованию на выборах. Помимо этого, вопросы о границах его применимости вызывает мысленный эксперимент "[ограбление Паскаля](https://en.wikipedia.org/wiki/Pascal%27s_mugging)".

<a name="3.4"></a>
### 3.4. Время на принятие решений

До сих пор мы говорили о задачах оптимизации упрощенно, как если бы все сводилось лишь к тому, чтобы выбрать лучший из вариантов, набор которых уже известен. Однако, если ситуация не требует от нас мгновенной реакции, то реальная задача, которую мы решаем, выглядит несколько сложнее. Ведь как сам набор вариантов дальнейшего поведения, так и оценки того, насколько хороши те или иные варианты, могут меняться в процессе наших размышлений или просто пассивного ожидания.

Например, мы можем иметь задачу вида "за 10 минут найти наилучшую стратегию поведения для следующих 20 минут, и придерживаться ее". Изначально мы можем даже не иметь никаких вариантов кроме "подумать еще" и "ничего не делать / ждать". А в процессе обдумывания перед нами может стоять выбор между "подумать над расширением числа вариантов стратегий", "уточнить оценку последствий для стратегии A, B или C", "перейти к ожиданию" или "закончить размышления, выбрав стратегию, которая оптимальна при текущих оценках".

Мы не будем углубляться в подробности и лишь упомянем, что в подобных задачах пригождаются такие величины как [ценность опций](https://forum.effectivealtruism.org/topics/option-value) (ценность наличия выбора, пока он не стал бесповоротным) и [ценность информации](https://forum.effectivealtruism.org/posts/8w2hNT5WtDMzoaGuy/when-to-find-more-information-a-short-explanation) (то, насколько сильно новая информация может повлиять на оценки вариантов — и в результате на выбор). Подобные вопросы рассматриваются также в теме [ограниченной рациональности](https://plato.stanford.edu/entries/bounded-rationality/).

<a name="4"></a>
## 4. Горизонт планирования

До сих пор, рассуждая об уменьшении страданий в тех или иных ситуациях, мы не поднимали вопроса о том, в каком именно масштабе нам лучше было бы производить агрегацию для оценки уровня страданий.

Какими вообще могут быть масштабы агрегации?

Мы можем оценивать последствия наших действий в краткосрочной или долгосрочной перспективе, от минут до вечности. Мы можем оценивать их только для тех, кто уже существует, или также для тех, кто еще не появился на свет. Мы можем оценивать их для одного человека или для нескольких, или для сообщества людей, или для всего человечества. Мы можем оценивать их для других животных или обитателей иных планет.

Так или иначе, речь идет о разных участках пространства-времени, в которых обитают или будут обитать те, чье благополучие нас интересует.

Что, если перед тем, как выбирать поступок, нам нужно выбрать, на каком участке действительности вообще рассматривать последствия нашего поступка? Зачем вообще задаваться таким вопросом?

Что может быть плохого в том, что мы уменьшаем страдания в каком-то одном выбранном нами участке пространственно-временной действительности? Проблема в том, что уменьшая их в одном участке, мы можем одновременно увеличивать их в каком-то другом. Более того, в некотором смысле мы _почти всегда_ [именно это и делаем](https://kkirdan.github.io/blog/a2.html).

Чтобы понять, почему это так, рассмотрим для начала случай, когда мы решаем, пустить ли единицу нашего ресурса на уменьшение страданий на одном участке действительности A, или же на другом участке B, отличном от него. Предположим, что наш выбор имеет разные последствия для этих участков. Тогда если мы вкладываем в A, мы при этом _упускаем_ возможность вложить ресурс в B. Это и означает, что выбрав вложиться в A, мы _увеличили_ страдания в B по сравнению с той альтернативой, в которой мы _вложили бы_ весь ресурс в B. 

Так, если мы делаем пожертвование на борьбу с бедностью в городе X (в перспективе ближайших N лет), мы упускаем возможность пожертвовать эти же деньги на уменьшение страданий подневольных животных в стране Y (в перспективе ближайших M лет). И наоборот — жертвуя на помощь животным, мы упускаем возможность помочь людям.

Конечно, мы можем рассматривать два участка действительности вместе, как один участок, и задуматься над тем, как уменьшить агрегированные страдания на всем этом участке. Разумеется, это не значит, что мы перестанем увеличивать страдания на обоих этих участках _по отдельности_ по сравнению со сценариями, где мы отдали какому-то одному из них все свои ресурсы. Однако, мы будем уменьшать их _в целом_ на более крупном участке действительности и, по крайней мере, это будет выглядеть менее морально предвзятым решением.

Например, мы можем измерить эффект от каждого дополнительно вкладываемого доллара для двух разных организаций и распределить свои средства между ними так, чтобы суммарный эффект был наибольшим (в самом простом случае может оказаться, что лучше вложить все средства в ту из этих организаций, эффективность которой выше).

Однако, в целом проблема локальной направленности наших действий никуда не делась. Да, в конкретной ситуации выбора мы решили объединить разные участки действительности в один, чтобы оценить агрегированный эффект от наших действий на этом большем участке. Но мы все еще игнорируем те участки действительности, которые _просто не рассматривались_ в ситуации выбора изначально.

Выбирая лишь между помощью одному человеку или другому, мы игнорируем всех прочих людей, которым можно было бы помочь. Выбирая между помощью слепым и помощью людям на предсмертном одре, мы игнорируем людей с иными проблемами и в иных обстоятельствах. Выбирая между помощью подневольным животным или людям, мы игнорируем диких животных, а также тех существ искусственного происхождения, которые могут прийти на смену людям в будущем.

При этом мы _не можем_ гарантированно избежать того или иного влияния на другие участки пространства-времени помимо тех, что у нас под носом. Все в мире взаимосвязано и последствия наших действий могут распространяться очень далеко в пространстве и времени. Более того, наличие в мире множества [хаотических систем](https://journals.sagepub.com/doi/10.1177/001872679304600701) означает, что последствия некоторых действий могут быть крайне масштабными, но при этом почти непредсказуемыми.

Получается, что если мы будем необоснованно ограничивать свой горизонт планирования теми или иными локальными участками пространства-времени, мы рискуем нарушить один из базовых принципов утилитарной этики —  _принцип равного рассмотрения интересов_ (также известный как _[принцип непредвзятости](https://utilitarianism.net/types-of-utilitarianism/)_). В нашем случае он подразумевает, что одинаковые страдания должны иметь для нас одинаковую важность, независимо от того, как далеко в пространстве и времени друг от друга они расположены.

Поэтому встает справедливый вопрос: можно ли каким-то образом принимать решения так, чтобы они были оптимальны не для каких-то узких участков действительности, а для всего доступного для нашего влияния пространства-времени?

<a name="5"></a>
## 5. Глобальный случай

Что будет, если наш горизонт планирования станет неограниченным? Или, если это невозможно, какой выбор горизонта планирования наиболее обоснован с точки зрения принципа равного рассмотрения интересов?

<a name="5.1"></a>
### 5.1. Постановка задачи

Предположим, что мы рассматриваем два варианта поведения, A и B, пошагово увеличивая горизонт планирования как в пространстве, так и во времени. Например, сначала мы спросим, что уменьшает страдания в масштабе одного дня и одного человеческого поселения, затем — в масштабе одного года и одной страны, и т. д., с каждым шагом захватывая все больше и больше от пространства-времени для своего планирования.

Сойдется ли такой процесс размышлений к какой-либо одной из стратегий A или B?

Заметим, речи не идет о том, чтобы с каждым шагом увеличивались еще и наши знания о вселенной. Нет, сейчас мы хотим понять, можно ли при _ограниченном объеме знаний_ и _ограниченном объеме ресурсов_ в принципе корректно поставить вопрос о глобальном уменьшении страданий во вселенной.

При некоторых начальных предположениях — да. По крайней мере, если мы полагаем объем и временную протяженность потенциально обитаемой части вселенной ограниченными, то начиная с какого-то шага ответ перестанет меняться.

Однако, если мы предполагаем, что вселенная в том или ином отношении бесконечна (в пространственных измерениях или во времени), и общее число сентиентных существ в ней тоже может оказаться бесконечным, то у нас возникают [серьезные затруднения](https://nickbostrom.com/ethics/infinite.pdf) при попытке оценить страдания. Так, если в качестве метода агрегации мы используем суммирование, то все оценки ожидаемых страданий будут стремиться к бесконечности, и мы не сможем ими пользоваться. В этом случае, как минимум, требуется доработка способов оценки страданий, и на этом пути нам [придется пожертвовать](https://askell.io/files/Askell-PhD-Thesis.pdf) какими-то из наших исходных моральных интуиций.

С другой стороны, мы можем предположить, что даже если вселенная бесконечна, _сфера нашего потенциального влияния_ конечна. Так, согласно теории относительности нельзя двигаться быстрее скорости света, и это накладывает некоторые ограничения на то, [какую часть вселенной](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D0%B5%D1%82%D0%BE%D0%B2%D0%BE%D0%B9_%D0%BA%D0%BE%D0%BD%D1%83%D1%81) мы способны затронуть. Кроме того, сфера нашего влияния на будущее может быть физически ограничена событиями вроде [тепловой смерти](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BF%D0%BB%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%BC%D0%B5%D1%80%D1%82%D1%8C_%D0%92%D1%81%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9) вселенной или [большого разрыва](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%BE%D0%B9_%D1%80%D0%B0%D0%B7%D1%80%D1%8B%D0%B2). В таких случаях можно было бы просто отбросить из наших расчетов все, на что невозможно повлиять.

Впрочем, здесь возможна неожиданная проблема. Представим себе, что где-то за пределами нашей зоны влияния есть агент, столь интеллектуально похожий на вас, что ваши с ним решения и сами методы принятия решений в некотором классе похожих ситуаций совпадают (при этом в целом у него вовсе не обязательно такая же цель оптимизации, как у вас). Следует ли считать, что в этих ситуациях последствия действий таких похожих на вас агентов (которых может быть и бесконечное число) — являются также и _последствиями ваших собственных действий_? И если они тоже осознали это, можете ли вы все вместе [сделать что-то](https://longtermrisk.org/multiverse-wide-cooperation-via-correlated-decision-making/), чтобы повысить качество всех этих ваших решений?

В конце концов, мы [можем усомниться](https://reducing-suffering.org/believe-infinity/) в том, что бесконечности вообще реальны. Но к сожалению, если мы допускаем хотя бы ненулевую вероятность того, что ошибаемся в этом, и что способны повлиять на бесконечные масштабы, перед нами снова будет вставать обозначенная проблема. В итоге получится, что мы находимся в положении, похожем на знаменитое [пари Паскаля](https://ru.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B8_%D0%9F%D0%B0%D1%81%D0%BA%D0%B0%D0%BB%D1%8F). Должны ли мы _ставить всё_ на вариант, предполагающий бесконечность нашего влияния?

В любом случае, как для уточнения формулировки самой задачи глобального уменьшения страданий с учетом наших наиболее важных интуиций, так и для ее решения, нам нужно систематически работать над улучшением своих _[методов познания](https://ru.wikipedia.org/wiki/%D0%AD%D0%BF%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F)_ и _[моделей реальности](https://lesswrong.ru/%D0%9A%D0%B0%D1%80%D1%82%D0%B0_%D0%B8_%D1%82%D0%B5%D1%80%D1%80%D0%B8%D1%82%D0%BE%D1%80%D0%B8%D1%8F)_, чтобы _повысить шансы_ на то, что мы движемся в верном направлении (при условии что такое направление вообще существует).

<a name="5.2"></a>
### 5.2. Решение задачи

Итак, предположим, что та или иная постановка задачи глобального уменьшения страданий — подразумевает ли она только конечную _зону ответственности_, или бесконечную, или какую-то их комбинацию — корректна. Есть ли какие-то догадки о том, как ее решать?

Мы не будем сильно углубляться в эту тему, однако обратим внимание на ряд важных моментов, чтобы интересующимся было с чего начать свой поиск.

<a name="5.2.1"></a>
#### **5.2.1. Процедуры принятия решений**

Начнем с одного естественного предположения: всегда, когда нам нужно сделать выбор, для оценки каждого сценария будущего нам нужно оценить количество ожидаемых страданий по всей зоне ответственности.

Такая формула может привести к избыточным вычислениям. Ведь для того, чтобы понять какой вариант лучше, нам достаточно оценить _разницу_ в количествах страданий, а не _всё_ количество страданий для всех рассматриваемых вариантов. В частности, если мы не имеем вообще никакой релевантной информации о тех или иных участках пространства-времени (например, об иных планетах или о будущих тысячелетиях), они не влияют на оценку разницы, поэтому можно [исключать](https://forum.effectivealtruism.org/topics/cluelessness) их из расчетов. Конечно, если у нас есть хоть какие-то догадки, склоняющие чашу весов в ту или иную сторону, нам следует их учитывать.

Предложим более скромную формулировку: всегда, когда нам нужно выбрать один из нескольких вариантов поступка, для упорядочивания вариантов от лучшего к худшему нужно оценивать отличие между ними в количестве ожидаемых страданий по всей зоне ответственности.

Такой подход все еще выглядит слишком требовательным, не соответствуя реальным возможностям людей. Скорее, оптимальный подход подразумевает использование [разных процедур](https://forum.effectivealtruism.org/posts/voDm6e6y4KHAPJeJX/act-utilitarianism-criterion-of-rightness-vs-decision) принятия решений в разных классах ситуаций, и обозначенный принцип нужно применять лишь в части случаев. Например, вам вряд ли нужно ставить перед собой подобный вопрос, когда вы решаете какую обувь вам надеть, взять ли зонт на улицу и т. п. С другой стороны, он скорее всего уместен, когда вы решаете, в какую организацию пожертвовать свои деньги или как устроить свою дальнейшую карьеру.

Вопрос о том, когда какие процедуры нам лучше использовать, можно считать во многом открытым. Некоторые попытки решить этот вопрос предлагаются в теориях [многоуровневого консеквенциализма](https://utilitarianism.net/types-of-utilitarianism/#multi-level-utilitarianism-versus-single-level-utilitarianism). Однако, отсутствие у нас идеала принятия решений не значит, что мы вообще не можем ни о чем судить. Мы вполне можем судить о том, что какие-то методы работают лучше или хуже для каких-то классов задач, и можем переключаться между разными видами методов по ситуации. Тем не менее, покуда наши представления о [рациональности](https://lesswrong.ru/w/%D0%A7%D1%82%D0%BE_%D1%82%D0%B0%D0%BA%D0%BE%D0%B5_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C) неидеальны, стоит выделять те или иные ресурсы на то, чтобы перепроверять свои принципы и искать или разрабатывать более эффективные альтернативы.

Отдельно стоит отметить, что нам нужно учиться распознавать ситуации, в которых локальный эффект от наших действий [пренебрежимо мал по сравнению с глобальным](https://www.effectivealtruism.org/articles/longtermism) (например, с последствиями в далеком будущем), и может иметь даже противоположную направленность. В частности, если у нас есть соображения в пользу того, что у некоторого выбора будут какие-то систематические позитивные и негативные последствия (по сравнению с альтернативным вариантом) в отдаленных участках пространства-времени, но мы не можем понять, какие из них более значимы, следует уделить особое внимание дальнейшему исследованию этого вопроса.

<a name="5.2.2"></a>
#### **5.2.2. Инструментальные ценности**

Поскольку идея уменьшения страданий основана на отрицательности (негативности) определенного класса явлений (страданий), может сложиться впечатление, будто ее реализация сводится к расчетам о том, как _чего-то избежать_. Помимо этого, может казаться, что уменьшение страданий в глобальном масштабе можно эффективно свести к отдельным актам уменьшения страданий в локальных, малых масштабах. Однако, и то, и другое неверно.

Оптимизация в сколько-нибудь крупном масштабе требует использования сложной системы _[инструментальных ценностей](https://streetepistemology.ru/instrumentalnie-i-terminalnie-tsennosti)_, подразумевающей как необходимость накопления чего-либо (а значит, решения задач максимизации, а не минимизации), так и необходимость соблюдения тех или иных ограничений на способы оптимизации.

Так, согласно [тезису](https://www.lesswrong.com/tag/instrumental-convergence) об _инструментальной конвергенции_ (верному как для людей, так и для искусственных агентов) — для уменьшения страданий, как и для почти _любых иных целей_, важны:
1. Самосохранение (очевидно, вы больше не можете уменьшать чужое страдание, если уже мертвы);
2. Сохранение целостности цели (сопротивление изменению главной цели на что-то другое — например, избегание употребления веществ, несущих существенный риск усилить ваши эгоистические тенденции);
3. Самосовершенствование (включая развитие своих приемов мышления, улучшение привычек и заботу о здоровье);
4. Накопление рычагов влияния на мир (например, материальных ресурсов, информации, [репутации и социального капитала](https://www.centreforeffectivealtruism.org/blog/considering-considerateness-why-communities-of-do-gooders-should-be)).

Помимо этого, множеством авторов отмечается важность полноценной [насыщенной и здоровой](https://reducingsuffering.github.io/magnus-vinding-suffering-focused-ethics-and-the-importance-of-happiness.html) жизни, [кооперативного настроя](https://centerforreducingsuffering.org/research/why-altruists-should-be-cooperative/) в отношении людей с другими ценностями ([даже](https://longtermrisk.org/reasons-to-be-nice-to-other-value-systems/) если им неинтересно уменьшение страданий), [уважения чужих прав](https://lesswrong.ru/w/%D0%9E_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%B5_%D0%BB%D1%8E%D0%B1%D0%B5%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%BE%D0%B1%D1%89%D0%B8%D0%BD_%D0%B8_%D1%86%D0%B8%D0%B2%D0%B8%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8), [миролюбия и ненасилия](https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism).

Более того, многие авторы отмечают, что такие на первый взгляд отличающиеся от консеквенциализма подходы как распространенные виды [деонтологии](https://plato.stanford.edu/entries/ethics-deontological/) и [этики добродетелей](https://reducingsuffering.github.io/46.html) — могут служить [аппроксимациями консеквенциализма](https://forum.effectivealtruism.org/posts/aDNPgm2v2boBbj8wK/deontology-and-virtue-ethics-as-effective-theories-of) даже лучше, чем слишком [наивно интерпретированный](https://reducingsuffering.github.io/157.html) консеквенциализм.

Итак, мы упомянули ряд ценностей, которые требуют сохранения и накопления, а также ограничений, которые следует соблюдать. Но как конвертировать накапливаемые ресурсы в уменьшение страданий?

<a name="5.2.3"></a>
#### **5.2.3. Приоритизация**

Как понять, сколько и на какие проекты стоит тратить ресурсов? В частности, в какой сфере выбрать [образование и карьеру](https://reducingsuffering.github.io/368.html)? В какие организации жертвовать свободные деньги? На какие темы писать статьи? Какие идеи обсудить с друзьями?

Подобные вопросы исследуют [эффективные альтруисты](https://ea-ru.org/articles/introduction-to-effective-altruism). Мы кратко обрисуем один из предлагаемых ими подходов к расстановке приоритетов. Согласно [этому подходу](https://80000hours.org/articles/problem-framework/) значимость того или иного проекта для уменьшения страданий оценивается на основе следующих трех параметров:
1. Масштаб рассматриваемой проблемы (количество страданий, порождаемых проблемой);
2. Недооцененность (насколько мало ресурсов сейчас пущено на решение проблемы);
3. Легкость решения (насколько велика доля проблемы, решаемой путем вклада единицы ресурса).

Проект тем важнее, чем больше масштаб проблемы, чем сильнее ее недооцененность, и чем легче она решается. К сожалению, описанные величины будут поддаваться хорошей оценке лишь в некоторых случаях — например, при анализе эффективности благотворительных организаций. В случаях, которые фокусируются на попытках повлиять на далекое будущее или предполагают исследовательскую работу, оценки делать намного сложнее. Однако, даже наши интуитивные оценки этих величин могут помочь.

Несложно разглядеть сходство этого подхода с описанным нами ранее принципом максимизации ожидаемой полезности (минимизации ожидаемых страданий).

<a name="6"></a>
## 6. Модификации

В этом разделе мы кратко обрисуем, какими могут быть нормативные системы, признающие важность уменьшения страданий, но либо подразумевающие наличие каких-то иных целей, либо сужающие круг допустимых для уменьшения страданий поступков, либо вносящие тот или иной вид предвзятости в вопрос о том, чьи страдания нам вообще следует уменьшать.

<a name="6.1"></a>
### 6.1. Дополнительные цели оптимизации

Рассмотрим случай, когда помимо уменьшения страданий агент имеет другие цели, также сводимые к уменьшению или увеличению количества чего-либо во вселенной. Например, агент может ценить увеличение своего счастья, или количества удовольствий во вселенной, или продолжительности жизни людей, или уменьшения числа нарушений автономии одних агентов другими, или уменьшения числа смертей.

В _общем случае_ выглядит маловероятным, чтобы решение задачи оптимизации одной ценности было полностью совместимо с решением задачи оптимизации какой-то другой. Подобно конфликту между оптимизацией одной и той же ценности для разных существ или в разных пространственно-временных масштабах, у нас также рано или поздно может вскрыться конфликт между оптимизацией разных ценностей на одних и тех же участках действительности, в том числе и в глобальном масштабе.

Поэтому рано или поздно (например, когда вы будете думать о том, в какую организацию пожертвовать свободные деньги, или на какие темы почитать статьи и пересказать своим друзьям) может встать вопрос о том, в какой степени для вас важны эти прочие вещи по сравнению со страданиями.

Один из способов совместить разные цели оптимизации — ввести что-то вроде курса обмена одних ценностей на другие. Т. е. нужно понять, сколько примерно страданий, по-вашему, эквивалентны тому или иному количеству другой отрицательной ценности (например, одной человеческой смерти) или сколько страданий можно окупить тем или иным количеством положительной ценности (например, удовольствиями). Если же страдания (или какая-то их разновидность) для вас всегда важнее (как в системах ценностей [с лексическим порядком](https://casparoesterheld.com/2016/08/08/lexicographic-utility-functions/)), то другие ценности просто не должны играть (неинструментальной) роли в принятии масштабных решений, пока во вселенной могут существовать страдания.

С другой стороны, _частичная_ совместимость разных человеческих ценностей не только достижима, но и неизбежна. В частности, очевидно, что вы просто не сможете быть успешными в уменьшении чьих-либо страданий, если не будете прибегать к компромиссам с эгоистической стороной своего существа и как-то заботиться _о себе лично_ — избегая сильных страданий и поощряя себя удовольствием за проделанную работу.

Кроме того, в сфере науки, философии и технологии есть множество направлений, в которых заинтересованы носители самых разных ценностей. Некоторые из этих направлений могут быть более значимыми для уменьшения страданий и каких-то дополнительных целей, чем другие. Возможным примером может служить [работа](https://longtermrisk.org/research-agenda) по уменьшению рисков глобальных конфликтов, связанных с искусственным интеллектом.

<a name="6.2"></a>
### 6.2. Ограничения на способы оптимизации

Рассмотрим теперь случай, когда дополнительной целью агента является соблюдение ограничений _деонтологического_ характера на то, что именно он может делать в процессе оптимизации.

Хотя и в этом случае ясно, что теоретически они могут конфликтовать с уменьшением страданий, у части распространенных деонтологий накал такого конфликта может оказаться намного меньшим, чем если бы вы, например, преследовали дополнительную цель максимизации удовольствий во вселенной.

Так, если вы придерживаетесь деонтологии, состоящей из запрета на поедание мяса животных, но знаете, как при этом избежать отрицательных последствий для вашего здоровья из-за отсутствия мяса в вашем рационе, это вряд ли будет угрожать вашей деятельности, направленной на уменьшение страданий. Более того, возможно, что избегая поедания мяса животных, вы [способствуете](https://reducing-suffering.org/does-vegetarianism-make-a-difference/) уменьшению страданий даже больше, чем если бы вы были мясоедом. Проблема, однако, может возникнуть, если в результате неудачного стечения обстоятельств вы окажетесь в местах, где можно выжить и остаться здоровым только употребляя мясо.

С другой стороны, наличие у агента деонтологии может сопровождаться явным желанием увеличить число ее сторонников в мире. Таким образом, может сформироваться дополнительная цель оптимизации и тоже возможен конфликт.

<a name="6.3"></a>
### 6.3. Сужения морального круга

[Моральный круг](https://reducingsuffering.github.io/376.html) — это круг существ, благополучие которых нас в конечном счете интересует, когда мы принимаем моральные решения.

В контексте гедонистического утилитаризма принцип беспристрастности подразумевает, что моральный круг должен охватывать всех сентиентных существ и одинаковые страдания разных персон должны давать один и тот же вклад в общие оценки страданий. Существует множество взглядов, которые отвергают принцип беспристрастности, но пересекаются с гедонистическим утилитаризмом в других аспектах.

Так, довольно известная в философии морали точка зрения, относимая к [person-affecting views](https://en.wikipedia.org/wiki/Person-affecting_view), подразумевает, что мы должны заботиться лишь о тех, кто _уже существует_, исключая из морального круга тех, кто еще не появился на свет. Помимо этого встречаются позиции, ограничивающие моральный круг человеческим видом или даже одной нацией или племенем. Наконец, крайняя форма сужения морального круга — это [моральный эгоизм](https://plato.stanford.edu/entries/egoism/#EthiEgoi), согласно которому нашей обязанностью является лишь забота о нашем собственном благополучии.

Помимо этого встречаются позиции, которые не сужают моральный круг явно, но все же отвергают принцип беспристрастности, присваивая разную значимость одинаковым по величине страданиям. Например, не отказываясь от оценки благополучия будущих, еще не появившихся на свет персон, некоторые теории предлагают [дисконтировать](https://en.wikipedia.org/wiki/Social_discount_rate) это благополучие, т. е. считать его значимость тем меньшей, чем сильнее отдалены во времени эти персоны.

<a name="7"></a>
## 7. Типичные ошибки

Приведем ряд примеров ошибок, которые нередко совершают сторонники или критики уменьшения страданий в своих рассуждениях.

<a name="7.1"></a>
### 7.1. Отсутствие сравнений

Первый вид ошибок связан с тем, что какие-то сценарии возможного будущего оцениваются сами по себе, не рассматриваются какие-либо их альтернативы. Таким образом, невозможно вообще говорить об уменьшении страданий, т. к. _уменьшение_ подразумевает выбор варианта со страданиями меньшими _чем при других вариантах_.

Так, аргументация вида "люди очень сильно и в большом количестве страдают от болезни X, поэтому нам нужно заняться разработкой лекарства от X" не содержит никакой информации о действительности за пределами страдающих от определенной болезни людей, поэтому не может считаться самодостаточной. Нам нужна хоть какая-то информация об иных страданиях помимо вызываемых болезнью X, и хоть какие-то альтернативные варианты деятельности, с которыми можно было бы сравнивать разработку лекарства от X. Помимо этого, приведенное описание проблемы указывает лишь на ее масштаб, но ничего не говорит о легкости ее решения и о том, сколько людей уже занимаются этой проблемой.

Другой пример представляют ошибочные рассуждения вида "при идеальном миропорядке нет страданий -> чтобы уменьшить страдания, нужно стремиться приблизить идеальный миропорядок". В роли "идеального миропорядка" обычно выступает либо опустошенный мир, где некому страдать, потому что все вымерли, либо [гедонистическая утопия](https://reducingsuffering.github.io/89.html), где сентиентные существа защищены от страданий в результате использования генной инженерии или иных технологий.

Эти рассуждения отличаются от предыдущего примера тем, что создают ложное впечатление учета страданий всех существ сразу, потому что смещают фокус внимания на специфический участок пространственно-временной действительности — тот, в котором наступил "идеальный миропорядок", _в рамках которого_ действительно никто не страдает. Однако, все прочие страдания — _до_ его наступления и _после_ (если он может не быть вечным), а то и _вне_ некоторой области пространства (если рассматривается судьба лишь одной планеты во вселенной) просто не рассматриваются. Не рассматривается и то, как на страдания во вселенной повлияли бы другие возможные виды деятельности. Таким образом, как и в предыдущем случае, отсутствует какое либо сравнение с альтернативами, поэтому исходя из самого рассуждения невозможно понять, действительно ли предложенный вариант уменьшает страдания.

Что же выяснится, если сравнивать такого рода проекты с другими? Есть аргументы в пользу некоторой [ограниченной поддержки](https://magnusvinding.com/2021/08/09/reasons-not-to-prioritize-the-abolitionist-project/) проекта гедонистической утопии. Но вот проекты вымирания, с другой стороны, [крайне проблематичны](https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism), и в некоторых случаях способны [саботировать](https://reducingsuffering.github.io/450.html) весь реальный прогресс в уменьшении страданий.

<a name="7.2"></a>
### 7.2. Предубеждения о приоритетах

Порой встречающийся у критиков пример ошибки — это "если ты так хочешь уменьшить страдания, почему не начнешь с себя и не [умрешь](https://reducingsuffering.github.io/73.html)?" или более мягкий вариант "почему не посвятишь жизнь медитациям в попытке достичь освобождения от страданий?". В этих случаях происходит безосновательная фокусировка на страданиях одной-единственной персоны. Не учитывается, что систематические усилия по уменьшению страданий других существ, предпринимаемые в течение жизни, могут предотвратить намного больше страданий, чем будет испытано данной персоной за всю жизнь. Помимо этого, может не учитываться риск того, что попытки ускорить смерть могут привести к еще большим мучениям этой персоны, чем в случае с доживанием до естественной смерти; и аналогичный риск в случае медитативных практик. Одна из возможных причин подобного вопроса состоит в привычке рассматривать проблемы через призму определенных представлений об ответственности, согласно которым каждый ответственен лишь за свои проблемы. Однако, утилитарный подход подразумевает, что мы несем ответственность за все во вселенной, на что способны повлиять.

Менее очевидной, но схожей ошибкой является идея о том, что нам следует целиком сфокусироваться на уменьшении страданий своих близких, или в своем поселении, или в своей стране, или в рамках человеческого вида, а также ограничиться ближайшими поколениями. Как и в предыдущем случае, пространственно-временная близость страданий к агенту создает впечатление большей важности уменьшения этих страданий. Одна из причин этого состоит в том, что близкие к нам последствия проще оценивать. Однако, как мы уже отмечали ранее, отдаленные последствия у части наших действий могут быть намного более масштабными, чем близкие, и могут иметь противоположную направленность, поэтому следует выделять ресурсы на их изучение, а не полагаться лишь на ту часть последствий, которую легко оценить. Другая возможная причина такого предубеждения состоит в путанице между глобальным уменьшением страданий и локальными моральными обязательствами вроде заботы о близких и отзывчивости к проблемам окружающих. Соблюдение таких обязательств нередко помогает нашему стабильному сосуществованию в обществе, но глобальное уменьшение страданий в общем случае требует и других видов деятельности.

<a name="sources"></a>
## Источники

* Стэнфордская энциклопедия философии, [Консеквенциализм](https://reducingsuffering.github.io/44.html)
* К. Кирдан, [Что такое негативный утилитаризм](https://reducingsuffering.github.io/what-is-negative-utilitarianism.html) (2020)
* Magnus Vinding, [Suffering-Focused Ethics: Defense and Implications](https://magnusvinding.com/2020/05/31/suffering-focused-ethics-defense-and-implications/) (2020)
* Stanford Encyclopedia of Philosophy, [Pain](https://plato.stanford.edu/entries/pain/)
* Wikipedia, [Aggregate function](https://en.wikipedia.org/wiki/Aggregate_function)
* Электронная философская энциклопедия, [Утилитаризм](https://reducingsuffering.github.io/337.html)
* Википедия, [Проблема вагонетки](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0_%D0%B2%D0%B0%D0%B3%D0%BE%D0%BD%D0%B5%D1%82%D0%BA%D0%B8)
* Wikipedia, [Mathematical optimization](https://en.wikipedia.org/wiki/Mathematical_optimization)
* Большая российская энциклопедия, [Контрфактуальное мышление](https://bigenc.ru/c/kontrfaktual-noe-myshlenie-41076d)
* Агата Коровина, [«Реальный мир — это тот, где ты жив, а возможный — где ты мертв». Как философы путешествуют по возможным мирам](https://knife.media/possible-worlds/)
* Douglas W. Portmore, [Objective and Subjective Consequentialism](https://philpapers.org/browse/objective-and-subjective-consequentialism)
* Douglas W. Portmore, [Maximizing and Satisficing Consequentialism](https://philpapers.org/browse/maximizing-and-satisficing-consequentialism)
* Luke Muehlhauser, [Decision Theory FAQ](https://www.lesswrong.com/posts/zEWJBFFMvQ835nq6h/decision-theory-faq) (2013)
* Caspar Oesterheld, [A comprehensive list of decision theories](https://casparoesterheld.com/a-comprehensive-list-of-decision-theories/)
* Brian Tomasik, [Why Maximize Expected Value?](https://reducing-suffering.org/why-maximize-expected-value/) (2007-2016)
* Holden Karnofsky, [Expected value](https://www.cold-takes.com/expected-value/)
* Wikipedia, [Von Neumann–Morgenstern utility theorem](https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Morgenstern_utility_theorem)
* Википедия, [Функция (математика)](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_(%D0%BC%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B0))
* Джон фон Нейман, Оскар Моргенштерн, [Теория игр и экономическое поведение](https://reducingsuffering.github.io/347.html) (1970)
* Стэнфордская энциклопедия философии, [Теория игр](https://brickofknowledge.com/articles/game-theory)
* Элиезер Юдковский, [Парадокс Ньюкома: сожалея о своей рациональности](https://lesswrong.ru/w/%D0%9F%D0%B0%D1%80%D0%B0%D0%B4%D0%BE%D0%BA%D1%81_%D0%9D%D1%8C%D1%8E%D0%BA%D0%BE%D0%BC%D0%B0_%D1%81%D0%BE%D0%B6%D0%B0%D0%BB%D0%B5%D1%8F_%D0%BE_%D1%81%D0%B2%D0%BE%D0%B5%D0%B9_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8) (2015)
* John C. Harsanyi, [Rule Utilitarianism and Decision Theory](https://www.jstor.org/stable/20010532) (1975)
* Wikipedia, [Pascal's mugging](https://en.wikipedia.org/wiki/Pascal%27s_mugging)
* Centre for Effective Altruism, [Option value](https://forum.effectivealtruism.org/topics/option-value)
* David Manheim, [When To Find More Information: A Short Explanation](https://forum.effectivealtruism.org/posts/8w2hNT5WtDMzoaGuy/when-to-find-more-information-a-short-explanation) (2019)
* Stanford Encyclopedia of Philosophy, [Bounded Rationality](https://plato.stanford.edu/entries/bounded-rationality/) (2018)
* К. Кирдан, [Плюс в одном месте — это минус в другом](https://kkirdan.github.io/blog/a2.html) (2023)
* MacAskill W., Meissner D., Chappell R. Y., [Elements and Types of Utilitarianism](https://utilitarianism.net/types-of-utilitarianism/) (2023)
* Hal Gregersen, Lee Sailer, [Chaos Theory and Its Implications for Social Science Research](https://journals.sagepub.com/doi/10.1177/001872679304600701) (1993)
* Nick Bostrom, [Infinite Ethics](https://nickbostrom.com/ethics/infinite.pdf) (2003-2011)
* Amanda Askell, [Pareto Principles in Infinite Ethics](https://askell.io/files/Askell-PhD-Thesis.pdf) (2018)
* Brian Tomasik, [Should We Believe in Infinity?](https://reducing-suffering.org/believe-infinity/) (2014-2018)
* Centre for Effective Altruism, [Cluelessness](https://forum.effectivealtruism.org/topics/cluelessness)
* Википедия, [Световой конус](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D0%B5%D1%82%D0%BE%D0%B2%D0%BE%D0%B9_%D0%BA%D0%BE%D0%BD%D1%83%D1%81)
* Википедия, [Тепловая смерть Вселенной](https://ru.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BF%D0%BB%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D0%BC%D0%B5%D1%80%D1%82%D1%8C_%D0%92%D1%81%D0%B5%D0%BB%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9) 
* Википедия, [Большой разрыв](https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D0%BE%D0%B9_%D1%80%D0%B0%D0%B7%D1%80%D1%8B%D0%B2)
* Caspar Oesterheld, [Multiverse-wide Cooperation via Correlated Decision Making](https://longtermrisk.org/multiverse-wide-cooperation-via-correlated-decision-making/) (2017)
* Википедия, [Эпистемология](https://ru.wikipedia.org/wiki/%D0%AD%D0%BF%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D1%8F)
* Элиезер Юдковский, [Рациональность: от ИИ до зомби](https://lesswrong.ru/w/%D0%A0%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%D0%BE%D1%82_%D0%98%D0%98_%D0%B4%D0%BE_%D0%97%D0%BE%D0%BC%D0%B1%D0%B8) (2015)
* Amanda Askell, [Criteria of rightness vs. decision procedures](https://forum.effectivealtruism.org/posts/voDm6e6y4KHAPJeJX/act-utilitarianism-criterion-of-rightness-vs-decision) (2017)
* Элиезер Юдковский, [Что такое рациональность](https://lesswrong.ru/w/%D0%A7%D1%82%D0%BE_%D1%82%D0%B0%D0%BA%D0%BE%D0%B5_%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C) (2009)
* Centre for Effective Altruism, [Longtermism](https://www.effectivealtruism.org/articles/longtermism)
* Уличная эпистемология, [Инструментальные и терминальные ценности. Как понять, что действительно важно для собеседника](https://streetepistemology.ru/instrumentalnie-i-terminalnie-tsennosti)
* LessWrong, [Instrumental convergence](https://www.lesswrong.com/tag/instrumental-convergence)
* Stefan Schubert, [Considering Considerateness: Why communities of do-gooders should be exceptionally considerate](https://forum.effectivealtruism.org/posts/Cn3dAZhtqeBXYmQvF/considering-considerateness-why-communities-of-do-gooders) (2017)
* Магнус Виндинг, [Этика противодействия страданию и важность счастья](https://reducingsuffering.github.io/magnus-vinding-suffering-focused-ethics-and-the-importance-of-happiness.html) (2021)
* Magnus Vinding, [Why altruists should be cooperative](https://centerforreducingsuffering.org/research/why-altruists-should-be-cooperative/) (2020)
* Teo Ajantaival, [Peacefulness, nonviolence, and experientialist minimalism](https://forum.effectivealtruism.org/posts/JnHeeTGAohMFxNbGK/peacefulness-nonviolence-and-experientialist-minimalism) (2022)
* Скотт Александер, [О пользе любезности, общин и цивилизации](https://lesswrong.ru/w/%D0%9E_%D0%BF%D0%BE%D0%BB%D1%8C%D0%B7%D0%B5_%D0%BB%D1%8E%D0%B1%D0%B5%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D0%BE%D0%B1%D1%89%D0%B8%D0%BD_%D0%B8_%D1%86%D0%B8%D0%B2%D0%B8%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D0%B8) (2014)
* Brian Tomasik, [Reasons to Be Nice to Other Value Systems](https://longtermrisk.org/reasons-to-be-nice-to-other-value-systems/) (2015)
* Stanford Encyclopedia of Philosophy, [Deontological Ethics](https://plato.stanford.edu/entries/ethics-deontological/)
* Стэнфордская энциклопедия философии, [Этика добродетели](https://philosophy.ru/ru/virtue_ethics/)
* Jan Kulveit, [Deontology and virtue ethics as "effective theories" of consequentialist ethics](https://forum.effectivealtruism.org/posts/aDNPgm2v2boBbj8wK/deontology-and-virtue-ethics-as-effective-theories-of) (2022)
* Лукас Глор, [Критика наивного консеквенциализма](https://lesswrong.ru/w/%D0%9A%D1%80%D0%B8%D1%82%D0%B8%D0%BA%D0%B0_%D0%BD%D0%B0%D0%B8%D0%B2%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BA%D0%BE%D0%BD%D1%81%D0%B5%D0%BA%D0%B2%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%BC%D0%B0) (2015)
* Бенджамин Тодд, [80,000 часов: построй успешную карьеру и принеси пользу миру](https://80000hours.ru/book/)
* Centre for Effective Altruism, [Введение в эффективный альтруизм](https://ea-ru.org/articles/introduction-to-effective-altruism)
* Robert Wiblin, [A framework for comparing global problems in terms of expected impact](https://80000hours.org/articles/problem-framework/) (2016-2019)
* Jesse Clifton, [Cooperation, Conflict, and Transformative Artificial Intelligence: A Research Agenda](https://longtermrisk.org/research-agenda) (2020)
* Caspar Oesterheld, [Lexicographic utility functions](https://casparoesterheld.com/2016/08/08/lexicographic-utility-functions/) (2016)
* Brian Tomasik, [Does Vegetarianism Make a Difference?](https://reducing-suffering.org/does-vegetarianism-make-a-difference/) (2006-2014)
* Сигаль Сэмюэл, [Звери, роботы и люди: есть ли шансы на равноправие?](https://newochem.io/moral-circle/) (2019)
* Stanford Encyclopedia of Philosophy, [Egoism](https://plato.stanford.edu/entries/egoism/)
* Wikipedia, [Person-affecting view](https://en.wikipedia.org/wiki/Person-affecting_view)
* Wikipedia, [Social discount rate](https://en.wikipedia.org/wiki/Social_discount_rate)
* Дэвид Пирс, [Гедонистический императив](https://reducingsuffering.github.io/89.html) (1995)
* Magnus Vinding, [Priorities for reducing suffering: Reasons not to prioritize the Abolitionist Project](https://magnusvinding.com/2021/08/09/reasons-not-to-prioritize-the-abolitionist-project/) (2021)
* Брайан Томасик, [Почему мы должны оставаться кооперативными](https://reducingsuffering.github.io/450.html) (2011-2019)
* Магнус Виндинг, [Вред смерти](https://reducingsuffering.github.io/magnus-vinding-the-harm-of-death.html) (2015)

<a name="further"></a>
## Что еще почитать

* Benjamin Todd, [Counterfactuals and how they change our view of what does good](https://80000hours.org/articles/counterfactuals/) (2021)
* Centre for Effective Altruism, [Model uncertainty](https://forum.effectivealtruism.org/topics/model-uncertainty)
* Centre for Effective Altruism, [Crucial consideration](https://forum.effectivealtruism.org/topics/crucial-consideration)
* Lukas Gloor, [Expected Utility](https://crucialconsiderations.org/rationality/expected-utility/) (2015)
* Benjamin Todd, [Expected value: how can we make a difference when we’re uncertain what’s true?](https://80000hours.org/articles/expected-value/) (2021-2023)
* Centre for Effective Altruism, [Expected value](https://forum.effectivealtruism.org/topics/expected-value)
* Holden Karnofsky, [Why we can’t take expected value estimates literally (even when they’re unbiased)](https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/) (2011-2016)
* Centre for Effective Altruism, [ITN framework](https://forum.effectivealtruism.org/topics/itn-framework)
* Benjamin Todd, [What is social impact? A definition](https://80000hours.org/articles/what-is-social-impact-definition/) (2021-2023)
* Аманда Аскелл, [Ценность информации и устойчивость убеждений](https://ea-ru.org/articles/the-moral-value-of-information) (2017)
* Magnus Vinding, [Research vs. non-research work to improve the world: In defense of more research and reflection](https://magnusvinding.com/2022/05/09/in-defense-of-research/) (2022)
* Benjamin Todd, [Cluelessness: can we know the effects of our actions?](https://80000hours.org/articles/cluelessness/) (2021)
* Hilary Greaves, [Cluelessness](https://philpapers.org/archive/GREC-38.pdf) (2016)
* Magnus Vinding, [Radical uncertainty about outcomes need not imply (similarly) radical uncertainty about strategies](https://magnusvinding.com/2022/09/07/strategic-uncertainty/) (2022)
* Stefan Schubert & Lucius Caviola, [Virtues for Real-World Utilitarians](https://utilitarianism.net/guest-essays/virtues-for-real-world-utilitarians/) (2023)
* MacAskill W., Meissner D., Chappell R. Y., [Utilitarianism and Practical Ethics](https://utilitarianism.net/utilitarianism-and-practical-ethics/) (2023)
* Teo Ajantaival, [Positive roles of life and experience in suffering-focused ethics](https://forum.effectivealtruism.org/posts/t3St6Fz4DmHtKfgqm/positive-roles-of-life-and-experience-in-suffering-focused) (2021)
* Teo Ajantaival, [Minimalist axiologies and positive lives](https://forum.effectivealtruism.org/posts/5gPubzt79QsmRJZnL/minimalist-axiologies-and-positive-lives) (2021)
* Элиезер Юдковский, [Ценности терминальные и инструментальные](https://lesswrong.ru/w/%D0%A6%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8_%D1%82%D0%B5%D1%80%D0%BC%D0%B8%D0%BD%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D0%B8_%D0%B8%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5) (2007)
* Toby Ord, [Moral Trade](https://www.fhi.ox.ac.uk/wp-content/uploads/moral-trade-1.pdf) (2016)
* Brian Tomasik, [Gains from Trade through Compromise](https://longtermrisk.org/gains-from-trade-through-compromise/) (2013-2018)
* Ману Эрран, [Зачем фокусироваться на уменьшении интенсивного страдания?](https://reducingsuffering.github.io/47.html) (2019)
* Ману Эрран, [Что я могу сделать для предотвращения интенсивных страданий?](https://reducingsuffering.github.io/119.html) (2020)
* Скотт Александер, [Часто задаваемые вопросы о консеквенциализме](https://lesswrong.ru/w/%D0%A7%D0%B0%D0%92%D0%BE_%D0%BE_%D0%BA%D0%BE%D0%BD%D1%81%D0%B5%D0%BA%D0%B2%D0%B5%D0%BD%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%BC%D0%B5)
* К. Кирдан, ["Цель оправдывает средства" — это и есть консеквенциализм?](https://kkirdan.github.io/blog/406.html) (2021)
* К. Кирдан, [Что такое этика](https://reducingsuffering.github.io/what-is-ethics.html) (2021)
* Centre for Effective Altruism, [Naive vs. sophisticated consequentialism](https://forum.effectivealtruism.org/topics/naive-vs-sophisticated-consequentialism)
* Nick Bostrom, Thomas Douglas, Anders Sandberg, [The Unilateralist’s Curse and the Case for a Principle of Conformity](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959137/) (2016)
* Stanford Encyclopedia of Philosophy, [Normative Theories of Rational Choice: Expected Utility](https://plato.stanford.edu/entries/rationality-normative-utility/) (2014-2023)
* Стэнфордская энциклопедия философии, [Теория игр](https://reducingsuffering.github.io/245.html)
* Абрам Демски, Скотт Гаррабрант, [Встроенная агентность](https://lesswrong.ru/w/%D0%92%D1%81%D1%82%D1%80%D0%BE%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F_%D0%B0%D0%B3%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D1%81%D1%82%D1%8C) (2018)
* Евгений Кононов, [Аналитическая метафизика. Тематический обзор](https://reducingsuffering.github.io/539.html) (2023)