---
layout: article
title: "Введение в проблему отрицательной синтетической феноменологии"
authors:
  - Томас Метцингер
original: "https://www.worldscientific.com/doi/10.1142/S270507852150003X"
original_date: "2021.02.19"
translated_by: "Евгений Вдовин (для <a href=\"https://vk.com/wall-210202656_1\">SciBooks</a>)"
edited_by: К. Кирдан
license: ["CC BY 4.0", "https://creativecommons.org/licenses/by/4.0/deed.ru"]
is_fragment: true
preview: assets/images/previews/cyborg-8514853_480.png
preview_here: true
excerpt: "Сегодня сознательные машины будущего не представлены в политическом процессе ни в одной стране. Их потенциальные интересы и предпочтения не представлены систематическим образом ни каким-либо комитетом по этике, ни какой-либо юридической процедурой, ни какой-либо политической партией на планете. В то же время, выглядит эмпирически правдоподобным, что как только машинное сознание эволюционирует, какие-то из этих систем будут иметь свои предпочтения, что они будут самостоятельно создавать иерархию целей, и что эта иерархия целей станет частью их феноменальной Я-модели (т.е., их сознательной самопрезентацией). Некоторые из них будут способны сознательно страдать. Если их предпочтения нарушены, если их цели не могут быть достигнуты, и если их сознательная Я-модель находится под угрозой распада, они могут подвергнуться отрицательным феноменальным состояниям, состояниям сознательного опыта, которых они хотят избежать, но _не могут_ избежать, и которые они вынуждены переживать как состояния _самих себя_. Конечно, они также могут страдать способами, которые мы не можем понять или вообразить, и мы, возможно, даже не сможем обнаружить этот самый факт. Но каждое существо, способное страдать, должно быть объектом морального рассмотрения."
---
(Это отрывок из статьи «[Artificial Suffering: An Argument for a Global Moratorium on Synthetic Phenomenology](https://www.worldscientific.com/doi/10.1142/S270507852150003X)»)

---

Сегодня сознательные машины будущего не представлены в политическом процессе ни в одной стране. Их потенциальные интересы и предпочтения не представлены систематическим образом ни каким-либо комитетом по этике, ни какой-либо юридической процедурой, ни какой-либо политической партией на планете. В то же время, выглядит эмпирически правдоподобным, что как только машинное сознание эволюционирует, какие-то из этих систем будут иметь свои предпочтения, что они будут самостоятельно создавать иерархию целей, и что эта иерархия целей станет частью их феноменальной Я-модели (т.е., их сознательной самопрезентацией; см. Metzinger \[2003a\], Metzinger \[2008\]). Некоторые из них будут способны сознательно страдать. Если их предпочтения нарушены, если их цели не могут быть достигнуты, и если их сознательная Я-модель находится под угрозой распада, они могут подвергнуться отрицательным феноменальным состояниям, состояниям сознательного опыта, которых они хотят избежать, но _не могут_ избежать, и которые они вынуждены переживать как состояния _самих себя_. Конечно, они также могут страдать способами, которые мы не можем понять или вообразить, и мы, возможно, даже не сможем обнаружить этот самый факт. Но каждое существо, способное страдать, должно быть объектом морального рассмотрения[^a].

Мы несем этическую ответственность за последствия наших действий. Наши сегодняшние действия будут влиять на феноменологию постбиотических систем в будущем. Предположительно, их может быть много. До сих пор на этой планете жило более 108 миллиардов человек, причем примерно 7% из них живут в наше время \[Population Reference Bureau, 2020\]. Бремя ответственности может быть чрезвычайно высоким, потому что, как и в случае с растущим климатическим кризисом, сравнительно небольшое число сентиентных существ будет нести этическую ответственность за качество жизни гораздо большего числа сентиентных существ будущего — сознательных систем, которые еще только должны появиться. Число самосознающих машин, которые будут развиваться и существовать на Земле, на данном этапе эпистемически неопределенно: оно все еще может равняться нулю на много веков вперед, но в какой-то момент времени оно может также превысить суммарное число людей. Особенно если учитывать возможность каскадных самосознающих _виртуальных_ агентов \[Gualeni, 2020; Holland, 2020 Sec. 6; Metzinger, 2018c, Example 7\]. Сейчас мы имеем дело с «риском внезапной синергии», соединяющей различные научные дисциплины и приводящей к неожиданному технологическому слиянию[^b]. Если теоретические интуиции растущего числа экспертов в этой области не совсем лишены оснований, и синтетическая феноменология[^c] действительно появится в какой-то момент, то число людей, которые будут иметь существенное каузальное влияние на появление сознательных машин на этой планете и виды феноменальных состояний, которые они должны будут претерпеть, чрезвычайно мало. В лучшем случае, это будет лишь несколько миллионов человек, которые несут этическую ответственность в сильном и прямом смысле — такие как политики и правовые регуляторы, исследователи ИИ, математики и нейробиологи, а также философы и исследователи в растущей междисциплинарной области науки о сознании. Многие из них уже живут в наше время. Эта исторически уникальная ситуация создает особенно высокое бремя этической ответственности для тех, кто видит общую проблему, которую я здесь раскрываю.

Существует риск, который рациональным и научно обоснованным образом должен быть сведен к минимуму. Я назову его риском «‎взрыва отрицательной феноменологии» (или просто «взрыва страданий») в искусственном интеллекте и других постбиотических системах. Здесь я определяю «отрицательную феноменологию» как любой вид сознательного опыта, которого сознательная система избегала бы или, скорее, предпочла бы не испытывать, если бы у нее был выбор. Я также предполагаю приоритетность уменьшения страданий — в этом мире более важно предотвращать и минимизировать страдания, чем увеличивать счастье (для введения в тему см. Vinding \[2020, Part I\]).

Обратите внимание, что в той части физической вселенной, которая нам известна в настоящее время, один взрыв отрицательной феноменологии уже произошел — через процесс биологической эволюции на этой планете. Благодаря эволюции сложных нервных систем такие свойства, как сентиентность, самосознание и отрицательная феноменология, уже были проявлены в чрезвычайно огромном числе биологических индивидов задолго до того, как в дело вступил _Гомо Сапиенс_ и начал в итоге строить интеллектуальные машины \[Horta, 2010; Iglesias, 2018\]. У людей преобладание негативного аффекта чрезмерно \[Gilbert, 2016\], а когнитивные искажения и механизмы самообмана делают нас в значительной степени неспособными ясно видеть этот феноменологический факт \[Trivers, 2011; von Hippel and Trivers, 2011\]. На научном уровне давно стало ясно, что естественный отбор никогда не формировал наше настроение и системы эмоциональной регуляции в наших собственных интересах, и что «мотивы, которыми мы руководствуемся, часто приносят пользу нашим генам в ущерб качеству жизни» \[Nesse, 2004, p. 1344\]. Для прикладной этики ИИ риск, который должен быть сведен к минимуму — это риск _второго_ взрыва отрицательной феноменологии, происходящего уже на уровне постбиологической эволюции. Иными словами, принимая во внимание возможность того, что он может оказаться еще хуже с точки зрения масштаба и интенсивности, мы не хотим, чтобы феноменология страдания перетекла из биологии в ИИ, — или, если хотите, из «Эволюции уровня 1» в «Эволюцию уровня 2» интеллектуальных систем.

### Сноски

* footnotes will be placed here
{:footnotes}

[^a]: Назовем это исходное предположение «Принципом патоцентризма»: все сентиентные и только сентиентные существа имеют моральное значение, потому что только сентиентные индивиды имеют права и/или интересы, которые необходимо учитывать. По словам Сингера \[2011, p. 50\]: «Если существо страдает, не может быть никакого морального оправдания для отказа принимать во внимание это страдание. Независимо от природы этого существа, принцип равенства требует, чтобы страдание считалось равным аналогичному страданию, покуда можно провести грубые сравнения с любым другим существом. Если существо не способно страдать, испытывать наслаждение или счастье, то принимать во внимание нечего. Вот почему предел сентиентности — единственно оправданная граница заботы об интересах других. Провести эту границу по характеристике вроде интеллекта или рациональности, — это все равно, что провести ее произвольным образом. Почему бы не выбрать тогда какую-нибудь другую характеристику, вроде цвета кожи?» Пожалуйста, обратите внимание, что в соответствии с принципом патоцентризма нет _обязательной_ концептуальной связи между интеллектом и сознательной обработкой. Поэтому вполне возможно, что сентиентные постбиотические системы со сравнительно низкой степенью интеллекта могут подвергаться интенсивным сознательным страданиям.

[^b]: Очевидными примерами являются современные подходы, направленные на слияние нейронауки и ИИ с конкретной целью содействия развитию машинного сознания. О недавних случаях см. Dehaene et al. \[2017\], Graziano \[2017\], и Kanai \[2017\].

[^c]: «Синтетическая феноменология» — это концепция, впервые введенная американским философом Скоттом Джорданом в 1998 году, и параллельная идее «синтетической биологии». Так же, как последняя относится к новой области биологических исследований и технологий, которая объединяет науку и технику, нацелившись на создание новых биологических функций и систем, не встречающихся в природе, «синтетическая феноменология» направлена на моделирование, развитие и проектирование _сознательных_ систем, включая их состояния и функции, на искусственном оборудовании. См. также Chrysler \[2009\].

### Ссылки

- Chrisley, R. \[2009\] Synthetic phenomenology, _Int. J. Mach. Conscious._ **1**(1), 53–70, doi: 10.1142/S1793843009000074.
- Dehaene, S., Lau, H. and Kouider, S. \[2017\] What is consciousness, and could machines have it? _Science_ **358**(6362), 486–492.
- Gilbert, P. \[2016\] _Human Nature and Suffering_ (Routledge, London).
- Graziano, M. S. A. \[2017\] The attention schema theory: A foundation for engineering artificial consciousness, _Front. Robot. AI_ **4**, 60, doi: 10.3389/frobt.2017.00060.
- Holland, O. \[2020\] Forget the bat, _J. Artif. Intell. Conscious._ **7**(1), 83–93, doi: 10.1142/S2705078520500058.
- Horta, O. \[2010\] Debunking the idyllic view of natural processes: Population dynamics and suffering in the wild, _Télos_ 17(1), 73–88.
- Iglesias, V. \[2018\] The overwhelming prevalence of suffering in nature, _Rev. Bioét. Derecho_ **42**, 181–195.
- Kanai, R. \[2017\] We need conscious robots, _Nautilus_, Issue 047, <http://nautil.us/issue/47/consciousness/we-need-conscious-robots>.
- Metzinger, T. \[2003a\] _Being No One: The Self-model Theory of Subjectivity_ (The MIT Press, Cambridge, MA).
- Metzinger, T. \[2008\] Empirical perspectives from the self-model theory of subjectivity: a brief summary with examples, _Prog. Brain Res._ **168**, 215–245. 273–278, doi: 10.1016/s0079-6123(07)68018-2.
- Metzinger, T. K. \[2018c\] Why is virtual reality interesting for philosophers? _Front. Robot. AI_ **5**, 101, doi: 10.3389/frobt.2018.00101.
- Nesse, R. M. \[2004\] Natural selection and the elusiveness of happiness, _Philos. Trans. R. Soc. Lond. B, Biol. Sci._ **359**(1449), 1333–1347.
- Population Reference Bureau \[2020\] Data Sheet 2020, <https://www.prb.org/2020-world-population-data-sheet/>.
- Trivers, R. \[2011\] _Deceit and Self-Deception: Fooling Yourself the Better to Fool Others_ (Penguin Books, London, UK).
- Vinding, M. \[2020\] _Suffering-focused Ethics: Defense and Implications_ (Radio Ethica, Copenhagen), <https://magnusvinding.files.wordpress.com/2020/05/suffering-focused-ethics.pdf>.
- von Hippel, W. and Trivers, R. \[2011\] The evolution and psychology of self-deception, _Behav. Brain Sci._ **34**(1), 1–16, doi: 10.1017/S0140525X10001354.
