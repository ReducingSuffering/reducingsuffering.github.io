---
layout: article
title: "Как мы можем уменьшить s-риски?"
authors:
  - Тобиас Бауман
translated_by: К. Кирдан
original: https://centerforreducingsuffering.org/research/how-can-we-reduce-s-risks/
original_date:
  - 2021
preview: assets/images/previews/tobias-baumann-how-can-we-reduce-s-risks.jpg
preview_here: true
---
Представляется [правдоподобным](https://centerforreducingsuffering.org/arguments-for-and-against-a-focus-on-s-risks/), что избежать будущего с астрономическим количеством страданий ([s-рисков](tobias-baumann-s-risks-an-introduction.html)) — приоритет с точки зрения многих систем ценностей, и в особенности с точки зрения этических взглядов, [сфокусированных на страданиях](https://magnusvinding.com/2020/05/31/suffering-focused-ethics-defense-and-implications/). Но учитывая довольно абстрактный и зачастую спекулятивный характер таких сценариев будущего, что мы на самом деле можем сделать уже сейчас, чтобы уменьшить s-риски?

В этом посте я дам обзор приоритетных направлений, выявленных на сегодняшний день исследованиями по приоритизации с точки зрения фокуса на страданиях. Разумеется, здесь присутствует большая неопределённость, и вполне возможно, что наиболее эффективные способы снижения s-рисков сильно отличаются от описанных далее мер.

Полноценная оценка каждого из основных приоритетных направлений выходит за рамки этого поста, но в целом я включил сюда те меры, которые выглядят достаточно многообещающими в плане важности, реализуемости и недооцененности. Я исключил те варианты, на которые слишком сложно повлиять или которые, скорее всего, приведут к обратному эффекту из-за сильной поляризации или негативной реакции (например, попытки полностью остановить технический прогресс). При снижении s-рисков мы должны стремиться находить [точки соприкосновения с другими системами ценностей](https://centerforreducingsuffering.org/common-ground-for-longtermists/). Соответственно, многие из описанных ниже мер представляют собой значимую ценность [с точки зрения множества разных взглядов](magnus-vinding-why-altruists-should-be-cooperative.html).

## Содержание
1. <a href="#1">Улучшение ценностей</a><br>
1.1. <a href="#1.1">Расширение морального круга</a><br>
1.2. <a href="#1.2">Этика, сфокусированная на страданиях</a><br>
2. <a href="#2">Политика и управление</a><br>
2.1. <a href="#2.1">Улучшение политической системы</a><br>
2.2. <a href="#2.2">Снижение рисков, исходящих от зловредных акторов</a><br>
2.3. <a href="#2.3">Поддержание верховенства закона</a><br>
3. <a href="#3">Исследования переговоров и эскалации конфликтов</a><br>
3.1. <a href="#3.1">Безопасность ИИ для наихудших сценариев</a><br>
3.2. <a href="#3.2">Суррогатные цели</a><br>
4. <a href="#4">Развитие потенциала</a>

<h2><a id="1"></a>Улучшение ценностей</h2>

На будущее влияют многие факторы — например, технический прогресс, экономическая динамика, проблемы кооперации, политические и культурные тренды. Однако именно ценности будущих субъектов, принимающих решения, по всей видимости — наиболее фундаментальный фактор, определяющий ход событий. Это делает улучшение ценностей перспективным рычагом воздействия на будущее. (Будет ли такой рычаг _наилучшим_, зависит от [осуществимости социальных изменений](https://www.sentienceinstitute.org/blog/how-tractable-is-changing-the-course-of-history), вероятности [фиксации ценностей](https://s-risks.org/how-can-we-influence-the-long-term-future/) вместо их дальнейшего [дрейфа](https://www.overcomingbias.com/2018/02/on-value-drift.html), и от того, насколько продвижение морали чувствительно ко времени[^1]. Подробнее см. в статье «[Arguments for and against moral advocacy](http://prioritizationresearch.com/arguments-for-and-against-moral-advocacy/)».)

<h3><a id="1.1"></a>Расширение морального круга</h3>

В частности, обеспечение достаточного морального рассмотрения _всех_ сентиентных существ, т. е. [расширение морального круга](https://forum.effectivealtruism.org/posts/BY8gXSpGijypbGitT/why-i-prioritize-moral-circle-expansion-over-artificial) — вероятно, ключевой фактор, определяющий, насколько благополучным будет отдаленное будущее. Проявляя и распространяя озабоченность страданиями независимо от того, в какое время они происходят, какой вид существ их испытывает или на каком субстрате работает их сознание, мы снижаем риск появления огромного количества «лишённых голоса» страданий, вызванных моральным пренебрежением к тем или иным типам существ — вроде животных или искусственных умов. (См. также «[How s-risks could come about](https://centerforreducingsuffering.org/intro/#How_s-risks_could_come_about)».)

Тем не менее, стоит отметить, что расширение морального круга может иметь и [обратный эффект](magnus-vinding-moral-circle-expansion-might-increase-future-suffering.html). В связи с этим крайне важно продвигать его вдумчивым, устойчивым и осмотрительным образом. В особенности следует избегать чрезмерно спорных стратегий, способных вызвать серьёзную (и возможно, необратимую) негативную реакцию, поскольку тяжелый конфликт с участием разных альтруистических движений сам по себе [может стать источником s-рисков](tobias-baumann-risk-factors-for-s-risks.html#3), а также затруднить будущую работу по их снижению.

Деятельность по расширению морального круга может принимать множество форм — от продвижения реформ в области защиты животных до продвижения [искусственного мяса](https://www.gfi.org/). Подробное обсуждение вопроса выходит за рамки этого поста, но в общем стоит отметить, что при фокусе на снижении s-рисков приоритеты могут существенно отличаться от тех приоритетов, которые ориентированы на помощь животным здесь и сейчас — было бы [поразительным совпадением](https://forum.effectivealtruism.org/posts/omoZDu8ScNbot6kXS/beware-surprising-and-suspicious-convergence), если бы работа с краткосрочным фокусом оказывалась одновременно оптимальной и для улучшения отдалённого будущего[^2]. (Подробнее см. в статье «[Longtermism and animal advocacy](https://centerforreducingsuffering.org/longtermism-and-animal-advocacy)».)

<h3><a id="1.2"></a>Этика, сфокусированная на страданиях</h3>

Помимо продвижения морального рассмотрения всех сентиентных существ (а также в качестве противовеса возможным отрицательным последствиям расширения морального круга), мы можем изучать и развивать этические взгляды, сфокусированные на страданиях, так как они склонны придавать наибольший приоритет снижению s-рисков. В своем эссе «[Reasons to promote suffering-focused ethics](https://reducing-suffering.org/the-case-for-promoting-suffering-focused-ethics/)», Брайан Томасик утверждает, что это может быть особенно надежной и эффективной стратегией, хотя он также рассматривает возможные недостатки (например, риск динамики с нулевой суммой).

Более общо, Магнус Виндинг [подчеркивает](https://web.archive.org/web/20231206000531/https://magnusvinding.blogspot.com/2016/11/fundamental-values-and-relevance-of_23.html), [что](https://web.archive.org/web/20231123072039/https://magnusvinding.blogspot.com/2017/01/reasons-to-focus-on-values-as-our-main.html) моральное размышление и прояснение фундаментальных ценностей имеют критически важное значение для любой альтруистической деятельности.

Подробнее об открытых вопросах для исследования в области этики, сфокусированной на страданиях, можно узнать [здесь](https://centerforreducingsuffering.org/open-research-questions/#Suffering-focused_ethics).

<h2><a id="2"></a>Политика и управление</h2>

С учетом нашей огромной неопределенности и «близорукости» насчёт будущего, разумно было бы сосредоточиться на том, чтобы максимально хорошо подготовить общество к решению будущих проблем — включая предотвращение потенциальных s-рисков.

Один из ключевых аспектов здесь — функциональная политическая система. Так что скорее всего усилия по предотвращению вредных политических и социальных процессов, а также по укреплению демократического управления, вносят вклад в снижение s-рисков.

<h3><a id="2.1"></a>Улучшение политической системы</h3>

Как добиться «лучшей политики» — вопрос, безусловно, непростой. (См. [этот](https://centerforreducingsuffering.org/improving-our-political-system-an-overview/) обзор.) Тем не менее, с точки зрения снижения s-рисков особенно важными кажутся следующие аспекты:

- Чрезмерная политическая поляризация, особенно поляризация между партиями в США, затрудняет достижение консенсуса и справедливых компромиссов, а также подрывает доверие к государственным институтам. Трайбализм также усиливает конфликты и, следовательно, представляет собой [фактор риска](tobias-baumann-risk-factors-for-s-risks.html#3) для s-рисков. [Предлагаемые](https://drive.google.com/file/d/179yTM3BhF2zPMnHh3iOjpvooqFG3DJ8S/view) меры по снижению поляризации включают [реформу избирательной системы](https://forum.effectivealtruism.org/posts/8Rn2gw7escCc2Rmb7/thoughts-on-electoral-reform), общественное вещание, делиберативные [гражданские совещания](https://www.electoral-reform.org.uk/latest-news-and-research/parliamentary-briefings/what-are-citizens-assemblies/) и обязательное голосование.
- Более взвешенный и доброжелательный политический дискурс, напротив, может снизить вероятность тяжелых конфликтов, и тем самым — наихудших возможных сценариев их последствий. Поэтому улучшение норм и стандартов политических дебатов может быть перспективным способом снижения s-рисков.
- Один из правдоподобных сценариев s-риска заключается в том, что доминирующее положение занимают «неподходящие» личности или идеологии, что приводит к закреплению постоянной тоталитарной властной структуры. Исторически такие режимы были временными и локализованными, но в будущем [может стать возможной](https://web.archive.org/web/20230528200308/https://essaydocs.org/the-totalitarian-threat.html) устойчивая глобальная диктатура.

<h3><a id="2.2"></a>Снижение рисков, исходящих от зловредных акторов</h3>

В сочетании с особенно дурными личностными чертами политических лидеров, такие проблемы, как поляризация или тоталитаризм, становятся особенно опасными. Поэтому один из способов улучшения управления — это снижение влияния «зловредных» акторов, где «зловредность» может быть измерена через черты [тёмной тетрады](https://en.wikipedia.org/wiki/Dark_triad#Dark_tetrad): психопатию, макиавеллизм, нарциссизм и садизм. В статье «[Reducing long-term risks from malevolent actors](https://forum.effectivealtruism.org/posts/LpkXtFXdsRd4rG8Kb/reducing-long-term-risks-from-malevolent-actors)» Дэвид Альтхаус и я утверждаем, что зловредные лидеры могут отрицательно влиять на долгосрочную траекторию человечества (и представлять как s-риск, так и x-риск), и рассматриваем возможные меры по уменьшению ожидаемого влияния таких индивидов на далёкое будущее.

Хотя такие меры в основном нацелены на людей (возможно, усовершенствованных), похожие соображения могут применяться и к другим будущим субъектам, таким как ИИ — если их поведение можно интерпретировать как обладающее схожими склонностями. В целом, у нас может быть гораздо больше возможностей для влияния на будущих субъектов, если станет возможным итеративный отбор эмбрионов или схожие с ним технологии, или если будут созданы совершенно новые классы умов (такие как эмы[^3] или ИИ). Поэтому важно работать над тем, как эти технологии могут быть использованы для избежания наихудших тенденций и предотвращения эскалации конфликтов.
 
(Это можно рассматривать в качестве частного случая [морального усовершенствования](https://en.wikipedia.org/wiki/Moral_enhancement). Однако, в отличие от других форм морального усовершенствования, ослабление зловредных черт направлено именно на снижение s-рисков, более надёжно и с большей вероятностью получит широкую поддержку.)

<h3><a id="2.3"></a>Поддержание верховенства закона</h3>

Современные общества справляются с [намеренными рисками](tobias-baumann-a-typology-of-s-risks.html#2), в основном за счёт принятия и исполнения соответствующих законов — например, запрета на вымогательство. Похоже, это довольно эффективно, что указывает на важность обеспечения того, чтобы в будущем у зловредных акторов тоже были стимулы не причинять вреда[^4].

Важно отметить, что s-риски могут исходить от будущих конфликтов, проходящих в радикально новых условиях — например, с участием продвинутого искусственного интеллекта или во время колонизации космоса. И выглядит правдоподобным ([хотя](https://centerforreducingsuffering.org/on-fat-tailed-distributions-and-s-risks/) и [не очевидным](http://s-risks.org/wp-content/uploads/2020/01/Is_most_expected_suffering_due_to_worst_case_scenarios_.pdf)), что больше всего нам следует беспокоиться о крайних сценариях с исключительно большими масштабами страданий. В таких экстремальных сценариях многие из вещей, которые мы обычно считаем само собой разумеющимися — вроде верховенства закона — могут перестать работать.

Один из способов предотвращения таких наихудших сценариев — это юридические исследования, посвящённые тому, как сделать более надежными имеющиеся законы, препятствующую таким сценариям (например, законы о вымогательстве и угрозах). В частности, важно изучить, как повысить вероятность того, что эти законы продолжат применяться и исполняться в радикально иных условиях, а также как применять схожее регулирование на уровне государств, транснациональных компаний или даже совершенно новых видов акторов, которые могут появиться в будущем[^5].

Ещё одно возможное направление, на котором можно сфокусироваться — это [управление космосом](https://forum.effectivealtruism.org/posts/QkRq6aRA84vv4xsu9/space-governance-is-important-tractable-and-neglected). В настоящее время у нас нет целостного глобального фреймворка для регулирования космоса — космос по сути остаётся зоной свободного доступа. Это создаёт риск серьёзных конфликтов, так что было бы ценно преодолеть нынешнюю неопределённость, разработав целостную систему (долгосрочного) управления космосом, которая обеспечит благоприятные исходы, когда (и если) станет возможной широкомасштабная колонизация космоса.

Наконец, мы могли бы попытаться распределить будущие технологические возможности так, чтобы стало затруднительно создавать астрономические масштабы страданий — чтобы (в идеале) ни один актор по отдельности не мог бы стать источником s-риска. Это снизило бы как побочные, так и намеренные s-риски. Однако трудно представить конкретные способы достижения такого более безопасного распределения будущих возможностей.

<h2><a id="3"></a>Исследования переговоров и эскалации конфликтов</h2>

Этот класс мер немного более спекулятивен и в основном направлен на уменьшение [намеренных s-рисков](tobias-baumann-a-typology-of-s-risks.html#2). Один из наиболее правдоподобных механизмов наступления наихудших сценариев состоит в том, что одни субъекты угрожают причинить вред другим — либо в попытке шантажа, либо как часть эскалации конфликта.

В связи с этим мы должны рассмотреть в качестве ещё одного возможного приоритетного направления исследования того, как лучше предотвращать такую динамику с отрицательной суммой (и достигать более кооперативных исходов). Эти исследования могут быть сосредоточены как на теоретических основах теории игр и теории принятия решений, так и на поиске наилучших способов изменить обстоятельства, в которых будут находиться будущие субъекты, с целью избегания эскалации конфликтов. (Подробнее см. «[Research priorities for preventing threats](https://s-risks.org/research-priorities-for-preventing-threats/)».)

<h3><a id="3.1"></a>Безопасность ИИ для наихудших сценариев</h3>

Трансформативный искусственный интеллект (ТИИ) [может быть](https://longtermrisk.org/altruists-should-prioritize-artificial-intelligence/) ([а может](https://magnusvinding.com/2018/09/18/why-altruists-should-perhaps-not-prioritize-artificial-intelligence-a-lengthy-critique/) и [не быть](https://s-risks.org/summary-of-my-views-on-ai-risk/)) исключительно важным рычагом влияния на далёкое будущее. В той мере, в какой он действительно трансформативен[^6], ТИИ может также привести к [астрономическим масштабам страданий](https://longtermrisk.org/files/Sotala-Gloor-Superintelligent-AI-and-Suffering-Risks.pdf), что указывает на возможность того, что исследования в области безопасности ИИ с фокусом на предотвращении s-рисков должны быть нашим приоритетом. (Такой подход называют [безопасностью ИИ, сфокусированной на страданиях](https://longtermrisk.org/files/fail-safe-ai.pdf), или [безопасностью ИИ для наихудших сценариев](https://s-risks.org/an-introduction-to-worst-case-ai-safety/).)

Особенно перспективными для снижения s-рисков представляются технические и управленческие меры[^7], направленные на избежание эскалации конфликтов с участием трансформативных ИИ-систем и на создание [кооперативного ИИ](https://arxiv.org/pdf/2012.08630.pdf). В «[Research Agenda on Cooperation, Conflict, and Transformative AI](https://longtermrisk.org/research-agenda)» Джесси Клифтон более подробно описывает возможные исследования в этом направлении. (См. также [пример](https://s-risks.org/mechanism-design-for-ai/) конкретной работы в этой области.)

<h3><a id="3.2"></a>Суррогатные цели</h3>

Особенно перспективной представляется идея повысить вероятность успешного внедрения [суррогатных целей](https://s-risks.org/using-surrogate-goals-to-deflect-threats/) в будущих субъектов, особенно в продвинутые ИИ-системы. Это позволило бы отразить угрозы (и связанные с ними страдания). Идея состоит в том, чтобы добавить к текущим целям новую, суррогатную цель, которая изначально не важна для субъекта, — в надежде, что именно эта цель, а не исходные ценности, станет мишенью в случае угрозы.

Возможные направления исследований по этой теме можно найти [здесь](https://s-risks.org/research-priorities-for-preventing-threats/#Surrogate_goals).

<h2><a id="4"></a>Развитие потенциала</h2>

Следует вновь подчеркнуть, что мы сталкиваемся с огромной неопределённостью в отношении будущего — как оно будет выглядеть, как мы можем на него сильнее всего повлиять и как лучше всего снизить s-риски. Перечисленные выше приоритетные области основаны на некоторых ныне наиболее обоснованных предположениях. Но есть также серьёзные основания считать одним из важнейших приоритетов _развитие потенциала_. То есть, возможно, самое важное, что мы сейчас можем — это сделать так, чтобы сострадательные субъекты в будущем были в лучшем положении для уменьшения страданий.

Это включает в себя построение сообщества, заинтересованного в проблеме уменьшения страданий и хорошо в ней разбирающегося. Учитывая нынешний недостаточный уровень моральной обеспокоенности страданиями (всех сентиентных существ), нам нужно обращаться к более широкой аудитории и доносить до людей наиболее убедительные причины относиться к этим вопросам серьёзно. Один из инструментов в этом — продвижение этики. Но ориентироваться исключительно на максимальность количества убеждённых нами людей будет ошибкой. Развитие потенциала подразумевает также обеспечение долгосрочной устойчивости движения, налаживание связей с заинтересованными сторонами, разработку и совершенствование идей, и [формирование здоровых социальных норм](magnus-vinding-why-altruists-should-be-cooperative.html). И, конечно, расширение наших знаний о том, как наилучшим образом уменьшать страдания («формирование мудрости») — ещё один критически важный аспект развития потенциала. (Подробности см. в нашем «[Стратегическом плане](https://centerforreducingsuffering.org/strategic-plan)» и «[Открытых вопросах для исследований](https://centerforreducingsuffering.org/open-research-questions/)».)

---

[^1]: Чувствительность ко времени касается того, можем ли мы делегировать или «переложить» ответственность на наших преемников. Иначе говоря, неясно, действительно ли так срочно нужно расширять моральный круг именно сейчас, по сравнению со сбором дополнительной информации с возможностью заняться этим позже. Это зависит от того, ожидаем ли мы, что в ближайшее время зафиксируются ценности или произойдут иные события решающей значимости. (Схожие вопросы [обсуждаются и в контексте других мер](https://www.fhi.ox.ac.uk/the-timing-of-labour-aimed-at-reducing-existential-risk/).)
[^2]: Однако это менее удивительно в том случае, если есть некоторая степень сходимости широкой категории действий в полезности как в краткосрочной, так и в долгосрочной перспективах. Например, увеличение озабоченности в отношении тех существ, которые сейчас игнорируются — это надёжная эвристика для улучшения мира, независимо от горизонта планирования. Кроме того, если нынешние знания и ресурсы движения ещё не полностью оптимизированы под максимальное влияние в краткосрочной перспективе, есть возможности для увеличения влияния как в краткосрочной, так и в долгосрочной перспективах (например, через повышение общей эффективности).
[^3]: Примечание переводчика: эмы (от слова «эмуляция») — это [гипотетические машины, эмулирующие сознание человека](485.html).
[^4]: Для этого также требуется, чтобы соответствующие законы распространялись на все формы страданий.
[^5]: Если законы неприменимы напрямую — например, в случае конфликтов между государствами или в некоторых будущих сценариях с участием ИИ — мы можем попытаться улучшить нормы и договорённости, имеющие отношение к намеренным рискам. К примеру, конвенции ООН могли бы запретить использование ИИ для угроз, аналогично уже существующим обсуждениям [использования ИИ для пыток](https://minnesotalawreview.org/article/stranger-than-science-fiction/).
[^6]: Примечание переводчика: трансформативными [называют](https://forum.effectivealtruism.org/topics/transformative-artificial-intelligence) такие ИИ, создание которых приводит к изменениям, сопоставимым по меньшей мере с аграрной или индустриальной революциями.
[^7]: Следует отметить, что наиболее перспективные меры в сфере управления могут не иметь прямого отношения к самому ИИ. Например, они могут касаться улучшения международных отношений в целом.
