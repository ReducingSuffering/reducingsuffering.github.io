---
layout: post
title: "Обзор катастрофических рисков ИИ"
unixtime: 
vk: https://vk.com/wall-199052526_562
telegram: https://t.me/reducing_suffering/291
tags:
  - искусственный_интеллект
  - x-риски
  - s-риски
meta_tags:
  - статьи
authors:
  - Дэн Хендрикс
  - Мантас Мазейка
  - Томас Вудсайд
link_to: https://lesswrong.ru/%D0%9E%D0%B1%D0%B7%D0%BE%D1%80_%D0%BA%D0%B0%D1%82%D0%B0%D1%81%D1%82%D1%80%D0%BE%D1%84%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85_%D1%80%D0%B8%D1%81%D0%BA%D0%BE%D0%B2_%D0%98%D0%98
preview: assets/images/previews/artificial-intelligence-155161-.jpg
preview_here: true
---
Из-за быстрого прогресса искусственного интеллекта среди экспертов, законодателей и мировых лидеров растёт беспокойство по поводу потенциальных катастрофических рисков, связанных с продвинутыми ИИ-системами.

В статье Дэна Хендрикса, Мантаса Мазейки и Томаса Вудсайда из Center for AI Safety приведен обзор основных источников катастрофических рисков ИИ, которые распределены на четыре категории: 1) злонамеренное использование, когда отдельные люди или группы людей намеренно используют ИИ для причинения вреда; 2) ИИ-гонка, когда конкурентная среда приводит к развёртыванию небезопасных ИИ или сдаче ИИ контроля; 3) организационные риски, когда шансы катастрофических происшествий растут из-за человеческого фактора и сложности задействованных систем; и 4) риски мятежных ИИ — возникающие из неотъемлемой сложности задачи контроля агентов, более умных, чем люди.

Для каждой категории рисков описаны специфические угрозы, предоставлены иллюстрирующие истории, обрисованы идеальные сценарии и предложены практические меры противодействия этим опасностям.
